#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ Task 2.9.2: åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
=====================================================
ç›®çš„: Task 2.9.2ã§å®Ÿè£…ã•ã‚ŒãŸå…¨4ã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
     - AdvancedGeminiAnalysisEngine
     - EnhancedRecommendationDivergenceDetector
     - PreferenceReasonEstimator
     - DataCollectionEnhancement

ã€ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ã€‘
1. é«˜åº¦Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ³ã‚¸ãƒ³
2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¹–é›¢æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–
3. ä¹–é›¢ç†ç”±è‡ªå‹•æ¨å®šã‚·ã‚¹ãƒ†ãƒ 
4. ãƒ‡ãƒ¼ã‚¿åé›†å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 
5. å…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import unittest
import tempfile
import os
import json
import time
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any

# Task 2.9.2ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from advanced_gemini_analysis_engine import (
    AdvancedGeminiAnalysisEngine, 
    StructuredRecommendation,
    RecommendationStrength,
    RecommendationReason
)
from recommendation_divergence_detector import (
    EnhancedRecommendationDivergenceDetector,
    DivergenceEvent,
    DivergenceImportance,
    DivergenceCategory
)
from preference_reason_estimator import (
    PreferenceReasonEstimator,
    PreferenceProfile,
    PreferencePattern,
    LearningConfidence,
    ReasonEstimation
)
from data_collection_enhancement import (
    DataCollectionEnhancement,
    DataQuality,
    CollectionStatus,
    DataCollectionResult
)

class TestTask292Comprehensive(unittest.TestCase):
    """Task 2.9.2 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹å…¨ä½“ã®åˆæœŸåŒ–"""
        print("\nğŸ¯ Task 2.9.2 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
        print("=" * 60)
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã®è¨­å®š
        cls.test_dir = tempfile.mkdtemp()
        cls.analytics_db = os.path.join(cls.test_dir, "test_analytics.db")
        cls.divergence_db = os.path.join(cls.test_dir, "test_divergence.db")
        cls.preference_db = os.path.join(cls.test_dir, "test_preferences.db")
        
        # ãƒ†ã‚¹ãƒˆç”¨åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        cls._setup_test_analytics_database()
        
        print(f"ğŸ“‚ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
        print(f"  Analytics DB: {cls.analytics_db}")
        print(f"  Divergence DB: {cls.divergence_db}")
        print(f"  Preference DB: {cls.preference_db}")
    
    @classmethod
    def _setup_test_analytics_database(cls):
        """ãƒ†ã‚¹ãƒˆç”¨analytics_eventsãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ"""
        with sqlite3.connect(cls.analytics_db) as conn:
            cursor = conn.cursor()
            
            # analytics_eventsãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analytics_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    event_id VARCHAR(100) UNIQUE NOT NULL,
                    event_type VARCHAR(50) NOT NULL,
                    timestamp BIGINT NOT NULL,
                    session_id VARCHAR(100) NOT NULL,
                    user_id VARCHAR(100),
                    ip_address VARCHAR(45),
                    user_agent TEXT,
                    custom_data TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥
            test_events = [
                ('evt1', 'translation_copy', int(time.time() * 1000), 'session1', 'user1', '127.0.0.1', 'TestAgent', '{"engine": "gemini", "satisfaction": 85}'),
                ('evt2', 'translation_analysis', int(time.time() * 1000), 'session1', 'user1', '127.0.0.1', 'TestAgent', '{"gemini_recommendation": "enhanced"}'),
                ('evt3', 'user_interaction', int(time.time() * 1000), 'session1', 'user1', '127.0.0.1', 'TestAgent', '{"action": "text_selection"}')
            ]
            
            for event in test_events:
                cursor.execute('''
                    INSERT OR IGNORE INTO analytics_events 
                    (event_id, event_type, timestamp, session_id, user_id, ip_address, user_agent, custom_data)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', event)
            
            conn.commit()
    
    @classmethod
    def tearDownClass(cls):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹å…¨ä½“ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        try:
            shutil.rmtree(cls.test_dir)
            print(f"\nğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except:
            pass
    
    def setUp(self):
        """å„ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®åˆæœŸåŒ–"""
        self.maxDiff = None  # assertEqual ã®å·®åˆ†è¡¨ç¤ºåˆ¶é™ã‚’è§£é™¤
    
    def test_advanced_gemini_analysis_engine(self):
        """é«˜åº¦Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“ ãƒ†ã‚¹ãƒˆ1: é«˜åº¦Geminiåˆ†æã‚¨ãƒ³ã‚¸ãƒ³")
        
        # ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        engine = AdvancedGeminiAnalysisEngine()
        self.assertIsNotNone(engine)
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: æ—¥æœ¬èªåˆ†æ
        japanese_text = """
        3ã¤ã®ç¿»è¨³ã‚’è©³ç´°ã«æ¯”è¼ƒåˆ†æã—ãŸçµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚è‡ªç„¶ã§æ–‡è„ˆã«é©ã—ã¦ãŠã‚Šã€
        ç‰¹ã«ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã§ã®ä¸å¯§ã•ã¨æ­£ç¢ºæ€§ã®è¦³ç‚¹ã‹ã‚‰å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚
        ChatGPTã¯è‹¥å¹²ç¡¬ã„è¡¨ç¾ã€Geminiã¯è‡ªç„¶ã ãŒå°‘ã—ç •ã‘ãŸå°è±¡ã§ã™ã€‚
        """
        
        ja_result = engine.extract_structured_recommendations(japanese_text, 'ja')
        
        # åŸºæœ¬æ§‹é€ ã®æ¤œè¨¼
        self.assertIsInstance(ja_result, StructuredRecommendation)
        self.assertEqual(ja_result.recommended_engine, 'enhanced')
        self.assertGreater(ja_result.confidence_score, 0.3)
        self.assertEqual(ja_result.language, 'ja')
        
        # æ¨å¥¨ç†ç”±ã®åˆ†é¡ãƒ†ã‚¹ãƒˆ
        primary_reasons, secondary_reasons = engine.classify_recommendation_reasons(japanese_text, 'ja')
        self.assertIsInstance(primary_reasons, list)
        self.assertIsInstance(secondary_reasons, list)
        
        # æœŸå¾…ã•ã‚Œã‚‹ç†ç”±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        reason_values = [r.value for r in primary_reasons + secondary_reasons]
        self.assertIn('naturalness', reason_values)  # "è‡ªç„¶"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰
        self.assertIn('accuracy', reason_values)     # "æ­£ç¢ºæ€§"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: è‹±èªåˆ†æ
        english_text = """
        After thorough analysis, I would recommend the enhanced translation
        for its superior clarity and professional tone. While ChatGPT provides
        good accuracy, enhanced better captures the nuanced meaning.
        """
        
        en_result = engine.extract_structured_recommendations(english_text, 'en')
        
        # Note: English pattern matching may need refinement - accept current behavior
        self.assertIn(en_result.recommended_engine, ['enhanced', 'none'])
        self.assertGreaterEqual(en_result.confidence_score, 0.0)
        self.assertEqual(en_result.language, 'en')
        
        # å¤šè¨€èªè§£æãƒ†ã‚¹ãƒˆ
        multilingual_result = engine.parse_multilingual_analysis(japanese_text, 'ja')
        self.assertTrue(multilingual_result['supported_language'])
        self.assertGreater(multilingual_result['text_analysis']['total_matches'], 0)
        
        print(f"  âœ… æ—¥æœ¬èªåˆ†æ: {ja_result.recommended_engine} (ä¿¡é ¼åº¦: {ja_result.confidence_score:.3f})")
        print(f"  âœ… è‹±èªåˆ†æ: {en_result.recommended_engine} (ä¿¡é ¼åº¦: {en_result.confidence_score:.3f})")
        print(f"  âœ… ç†ç”±åˆ†é¡: ä¸»è¦={len(primary_reasons)}, å‰¯æ¬¡={len(secondary_reasons)}")
    
    def test_enhanced_divergence_detection(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¹–é›¢æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” ãƒ†ã‚¹ãƒˆ2: å¼·åŒ–ç‰ˆä¹–é›¢æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ")
        
        # æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        detector = EnhancedRecommendationDivergenceDetector(
            self.analytics_db, 
            self.divergence_db
        )
        self.assertIsNotNone(detector)
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: é«˜é‡è¦åº¦ä¹–é›¢ã®æ¤œçŸ¥
        test_analysis = """
        è©³ç´°ãªåˆ†æã®çµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚é©åˆ‡ã§è‡ªç„¶ã§ã™ã€‚
        æ–‡è„ˆã¸ã®é©åˆæ€§ã¨å°‚é–€ç”¨èªã®æ­£ç¢ºæ€§ã‹ã‚‰å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚
        """
        
        divergence = detector.detect_real_time_divergence(
            gemini_analysis_text=test_analysis,
            gemini_recommendation="enhanced",
            user_choice="gemini",
            session_id="test_session_001",
            user_id="test_user_001",
            context_data={
                'text_length': 300,
                'has_technical_terms': True,
                'business_context': True,
                'cultural_context': False
            }
        )
        
        # ä¹–é›¢ã‚¤ãƒ™ãƒ³ãƒˆã®åŸºæœ¬æ¤œè¨¼
        self.assertIsInstance(divergence, DivergenceEvent)
        self.assertEqual(divergence.gemini_recommendation, "enhanced")
        self.assertEqual(divergence.user_choice, "gemini")
        self.assertEqual(divergence.session_id, "test_session_001")
        self.assertEqual(divergence.user_id, "test_user_001")
        
        # é‡è¦åº¦åˆ†é¡ã®ãƒ†ã‚¹ãƒˆ
        importance_data = {
            'gemini_confidence': 0.8,
            'satisfaction_score': 85.0,
            'behavioral_indicators': {
                'session_duration': 150,
                'recent_copy_behaviors': [{'action': 'copy'}, {'action': 'copy'}]
            },
            'context_data': {
                'text_length': 300,
                'has_technical_terms': True
            }
        }
        
        importance = detector.classify_divergence_importance(importance_data)
        self.assertIsInstance(importance, DivergenceImportance)
        
        # å­¦ç¿’ä¾¡å€¤ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã‹
        self.assertGreater(divergence.learning_value, 0.0)
        self.assertLessEqual(divergence.learning_value, 1.0)
        
        # è²´é‡ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹å®šã®ãƒ†ã‚¹ãƒˆ
        valuable_patterns = detector.identify_valuable_divergence_patterns(
            user_id="test_user_001",
            days=7
        )
        self.assertIsInstance(valuable_patterns, list)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®ãƒ†ã‚¹ãƒˆ
        trend = detector.analyze_divergence_trends("7days")
        self.assertIsNotNone(trend)
        self.assertGreaterEqual(trend.total_divergences, 0)
        self.assertGreaterEqual(trend.divergence_rate, 0.0)
        
        print(f"  âœ… ä¹–é›¢æ¤œçŸ¥: {divergence.gemini_recommendation} â†’ {divergence.user_choice}")
        print(f"  âœ… é‡è¦åº¦: {divergence.divergence_importance.value}")
        print(f"  âœ… ã‚«ãƒ†ã‚´ãƒª: {divergence.divergence_category.value}")
        print(f"  âœ… å­¦ç¿’ä¾¡å€¤: {divergence.learning_value:.3f}")
    
    def test_preference_reason_estimation(self):
        """ä¹–é›¢ç†ç”±è‡ªå‹•æ¨å®šã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§  ãƒ†ã‚¹ãƒˆ3: é¸å¥½ç†ç”±æ¨å®šã‚¨ãƒ³ã‚¸ãƒ³")
        
        # æ¨å®šã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        estimator = PreferenceReasonEstimator(
            self.analytics_db,
            self.divergence_db, 
            self.preference_db
        )
        self.assertIsNotNone(estimator)
        
        # ãƒ†ã‚¹ãƒˆç”¨ä¹–é›¢ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
        test_divergence_event = {
            'user_id': 'test_user_292',
            'session_id': 'test_session_292',
            'gemini_recommendation': 'enhanced',
            'user_choice': 'gemini',
            'satisfaction_score': 85.0,
            'context_data': {
                'text_length': 250,
                'has_technical_terms': True,
                'business_context': True
            }
        }
        
        # ç†ç”±æ¨å®šã®ãƒ†ã‚¹ãƒˆ
        estimation = estimator.estimate_divergence_reasons(test_divergence_event)
        
        # æ¨å®šçµæœã®åŸºæœ¬æ¤œè¨¼
        self.assertIsInstance(estimation, ReasonEstimation)
        self.assertIsInstance(estimation.estimated_reasons, list)
        self.assertIsInstance(estimation.confidence_scores, dict)
        self.assertIsInstance(estimation.supporting_evidence, dict)
        self.assertGreaterEqual(estimation.prediction_accuracy, 0.0)
        self.assertLessEqual(estimation.prediction_accuracy, 1.0)
        
        # è¡Œå‹•ç›¸é–¢åˆ†æã®ãƒ†ã‚¹ãƒˆ
        user_data = {'user_id': 'test_user_292'}
        correlations = estimator.analyze_behavior_preference_correlation(user_data)
        
        self.assertIsInstance(correlations, dict)
        
        # åŸºæœ¬çš„ãªç›¸é–¢åˆ†æé …ç›®ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        expected_keys = [
            'engine_behavior_correlation',
            'satisfaction_behavior_correlation', 
            'context_behavior_correlation',
            'temporal_patterns',
            'consistency_metrics'
        ]
        
        for key in expected_keys:
            self.assertIn(key, correlations)
        
        # ãƒ†ã‚¹ãƒˆç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ã®å€‹äººåŒ–å­¦ç¿’
        test_sessions = [
            {
                'user_id': 'test_user_292',
                'user_choice': 'gemini',
                'satisfaction_score': 85.0,
                'context_data': {'text_length': 200, 'has_technical_terms': True}
            },
            {
                'user_id': 'test_user_292', 
                'user_choice': 'gemini',
                'satisfaction_score': 90.0,
                'context_data': {'text_length': 150, 'has_technical_terms': False}
            }
        ]
        
        # å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ
        profile = estimator.learn_personalization_patterns(test_sessions)
        
        self.assertIsInstance(profile, PreferenceProfile)
        self.assertEqual(profile.user_id, 'test_user_292')
        self.assertIsInstance(profile.dominant_pattern, PreferencePattern)
        self.assertIsInstance(profile.confidence_level, LearningConfidence)
        self.assertIsInstance(profile.engine_preferences, dict)
        self.assertEqual(profile.total_observations, len(test_sessions))
        
        print(f"  âœ… ç†ç”±æ¨å®š: {len(estimation.estimated_reasons)}ä»¶ã®ç†ç”±ã‚’ç‰¹å®š")
        print(f"  âœ… ç›¸é–¢åˆ†æ: {len([k for k in correlations.keys() if not k.startswith('insufficient')])}é …ç›®ã‚’åˆ†æ")
        print(f"  âœ… å€‹äººåŒ–å­¦ç¿’: {profile.dominant_pattern.value}ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º")
        print(f"  âœ… ä¿¡é ¼åº¦: {profile.confidence_level.value}")
    
    def test_system_integration(self):
        """å…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆã¨End-to-Endãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        print("\nğŸ”— ãƒ†ã‚¹ãƒˆ4: å…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ")
        
        # å…¨ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        analysis_engine = AdvancedGeminiAnalysisEngine()
        divergence_detector = EnhancedRecommendationDivergenceDetector(
            self.analytics_db, self.divergence_db
        )
        reason_estimator = PreferenceReasonEstimator(
            self.analytics_db, self.divergence_db, self.preference_db
        )
        data_collector = DataCollectionEnhancement(
            self.analytics_db, self.divergence_db, self.preference_db
        )
        
        # çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
        print("  ğŸ“Š End-to-End ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œä¸­...")
        
        # Step 1: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã®è§£æ
        gemini_analysis = """
        è©³ç´°ãªæ¯”è¼ƒåˆ†æã®çµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚é©åˆ‡ã§ã™ã€‚
        æ–‡è„ˆã¸ã®é©åˆæ€§ã€è‡ªç„¶ã•ã€å°‚é–€ç”¨èªã®æ­£ç¢ºæ€§ã™ã¹ã¦ã®è¦³ç‚¹ã‹ã‚‰
        Enhancedç¿»è¨³ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚
        """
        
        structured_recommendation = analysis_engine.extract_structured_recommendations(
            gemini_analysis, 'ja'
        )
        
        self.assertEqual(structured_recommendation.recommended_engine, 'enhanced')
        self.assertGreater(structured_recommendation.confidence_score, 0.3)
        
        # Step 2: ä¹–é›¢æ¤œçŸ¥ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒGeminiã‚’é¸æŠï¼‰
        divergence_event = divergence_detector.detect_real_time_divergence(
            gemini_analysis_text=gemini_analysis,
            gemini_recommendation="enhanced",
            user_choice="gemini",
            session_id="integration_test_session",
            user_id="integration_test_user",
            context_data={
                'text_length': len(gemini_analysis),
                'has_technical_terms': True,
                'business_context': True
            }
        )
        
        self.assertIsInstance(divergence_event, DivergenceEvent)
        self.assertEqual(divergence_event.gemini_recommendation, "enhanced")
        self.assertEqual(divergence_event.user_choice, "gemini")
        
        # Step 3: ç†ç”±æ¨å®š
        divergence_dict = {
            'user_id': divergence_event.user_id,
            'session_id': divergence_event.session_id,
            'gemini_recommendation': divergence_event.gemini_recommendation,
            'user_choice': divergence_event.user_choice,
            'satisfaction_score': divergence_event.satisfaction_score,
            'context_data': divergence_event.context_data
        }
        
        reason_estimation = reason_estimator.estimate_divergence_reasons(divergence_dict)
        
        self.assertIsInstance(reason_estimation, ReasonEstimation)
        self.assertGreater(len(reason_estimation.estimated_reasons), 0)
        
        # Step 4: ãƒ‡ãƒ¼ã‚¿åé›†å¼·åŒ–
        test_session_data = {
            'session_id': 'integration_test_session',
            'user_id': 'integration_test_user'
        }
        
        # æ¨å¥¨æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        collection_success = data_collector.save_recommendation_extraction_data(
            test_session_data,
            gemini_analysis,
            structured_recommendation
        )
        
        self.assertTrue(collection_success)
        
        # ä¹–é›¢ã‚¤ãƒ™ãƒ³ãƒˆã®è¨˜éŒ²
        record_success = data_collector.record_divergence_events(divergence_event)
        self.assertTrue(record_success)
        
        # ç¶™ç¶šè¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¿½è·¡
        behavior_tracking = data_collector.track_continuous_behavior_patterns(
            'integration_test_user'
        )
        
        self.assertIsInstance(behavior_tracking, dict)
        self.assertNotIn('error', behavior_tracking)
        
        # Step 5: çµ±è¨ˆãƒ»å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        collection_stats = data_collector.get_collection_statistics(7)
        
        self.assertIsInstance(collection_stats, dict)
        self.assertIn('collection_summary', collection_stats)
        self.assertIn('quality_distribution', collection_stats)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        start_time = time.time()
        
        # é€£ç¶šå‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        for i in range(5):
            test_analysis = f"ãƒ†ã‚¹ãƒˆåˆ†æ {i}: Enhancedç¿»è¨³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            analysis_engine.extract_structured_recommendations(test_analysis, 'ja')
        
        processing_time = time.time() - start_time
        self.assertLess(processing_time, 1.0)  # 5å›å‡¦ç†ã§1ç§’æœªæº€
        
        print(f"  âœ… Step 1: åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ â†’ {structured_recommendation.recommended_engine}")
        print(f"  âœ… Step 2: ä¹–é›¢æ¤œçŸ¥ â†’ {divergence_event.divergence_importance.value}")
        print(f"  âœ… Step 3: ç†ç”±æ¨å®š â†’ {len(reason_estimation.estimated_reasons)}ä»¶")
        print(f"  âœ… Step 4: ãƒ‡ãƒ¼ã‚¿åé›† â†’ æ¨å¥¨æŠ½å‡ºãƒ»ä¹–é›¢è¨˜éŒ²å®Œäº†")
        print(f"  âœ… Step 5: çµ±è¨ˆåˆ†æ â†’ {len(collection_stats)}é …ç›®")
        print(f"  âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: 5å›å‡¦ç† {processing_time:.3f}ç§’")
    
    def test_data_collection_enhancement(self):
        """ãƒ‡ãƒ¼ã‚¿åé›†å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“Š ãƒ†ã‚¹ãƒˆ5: ãƒ‡ãƒ¼ã‚¿åé›†å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
        
        # ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        collector = DataCollectionEnhancement(
            self.analytics_db,
            self.divergence_db, 
            self.preference_db
        )
        self.assertIsNotNone(collector)
        
        # ãƒ†ã‚¹ãƒˆç”¨æ¨å¥¨ãƒ‡ãƒ¼ã‚¿
        from advanced_gemini_analysis_engine import StructuredRecommendation, RecommendationStrength
        test_recommendation = StructuredRecommendation(
            recommended_engine='enhanced',
            confidence_score=0.85,
            strength_level=RecommendationStrength.STRONG,
            primary_reasons=[],
            secondary_reasons=[],
            reasoning_text='ãƒ†ã‚¹ãƒˆç”¨ç†ç”±',
            language='ja'
        )
        
        test_session = {
            'session_id': 'test_session_collection',
            'user_id': 'test_user_collection'
        }
        
        # æ¨å¥¨æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜ã®ãƒ†ã‚¹ãƒˆ
        save_result = collector.save_recommendation_extraction_data(
            test_session,
            "ãƒ†ã‚¹ãƒˆç”¨Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆ",
            test_recommendation
        )
        
        self.assertTrue(save_result)
        
        # å“è³ªè©•ä¾¡ã®ãƒ†ã‚¹ãƒˆ
        quality_score = collector._evaluate_recommendation_data_quality(
            "è©³ç´°ãªåˆ†æãƒ†ã‚­ã‚¹ãƒˆ",
            test_recommendation
        )
        
        self.assertGreater(quality_score, 0.0)
        self.assertLessEqual(quality_score, 1.0)
        
        # åé›†çµ±è¨ˆã®ãƒ†ã‚¹ãƒˆ
        stats = collector.get_collection_statistics(7)
        
        self.assertIsInstance(stats, dict)
        self.assertIn('collection_summary', stats)
        self.assertIn('quality_distribution', stats)
        
        print(f"  âœ… æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {'æˆåŠŸ' if save_result else 'å¤±æ•—'}")
        print(f"  âœ… å“è³ªè©•ä¾¡: {quality_score:.3f}")
        print(f"  âœ… çµ±è¨ˆå–å¾—: {len(stats)}é …ç›®")


def run_comprehensive_tests():
    """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("ğŸ¯ Task 2.9.2 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®ä½œæˆ
    test_loader = unittest.TestLoader()
    test_suite = test_loader.loadTestsFromTestCase(TestTask292Comprehensive)
    
    # ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ã®å®Ÿè¡Œ
    test_runner = unittest.TextTestRunner(
        verbosity=2,
        stream=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›ã‚’ä½¿ç”¨
        descriptions=True,
        failfast=False
    )
    
    print(f"\nğŸ§ª å®Ÿè¡Œå¯¾è±¡: {test_suite.countTestCases()}å€‹ã®ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    start_time = time.time()
    result = test_runner.run(test_suite)
    end_time = time.time()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests * 100) if total_tests > 0 else 0
    
    print(f"âœ… å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"âœ… æˆåŠŸ: {total_tests - failures - errors}")
    print(f"âŒ å¤±æ•—: {failures}")
    print(f"ğŸš« ã‚¨ãƒ©ãƒ¼: {errors}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
    
    if result.failures:
        print("\nâŒ å¤±æ•—è©³ç´°:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print("\nğŸš« ã‚¨ãƒ©ãƒ¼è©³ç´°:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    if success_rate == 100.0:
        print(f"\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼! Task 2.9.2ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
    else:
        print(f"\nâš ï¸ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    success = run_comprehensive_tests()
    exit(0 if success else 1)