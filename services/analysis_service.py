"""
åˆ†æã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Task #9-3 AP-1 Phase 3: åˆ†ææ©Ÿèƒ½ã®Blueprintåˆ†é›¢

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
- åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹ç¿»è¨³åˆ†æå®Ÿè¡Œ
- åˆ†æçµæœã®ä¿å­˜ãƒ»ç®¡ç†
- çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ä¾å­˜æ³¨å…¥ã«ã‚ˆã‚‹ç–çµåˆè¨­è¨ˆ
"""

import os
import time
import requests
from datetime import datetime
from typing import Optional, Dict, Any
from flask import session, request
from security.security_logger import log_security_event, log_access_event


class AnalysisService:
    """åˆ†æã‚µãƒ¼ãƒ“ã‚¹ã®çµ±åˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, translation_state_manager, analysis_engine_manager, 
                 claude_client, logger, labels):
        """
        ä¾å­˜æ³¨å…¥ã«ã‚ˆã‚‹ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            translation_state_manager: TranslationStateManager instance
            analysis_engine_manager: AnalysisEngineManager instance
            claude_client: Claude API client
            logger: Application logger
            labels: Multilingual labels
        """
        self.state_manager = translation_state_manager
        self.engine_manager = analysis_engine_manager
        self.claude_client = claude_client
        self.logger = logger
        self.labels = labels
    
    def perform_nuance_analysis(self, session_id: str, selected_engine: str = "gemini") -> Dict[str, Any]:
        """
        ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            selected_engine: åˆ†æã‚¨ãƒ³ã‚¸ãƒ³å
            
        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """
        try:
            # ç¿»è¨³ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆRedis + Session ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            if self.state_manager and session_id:
                translated_text = self.state_manager.get_large_data(
                    "translated_text", session_id, 
                    default=session.get("translated_text", "")
                )
                better_translation = self.state_manager.get_large_data(
                    "better_translation", session_id, 
                    default=session.get("better_translation", "")
                )
                gemini_translation = self.state_manager.get_large_data(
                    "gemini_translation", session_id, 
                    default=session.get("gemini_translation", "")
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—
                translated_text = session.get("translated_text", "")
                better_translation = session.get("better_translation", "")
                gemini_translation = session.get("gemini_translation", "")

            # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª
            if not (len(translated_text.strip()) > 0 and
                    len(better_translation.strip()) > 0 and
                    len(gemini_translation.strip()) > 0):
                return {"error": "å¿…è¦ãªç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}

            # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥åˆ†æå®Ÿè¡Œ
            if selected_engine == 'gemini':
                # å¾“æ¥ã®Geminiåˆ†æ
                result, chatgpt_prompt = self._gemini_3way_analysis(
                    translated_text, better_translation, gemini_translation
                )
                return {
                    "success": True,
                    "analysis_text": result,
                    "prompt_used": chatgpt_prompt,
                    "engine": selected_engine
                }
            else:
                # ãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                input_text = session.get("input_text", "")
                
                analysis_result = self.engine_manager.analyze_translations(
                    chatgpt_trans=translated_text,
                    enhanced_trans=better_translation,
                    gemini_trans=gemini_translation,
                    engine=selected_engine,
                    context={
                        "input_text": input_text,
                        "source_lang": self._get_translation_state("language_pair", "ja-en").split("-")[0],
                        "target_lang": self._get_translation_state("language_pair", "ja-en").split("-")[1],
                        "partner_message": self._get_translation_state("partner_message", ""),
                        "context_info": self._get_translation_state("context_info", "")
                    }
                )

                if not analysis_result['success']:
                    return {
                        "error": f"åˆ†æã‚¨ãƒ³ã‚¸ãƒ³({selected_engine})ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {analysis_result['error']}"
                    }

                return {
                    "success": True,
                    "analysis_text": analysis_result.get('analysis_text', ''),
                    "prompt_used": analysis_result.get('prompt_used', ''),
                    "engine": selected_engine
                }

        except Exception as e:
            self.logger.error(f"Analysis service error: {str(e)}")
            return {"error": str(e)}
    
    def save_analysis_results(self, session_id: str, analysis_data: Dict[str, Any]) -> bool:
        """
        åˆ†æçµæœã‚’Redisã«ä¿å­˜
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            analysis_data: ä¿å­˜ã™ã‚‹åˆ†æãƒ‡ãƒ¼ã‚¿
            
        Returns:
            bool: ä¿å­˜æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            if not self.state_manager or not session_id:
                return False
                
            # åˆ†æçµæœã‚’Redisã«ä¿å­˜
            analysis_saved = self.state_manager.save_large_data(
                "gemini_3way_analysis", analysis_data.get("analysis_text", ""), session_id
            )
            
            if analysis_saved:
                self.logger.info(f"âœ… Analysis result cached successfully - {len(analysis_data.get('analysis_text', ''))} chars for session {session_id[:16]}...")
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                session.pop("gemini_3way_analysis", None)
                return True
            else:
                self.logger.warning("âš ï¸ Failed to cache analysis result - using session fallback")
                return False
                
        except Exception as e:
            self.logger.error(f"Failed to save analysis results: {e}")
            return False

    def save_analysis_to_db(self, session_id: str, analysis_result: str, recommendation: str,
                           confidence: float, strength: str, reasons: str) -> bool:
        """
        åˆ†æçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆapp.pyã‹ã‚‰ç§»å‹•ï¼‰
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            analysis_result: åˆ†æçµæœãƒ†ã‚­ã‚¹ãƒˆ
            recommendation: æ¨å¥¨ç¿»è¨³
            confidence: ä¿¡é ¼åº¦
            strength: å¼·åº¦
            reasons: ç†ç”±
            
        Returns:
            bool: ä¿å­˜æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            self.logger.info(f"ğŸ” ä¿å­˜é–‹å§‹: session_id={session_id}")
            self.logger.info(f"ğŸ” åˆ†æçµæœé•·: {len(analysis_result)} æ–‡å­—")
            self.logger.info(f"ğŸ” æ¨å¥¨: {recommendation}, ä¿¡é ¼åº¦: {confidence}, å¼·åº¦: {strength}")

            import sqlite3
            conn = sqlite3.connect('langpont_translation_history.db')
            cursor = conn.cursor()

            # ã¾ãšå¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            cursor.execute("""
                SELECT id, source_text, created_at 
                FROM translation_history 
                WHERE session_id = ?
                ORDER BY created_at DESC
            """, (session_id,))

            records = cursor.fetchall()
            self.logger.info(f"ğŸ” session_id={session_id} ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(records)}")

            if not records:
                self.logger.error(f"âŒ session_id {session_id} ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                # ãƒ‡ãƒãƒƒã‚°ç”¨: æœ€æ–°10ä»¶ã®session_idã‚’è¡¨ç¤º
                cursor.execute("""
                    SELECT session_id, created_at 
                    FROM translation_history 
                    ORDER BY created_at DESC 
                    LIMIT 10
                """)
                recent_sessions = cursor.fetchall()
                self.logger.info("ğŸ” æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDä¸€è¦§:")
                for sess_id, created_at in recent_sessions:
                    self.logger.info(f"  - {sess_id} ({created_at})")

                conn.close()
                return False

            # æœ€æ–°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠ
            record_id = records[0][0]
            source_text = records[0][1][:50] if records[0][1] else "N/A"
            created_at = records[0][2]
            self.logger.info(f"âœ… å¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰ç™ºè¦‹: ID={record_id}, ç¿»è¨³å…ƒ={source_text}..., ä½œæˆ={created_at}")

            # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            combined_analysis = f"""=== Gemini åˆ†æçµæœ ===
{analysis_result}

=== æ¨å¥¨ç¿»è¨³ ===
æ¨å¥¨: {recommendation}
ä¿¡é ¼åº¦: {confidence}
å¼·åº¦: {strength}
ç†ç”±: {reasons}
åˆ†ææ—¥æ™‚: {datetime.now().isoformat()}
"""

            # æ›´æ–°å®Ÿè¡Œï¼ˆæ—¢å­˜ã®gemini_analysisã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨ï¼‰
            cursor.execute("""
                UPDATE translation_history 
                SET gemini_analysis = ?
                WHERE id = ?
            """, (combined_analysis, record_id))

            updated_rows = cursor.rowcount
            self.logger.info(f"âœ… æ›´æ–°å®Œäº†: {updated_rows} è¡Œæ›´æ–°")

            conn.commit()
            conn.close()

            return updated_rows > 0

        except Exception as e:
            self.logger.error(f"Failed to save analysis to DB: {str(e)}")
            self.logger.error(f"âŒ åˆ†æä¿å­˜å¤±æ•—: session_id={session_id}")
            try:
                conn.close()
            except:
                pass
            return False

    def _gemini_3way_analysis(self, translated_text: str, better_translation: str, gemini_translation: str) -> tuple:
        """
        3ã¤ã®ç¿»è¨³çµæœã‚’åˆ†æã™ã‚‹é–¢æ•°ï¼ˆapp.pyã‹ã‚‰ç§»å‹•ï¼‰
        
        Args:
            translated_text: ChatGPTç¿»è¨³
            better_translation: Enhancedç¿»è¨³
            gemini_translation: Geminiç¿»è¨³
            
        Returns:
            tuple: (åˆ†æçµæœ, ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)
        """
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰è¡¨ç¤ºè¨€èªã‚’æ—©æœŸå–å¾—ï¼ˆã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚å¤šè¨€èªåŒ–ï¼‰
        display_lang = session.get("lang", "jp")
        analysis_lang_map = {
            "jp": "Japanese",
            "en": "English", 
            "fr": "French",
            "es": "Spanish"
        }
        analysis_language = analysis_lang_map.get(display_lang, "Japanese")

        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
        if not GEMINI_API_KEY or len(GEMINI_API_KEY) < 10:
            if analysis_language == "English":
                return "âš ï¸ Gemini API key is not properly configured", ""
            elif analysis_language == "French":
                return "âš ï¸ La clÃ© API Gemini n'est pas correctement configurÃ©e", ""
            elif analysis_language == "Spanish":
                return "âš ï¸ La clave API de Gemini no estÃ¡ configurada correctamente", ""
            else:
                return "âš ï¸ Gemini APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", ""

        # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼
        if not all([translated_text, better_translation, gemini_translation]):
            if analysis_language == "English":
                return "âš ï¸ Translation data required for analysis is missing", ""
            elif analysis_language == "French":
                return "âš ï¸ Les donnÃ©es de traduction nÃ©cessaires Ã  l'analyse sont manquantes", ""
            elif analysis_language == "Spanish":
                return "âš ï¸ Faltan los datos de traducciÃ³n necesarios para el anÃ¡lisis", ""
            else:
                return "âš ï¸ åˆ†æã«å¿…è¦ãªç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™", ""

        # ç¾åœ¨ã®è¨€èªè¨­å®šã‚’ç›´æ¥å–å¾—
        current_language_pair = request.form.get('language_pair') or self._get_translation_state("language_pair", "ja-en")

        try:
            source_lang, target_lang = current_language_pair.split("-")
            log_access_event(f'Gemini analysis - Current language pair: {current_language_pair}')
        except:
            source_lang = "ja"
            target_lang = "en"
            log_security_event('GEMINI_LANGUAGE_FALLBACK', 'Using fallback language pair ja-en', 'WARNING')

        # ç¾åœ¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        current_input_text = request.form.get('japanese_text') or session.get("input_text", "")
        current_partner_message = request.form.get('partner_message') or ""
        current_context_info = request.form.get('context_info') or ""

        # è¨€èªãƒãƒƒãƒ—
        lang_map = {
            "ja": "Japanese", "fr": "French", "en": "English",
            "es": "Spanish", "de": "German", "it": "Italian"
        }

        source_label = lang_map.get(source_lang, source_lang.capitalize())
        target_label = lang_map.get(target_lang, target_lang.capitalize())

        # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
        if current_context_info.strip():
            context_section = f"""
CURRENT TRANSLATION CONTEXT:
- Language pair: {source_label} â†’ {target_label}
- Previous conversation: {current_partner_message or "None"}
- Situation: {current_context_info.strip()}"""
        else:
            context_section = f"""
CURRENT TRANSLATION CONTEXT:
- Language pair: {source_label} â†’ {target_label}
- Type: General conversation"""

        # è¨€èªåˆ¥ã®æŒ‡ç¤ºã‚’æ§‹ç¯‰
        current_ui_lang = session.get('lang', 'jp')
        lang_instructions = {
            'jp': "IMPORTANT: æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ä»–ã®è¨€èªã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚",
            'en': "IMPORTANT: Please respond in English. Do not use any other languages.",
            'fr': "IMPORTANT: Veuillez rÃ©pondre en franÃ§ais. N'utilisez aucune autre langue.",
            'es': "IMPORTANT: Por favor responda en espaÃ±ol. No use ningÃºn otro idioma."
        }
        lang_instruction = lang_instructions.get(current_ui_lang, lang_instructions['jp'])

        # ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãƒã‚¤ãƒ³ãƒˆ
        focus_points_map = {
            'jp': f"""- ã©ã®{target_label}ç¿»è¨³ãŒæœ€ã‚‚è‡ªç„¶ã‹
- ä¸ãˆã‚‰ã‚ŒãŸæ–‡è„ˆã¸ã®é©åˆ‡æ€§
- ã“ã®{source_label}ã‹ã‚‰{target_label}ã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã¸ã®æ¨å¥¨""",
            'en': f"""- Which {target_label} translation is most natural
- Appropriateness to the given context
- Recommendation for this {source_label} to {target_label} translation task""",
            'fr': f"""- Quelle traduction {target_label} est la plus naturelle
- AdÃ©quation au contexte donnÃ©
- Recommandation pour cette tÃ¢che de traduction {source_label} vers {target_label}""",
            'es': f"""- QuÃ© traducciÃ³n al {target_label} es mÃ¡s natural
- AdecuaciÃ³n al contexto dado
- RecomendaciÃ³n para esta tarea de traducciÃ³n de {source_lang} a {target_lang}"""
        }
        focus_points = focus_points_map.get(current_ui_lang, focus_points_map['jp'])

        # æ˜ç¢ºãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""{lang_instruction}

Analyze these {target_label} translations of the given {source_label} text.

ORIGINAL TEXT ({source_label}): {current_input_text[:1000]}

{context_section}

TRANSLATIONS TO COMPARE:
1. ChatGPT Translation: {translated_text}
2. Enhanced Translation: {better_translation}  
3. Gemini Translation: {gemini_translation}

IMPORTANT: All translations above are in {target_label}. Analyze them as {target_label} text.

Provide analysis in {analysis_language} focusing on:
{focus_points}

Your entire response must be in {analysis_language}."""

        # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        total_length = len(translated_text) + len(better_translation) + len(gemini_translation)
        warning = ""
        if total_length > 8000:
            warning = f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã„ãŸã‚åˆ†æãŒåˆ¶é™ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆ{total_length}æ–‡å­—ï¼‰\n\n"

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={GEMINI_API_KEY}"
        headers = {"Content-Type": "application/json"}
        data = {
            "contents": [{
                "parts": [{
                    "text": prompt[:8000]  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’8000æ–‡å­—ã«åˆ¶é™
                }]
            }],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 1000
            }
        }

        try:
            response = requests.post(url, headers=headers, json=data, timeout=45)
            if response.status_code == 200:
                result_text = response.json()["candidates"][0]["content"]["parts"][0]["text"]
                log_access_event('Gemini 3-way analysis completed successfully')
                return warning + result_text.strip(), prompt
            else:
                error_msg = f"âš ï¸ Gemini API error: {response.status_code}"
                log_security_event('GEMINI_API_ERROR', error_msg, 'ERROR')
                return error_msg, prompt

        except requests.exceptions.Timeout:
            # å¤šè¨€èªå¯¾å¿œã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if analysis_language == "English":
                return f"âš ï¸ Gemini analysis timed out (45 seconds).\n\n" \
                       f"The text may be too long (total {total_length} characters).\n" \
                       f"Please try shortening the translation text and try again.", prompt
            elif analysis_language == "French":
                return f"âš ï¸ L'analyse Gemini a expirÃ© (45 secondes).\n\n" \
                       f"Le texte est peut-Ãªtre trop long (total {total_length} caractÃ¨res).\n" \
                       f"Veuillez raccourcir le texte de traduction et rÃ©essayer.", prompt
            elif analysis_language == "Spanish":
                return f"âš ï¸ El anÃ¡lisis de Gemini agotÃ³ el tiempo de espera (45 segundes).\n\n" \
                       f"El texto puede ser demasiado largo (total {total_length} caractÃ¨res).\n" \
                       f"Por favor acorte el texto de traducciÃ³n e intente de nuevo.", prompt
            else:
                return f"âš ï¸ Geminiåˆ†æãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ45ç§’ï¼‰ã€‚\n\n" \
                       f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆåˆè¨ˆ{total_length}æ–‡å­—ï¼‰ã€‚\n" \
                       f"ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’çŸ­ç¸®ã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚", prompt

        except Exception as e:
            import traceback
            # Gemini APIã®è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            if hasattr(e, 'response'):
                error_detail = f"Status: {e.response.status_code}, Body: {e.response.text[:500]}"
            else:
                error_detail = str(e)

            log_security_event('GEMINI_DETAILED_ERROR', error_detail, 'ERROR')
            self.logger.error(traceback.format_exc())

            # å¤šè¨€èªå¯¾å¿œã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if analysis_language == "English":
                return f"âš ï¸ Gemini analysis error (details logged): {str(e)[:100]}", prompt
            elif analysis_language == "French":
                return f"âš ï¸ Erreur d'analyse Gemini (dÃ©tails enregistrÃ©s): {str(e)[:100]}", prompt
            elif analysis_language == "Spanish":
                return f"âš ï¸ Error de anÃ¡lisis de Gemini (detalles registrados): {str(e)[:100]}", prompt
            else:
                return f"âš ï¸ Geminiåˆ†æã‚¨ãƒ©ãƒ¼ï¼ˆè©³ç´°ãƒ­ã‚°ã«è¨˜éŒ²æ¸ˆã¿ï¼‰: {str(e)[:100]}", prompt

    def _get_translation_state(self, field_name: str, default_value: str = "") -> str:
        """
        ç¿»è¨³çŠ¶æ…‹å–å¾—ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆapp.pyã‹ã‚‰ç§»å‹•ï¼‰
        
        Args:
            field_name: å–å¾—ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
            default_value: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
        Returns:
            str: å–å¾—ã—ãŸå€¤
        """
        session_id = getattr(session, 'session_id', None)
        
        if self.state_manager and session_id:
            cached_value = self.state_manager.get_translation_state(
                session_id, field_name, default_value
            )
            if cached_value is not None:
                return cached_value
        
        return session.get(field_name, default_value)