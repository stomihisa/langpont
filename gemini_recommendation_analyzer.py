#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ Task 2.9.1.5: Geminiæ¨å¥¨æŠ½å‡ºãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ 
=====================================================
ç›®çš„: Geminiåˆ†æçµæœã‹ã‚‰æ¨å¥¨ç¿»è¨³ã‚’è‡ªå‹•æŠ½å‡ºã—ã€
     ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿé¸æŠã¨ã®ä¹–é›¢ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€
     çœŸã®å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹ã™ã‚‹

ã€é‡è¦ã€‘å¾ªç’°åˆ†æå›é¿ã®ãŸã‚ã€æ¨å¥¨æŠ½å‡ºã¯
       Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥è¡Œã†
"""

import re
import json
import logging
import os
import openai
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
from collections import Counter, defaultdict

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiRecommendationAnalyzer:
    """Geminiåˆ†æçµæœã‹ã‚‰æ¨å¥¨ç¿»è¨³ã‚’è‡ªå‹•æŠ½å‡ºãƒ»åˆ†æ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # ğŸ†• ä¿®æ­£: æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ç”¨æ­£è¦è¡¨ç¾ï¼ˆåŒ…æ‹¬çš„æ”¹å–„ç‰ˆ + ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å¯¾å¿œï¼‰
        self.recommendation_patterns = [
            # ğŸ†• ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³
            r"\*\*(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³\*\*",
            r"æœ€ã‚‚.*?é©åˆ‡.*?ç¿»è¨³.*?ã¯.*?\*\*(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³\*\*",
            r"\*\*(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³\*\*.*?(?:ãŒ|ã¯).*?(?:æœ€ã‚‚|æœ€è‰¯|ãƒ™ã‚¹ãƒˆ)",
            r"(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³.*?(?:ãŒ|ã¯).*?(?:æœ€ã‚‚|æœ€è‰¯|ãƒ™ã‚¹ãƒˆ|ä¸€ç•ª).*?(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€)",
            r"(?:æœ€ã‚‚|æœ€è‰¯|ãƒ™ã‚¹ãƒˆ|ä¸€ç•ª).*?(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€).*?(?:ã¯|ãŒ).*?(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³",
            r"æ¨å¥¨.*?(?:ã¯|ãŒ).*?(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³",
            r"(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³.*?æ¨å¥¨",
            r"(ChatGPT|Enhanced|Gemini)(?:ã®|)ç¿»è¨³.*?(?:ã‚’|ãŒ).*?(?:æœ€ã‚‚|æœ€è‰¯|ãƒ™ã‚¹ãƒˆ)",
            
            # æ—¥æœ¬èªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤§å¹…å¼·åŒ–ï¼‰
            r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ãŒ|ã¯|ã‚’)?(?:æœ€ã‚‚|ã‚‚ã£ã¨ã‚‚|ä¸€ç•ª|ç‰¹ã«)?(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€|æ¨å¥¨|ãŠã™ã™ã‚|æœ€é©|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)',
            r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ãŒ|ã¯|ã‚’)?(?:æœ€é©|æœ€ã‚‚é©åˆ‡|ã‚‚ã£ã¨ã‚‚é©åˆ‡|ä¸€ç•ªé©åˆ‡|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)(?:ãª|ã®)?(?:é¸æŠ|é¸æŠè‚¢|ã‚ªãƒ—ã‚·ãƒ§ãƒ³|æ–¹æ³•|ç¿»è¨³)?',
            r'(?:æœ€ã‚‚|ã‚‚ã£ã¨ã‚‚|ä¸€ç•ª|ç‰¹ã«|æœ€ã‚‚é©åˆ‡|æœ€é©|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)(?:ãª|ã®)?(?:ç¿»è¨³|è¨³|é¸æŠè‚¢|é¸æŠ|ã‚ªãƒ—ã‚·ãƒ§ãƒ³)?(?:ã¯|ï¼š|:)?\s*([A-Za-z]+)',
            r'([A-Za-z]+)(?:ã‚’|ãŒ)(?:æ¨å¥¨|ãŠã™ã™ã‚|é¸æŠ|é¸ã¶ã¹ã|é¸æŠã™ã¹ã)',
            r'(?:æ¨å¥¨|ãŠã™ã™ã‚|ãƒ™ã‚¹ãƒˆ|æœ€é©|æœ€è‰¯|æœ€å–„)(?:ç¿»è¨³|è¨³|é¸æŠ|ã®é¸æŠè‚¢)?(?:ã¯|ï¼š|:)?\s*([A-Za-z]+)',
            r'([A-Za-z]+)(?:ãŒ|ã®ç¿»è¨³ãŒ|ç¿»è¨³ã¯)(?:ã‚ˆã‚Š|ã‚‚ã£ã¨|æœ€ã‚‚)(?:é©ã—ã¦ã„ã‚‹|é©åˆ‡|è‡ªç„¶|è‰¯ã„)',
            r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ã®æ–¹ãŒ|ã®ç¿»è¨³ã®æ–¹ãŒ)(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€)',
            
            # ğŸ†• è‹±èªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤šè¨€èªå¯¾å¿œå¼·åŒ–ç‰ˆï¼‰
            r"(?:most|best).*?(?:appropriate|suitable|natural).*?translation.*?(?:is|would be).*?(chatgpt|enhanced|gemini)",
            r"(?:recommend|suggest).*?(chatgpt|enhanced|gemini).*?translation",
            r"(chatgpt|enhanced|gemini).*?translation.*?(?:is|would be).*?(?:most|best).*?(?:appropriate|suitable|natural)",
            r"\*\*(ChatGPT|Enhanced|Gemini).*?translation\*\*",
            r"the.*?(chatgpt|enhanced|gemini).*?translation.*?(?:is|would be).*?(?:recommended|preferred)",
            r"I.*?(?:recommend|suggest).*?the.*?(chatgpt|enhanced|gemini).*?translation",
            r'(?:recommend|suggest|prefer|choose|select)\s+(?:the\s+)?([A-Za-z]+)(?:\s+translation)?',
            r'([A-Za-z]+)(?:\s+translation)?\s+(?:is|would be|will be)\s+(?:the\s+)?(?:most\s+)?(?:recommended|best|appropriate|preferred|suitable|optimal)',
            r'(?:best|most appropriate|preferred|optimal|most suitable)\s+(?:translation|choice|option)?\s*(?:is|would be|:)?\s*(?:the\s+)?([A-Za-z]+)',
            r'(?:I would|I\'d|should|you should)\s+(?:recommend|suggest|choose|select|prefer)\s+(?:the\s+)?([A-Za-z]+)',
            r'([A-Za-z]+)(?:\s+translation)?\s+(?:is|would be)\s+(?:more|most)\s+(?:suitable|appropriate|accurate|natural)',
            r'(?:the\s+)?([A-Za-z]+)(?:\s+translation)?\s+(?:performs|works)\s+(?:better|best)',
            r'(?:go with|use|choose)\s+(?:the\s+)?([A-Za-z]+)(?:\s+translation)?',
            
            # ğŸ†• ãƒ•ãƒ©ãƒ³ã‚¹èªãƒ‘ã‚¿ãƒ¼ãƒ³
            r"(?:la plus|le plus).*?(?:appropriÃ©e|appropriÃ©|naturelle|naturel).*?traduction.*?(?:est|serait).*?(chatgpt|enhanced|gemini)",
            r"(?:recommande|suggÃ¨re).*?traduction.*?(chatgpt|enhanced|gemini)",
            r"traduction.*?(chatgpt|enhanced|gemini).*?(?:est|serait).*?(?:la plus|le plus).*?(?:appropriÃ©e|appropriÃ©|naturelle|naturel)",
            r"la traduction.*?(chatgpt|enhanced|gemini).*?(?:est|serait).*?(?:recommandÃ©e|prÃ©fÃ©rÃ©e)",
            
            # ğŸ†• ã‚¹ãƒšã‚¤ãƒ³èªãƒ‘ã‚¿ãƒ¼ãƒ³
            r"(?:la mÃ¡s|el mÃ¡s).*?(?:apropiada|apropiado|natural).*?traducciÃ³n.*?(?:es|serÃ­a).*?(chatgpt|enhanced|gemini)",
            r"(?:recomiendo|sugiero).*?traducciÃ³n.*?(chatgpt|enhanced|gemini)",
            r"traducciÃ³n.*?(chatgpt|enhanced|gemini).*?(?:es|serÃ­a).*?(?:la mÃ¡s|el mÃ¡s).*?(?:apropiada|apropiado|natural)",
            r"la traducciÃ³n.*?(chatgpt|enhanced|gemini).*?(?:es|serÃ­a).*?(?:recomendada|preferida)",
            
            # ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
            r'([A-Za-z]+)[ï¼š:]\s*(?:â˜…|â˜†|â—|â—‹|â—¯|âœ“|âœ”|ğŸ‘|ğŸŒŸ|â­)+\s*(?:\(|ï¼ˆ)?(?:æœ€|æ¨å¥¨|best)',
            # é †ä½ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
            r'(?:1ä½|ç¬¬1ä½|1st|first)(?:ã¯|ï¼š|:)?\s*[ã€Œã€]?([A-Za-z]+)',
        ]
        
        # ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.engine_mappings = {
            'chatgpt': ['chatgpt', 'gpt', 'openai', 'ãƒãƒ£ãƒƒãƒˆã‚¸ãƒ¼ãƒ”ãƒ¼ãƒ†ã‚£ãƒ¼'],
            'enhanced': ['enhanced', 'better', 'å¼·åŒ–', 'æ”¹è‰¯', 'ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒ‰'],
            'gemini': ['gemini', 'google', 'ã‚¸ã‚§ãƒŸãƒ‹', 'ã‚°ãƒ¼ã‚°ãƒ«'],
            'original': ['original', 'source', 'åŸæ–‡', 'ã‚ªãƒªã‚¸ãƒŠãƒ«']
        }
        
        # åˆ†æå±¥æ­´ä¿å­˜
        self.analysis_history = []
        
        logger.info("Geminiæ¨å¥¨åˆ†æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def extract_gemini_recommendation(self, gemini_analysis_text: str, language: str = 'ja') -> Optional[str]:
        """
        ğŸš€ Phase A-7: extract_gemini_recommendation ã‚’ LLMå®Œå…¨ç§»è¡Œç‰ˆã«ç½®ãæ›ãˆ
        ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Œå…¨å‰Šé™¤ï¼‰
        
        Args:
            gemini_analysis_text: Geminiåˆ†æã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ
            language: åˆ†æè¨€èª ('ja', 'en', 'fr', 'es')
            
        Returns:
            æ¨å¥¨ã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³å (chatgpt/enhanced/gemini) ã¾ãŸã¯ None
        """
        logger.info(f"ğŸš€ Phase A-7: extract_gemini_recommendation LLMç§»è¡Œç‰ˆå‘¼ã³å‡ºã—")
        
        # enhanced_recommendation_extraction ã‚’ç›´æ¥å‘¼ã³å‡ºã—
        recommendation, confidence, method = self.enhanced_recommendation_extraction(
            analysis_text=gemini_analysis_text,
            analysis_language=self._map_language_code(language)
        )
        
        logger.info(f"ğŸš€ Phase A-7: LLMåˆ¤å®šçµæœ - æ¨å¥¨: {recommendation}, ä¿¡é ¼åº¦: {confidence}, æ‰‹æ³•: {method}")
        
        return recommendation
    
    def _map_language_code(self, language_code: str) -> str:
        """
        è¨€èªã‚³ãƒ¼ãƒ‰ã‚’analysis_languageã«ãƒãƒƒãƒ”ãƒ³ã‚°
        
        Args:
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ ('ja', 'en', 'fr', 'es')
            
        Returns:
            åˆ†æè¨€èªå ('Japanese', 'English', 'French', 'Spanish')
        """
        language_map = {
            'ja': 'Japanese',
            'en': 'English',
            'fr': 'French',
            'es': 'Spanish'
        }
        return language_map.get(language_code, 'Japanese')
    
    def get_analysis_tail(self, text: str, lines: int = 10) -> str:
        """
        ğŸ¤– Phase A-4: åˆ†æçµæœã®æœ€å¾ŒNè¡Œã‚’æŠ½å‡ºï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–ï¼‰
        
        Args:
            text: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            lines: æŠ½å‡ºã™ã‚‹è¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10è¡Œï¼‰
            
        Returns:
            æœ€å¾ŒNè¡Œã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not text:
            return ""
        
        # æ”¹è¡Œã§åˆ†å‰²ã—ã¦æœ€å¾Œã®Nè¡Œã‚’å–å¾—
        text_lines = text.strip().split('\n')
        tail_lines = text_lines[-lines:] if len(text_lines) > lines else text_lines
        
        result = '\n'.join(tail_lines)
        
        logger.info(f"ğŸ¤– Phase A-4: ãƒ†ã‚­ã‚¹ãƒˆæœ€é©åŒ–å®Œäº† - å…ƒ: {len(text_lines)}è¡Œ â†’ æŠ½å‡º: {len(tail_lines)}è¡Œ")
        logger.debug(f"ğŸ¤– æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {result[:100]}...")
        
        return result
    
    def extract_recommendation_with_chatgpt(self, analysis_tail: str, analysis_language: str = "Japanese") -> Tuple[Optional[str], float, str]:
        """
        ğŸš€ Phase A-6: ChatGPTæ¨å¥¨åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ç‰ˆï¼‰
        
        Args:
            analysis_tail: Geminiåˆ†æã®æœ€å¾Œã®éƒ¨åˆ†
            analysis_language: åˆ†æè¨€èª ("Japanese", "English", "French", "Spanish")
            
        Returns:
            (recommendation, confidence, method) ã®ã‚¿ãƒ—ãƒ«
        """
        logger.info(f"ğŸš€ Phase A-6: ChatGPTæ¨å¥¨åˆ¤å®šé–‹å§‹ (è¨€èª: {analysis_language})")
        
        # ğŸš€ Phase A-9.2: è¨€èªåˆ¥æ–‡è„ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        analysis_tail_clean = self._clean_negative_context(analysis_tail, analysis_language)
        logger.info(f"ğŸš€ Phase A-9.2: {analysis_language}æ–‡è„ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
        
        # ğŸš€ Phase A-6: æ”¹è‰¯ã•ã‚ŒãŸè¶…ç²¾å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompts = {
            "Japanese": f"""ã€ç¿»è¨³æ¨å¥¨åˆ†æã‚¿ã‚¹ã‚¯ã€‘

åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:
{analysis_tail_clean}

ã€åˆ¤å®šæŒ‡ç¤ºã€‘
ä¸Šè¨˜ã®Geminiåˆ†æã‹ã‚‰ã€Œæœ€ã‚‚æ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã€ã‚’1ã¤ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
âœ… ã€Œæ¨å¥¨ã€ã€Œæœ€é©ã€ã€Œãƒ™ã‚¹ãƒˆã€ã€Œæœ€ã‚‚é©åˆ‡ã€ç­‰ã®è‚¯å®šçš„è¡¨ç¾ã‚’é‡è¦–
âœ… ChatGPTã€Enhancedã€Geminiã®ä¸­ã‹ã‚‰1ã¤é¸æŠ
âœ… æ˜ç¢ºãªæ¨å¥¨ãŒãªã„å ´åˆã¯ã€Œnoneã€
âŒ å¦å®šçš„ã‚³ãƒ¡ãƒ³ãƒˆã¯ç„¡è¦–
âŒ è§£èª¬ä¸è¦ã€æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³åã®ã¿å›ç­”

ã€å›ç­”å½¢å¼ã€‘
chatgpt / enhanced / gemini / none ã®ã„ãšã‚Œã‹1èªã®ã¿

å›ç­”:""",

            "English": f"""ã€Translation Recommendation Analysis Taskã€‘

Analysis Text:
{analysis_tail_clean}

ã€Detection Instructionsã€‘
Identify the ONE most recommended translation engine from the above Gemini analysis.

ã€Critical Rulesã€‘
âœ… Focus on positive expressions: "recommended", "best", "most appropriate", "optimal"
âœ… Choose ONE from: ChatGPT, Enhanced, Gemini
âœ… If no clear recommendation exists, answer "none"
âŒ Ignore negative comments
âŒ No explanation needed, engine name only

ã€Response Formatã€‘
Only one word: chatgpt / enhanced / gemini / none

Answer:""",

            "French": f"""ã€TÃ¢che d'Analyse de Recommandation de Traductionã€‘

Texte d'Analyse:
{analysis_tail_clean}

ã€Instructions de DÃ©tectionã€‘
Identifiez le moteur de traduction LE PLUS recommandÃ© dans l'analyse Gemini ci-dessus.

ã€RÃ¨gles Critiquesã€‘
âœ… Concentrez-vous sur les expressions positives: "recommandÃ©", "meilleur", "plus appropriÃ©", "optimal"
âœ… Choisissez UN parmi: ChatGPT, Enhanced, Gemini
âœ… Si aucune recommandation claire, rÃ©pondez "none"
âŒ Ignorez les commentaires nÃ©gatifs
âŒ Pas d'explication, nom du moteur uniquement

ã€Format de RÃ©ponseã€‘
Un seul mot: chatgpt / enhanced / gemini / none

RÃ©ponse:""",

            "Spanish": f"""ã€Tarea de AnÃ¡lisis de RecomendaciÃ³n de TraducciÃ³nã€‘

Texto de AnÃ¡lisis:
{analysis_tail_clean}

ã€Instrucciones de DetecciÃ³nã€‘
Identifique el motor de traducciÃ³n MÃS recomendado en el anÃ¡lisis Gemini anterior.

ã€Reglas CrÃ­ticasã€‘
âœ… EnfÃ³quese en expresiones positivas: "recomendado", "mejor", "mÃ¡s apropiado", "Ã³ptimo"
âœ… Elija UNO de: ChatGPT, Enhanced, Gemini
âœ… Si no hay recomendaciÃ³n clara, responda "none"
âŒ Ignore comentarios negativos
âŒ Sin explicaciÃ³n, solo nombre del motor

ã€Formato de Respuestaã€‘
Una sola palabra: chatgpt / enhanced / gemini / none

Respuesta:"""
        }
        
        prompt = prompts.get(analysis_language, prompts["Japanese"])
        
        logger.info(f"ğŸš€ Phase A-6: === ChatGPT APIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        
        try:
            # ğŸš€ Phase A-6: ç’°å¢ƒå¤‰æ•°ç¢ºèª
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.error("ğŸš€ Phase A-6: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return None, 0.0, "api_key_missing"
            
            logger.info(f"ğŸš€ Phase A-6: APIã‚­ãƒ¼ç¢ºèªå®Œäº† (é•·ã•: {len(api_key)}æ–‡å­—)")
            
            # ğŸš€ Phase A-8: OpenAI v1.x å¯¾å¿œã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
            client = openai.OpenAI(api_key=api_key)
            
            # ğŸš€ Phase A-8: æœ€é©åŒ–ã•ã‚ŒãŸAPIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            api_params = {
                "model": "gpt-3.5-turbo",
                "max_tokens": 5,  # ğŸš€ ã•ã‚‰ã«çŸ­ç¸®ï¼ˆ1èªã®ã¿ï¼‰
                "temperature": 0.0,  # ğŸš€ å®Œå…¨æ±ºå®šè«–çš„
                "top_p": 1.0,
                "frequency_penalty": 0.0,
                "presence_penalty": 0.0
            }
            logger.info(f"ğŸš€ Phase A-8: APIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {api_params}")
            
            # ğŸš€ Phase A-8: æ”¹è‰¯ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt = "You are a precise translation recommendation detector. Analyze the text and respond with exactly one word: chatgpt, enhanced, gemini, or none. No explanation, no punctuation, just the single word."
            
            logger.info(f"ğŸš€ Phase A-8: ChatGPT APIå‘¼ã³å‡ºã—å®Ÿè¡Œ...")
            
            response = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                **api_params
            )
            
            logger.info(f"ğŸš€ Phase A-6: APIå‘¼ã³å‡ºã—æˆåŠŸ")
            
            # ğŸš€ Phase A-8: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            if response and hasattr(response, 'choices') and response.choices:
                choice = response.choices[0]
                if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                    raw_answer = choice.message.content.strip().lower()
                    logger.info(f"ğŸš€ Phase A-8: ChatGPTç”Ÿå›ç­”: '{raw_answer}'")
                    
                    # ğŸš€ Phase A-8: å³å¯†ãªå›ç­”æ¤œè¨¼
                    normalized_answer = self._normalize_chatgpt_response(raw_answer)
                    logger.info(f"ğŸš€ Phase A-8: æ­£è¦åŒ–å¾Œ: '{normalized_answer}'")
                    
                    if normalized_answer in ['chatgpt', 'enhanced', 'gemini']:
                        confidence = 0.98  # ğŸš€ Phase A-8 é«˜ä¿¡é ¼åº¦
                        logger.info(f"âœ… Phase A-8: ChatGPTåˆ¤å®šæˆåŠŸ - æ¨å¥¨: {normalized_answer} (ä¿¡é ¼åº¦: {confidence})")
                        return normalized_answer, confidence, "llm_chatgpt_a8"
                    elif normalized_answer == 'none':
                        logger.info(f"ğŸš€ Phase A-8: ChatGPTåˆ¤å®š - æ˜ç¢ºãªæ¨å¥¨ãªã—")
                        return None, 0.7, "llm_chatgpt_none_a8"
                    else:
                        logger.warning(f"ğŸš€ Phase A-8: ChatGPTå›ç­”ãŒäºˆæœŸã—ãªã„å½¢å¼: '{raw_answer}' â†’ '{normalized_answer}'")
                        return None, 0.0, "llm_chatgpt_invalid_a8"
                else:
                    logger.error("ğŸš€ Phase A-8: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚¨ãƒ©ãƒ¼")
                    return None, 0.0, "llm_response_malformed_a8"
            else:
                logger.error("ğŸš€ Phase A-8: ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                return None, 0.0, "llm_response_empty_a8"
                
        except openai.RateLimitError as e:
            logger.error(f"ğŸš€ Phase A-8: OpenAI ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, 0.0, "llm_rate_limit_a8"
        except openai.AuthenticationError as e:
            logger.error(f"ğŸš€ Phase A-8: OpenAI èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, 0.0, "llm_auth_error_a8"
        except openai.APIError as e:
            logger.error(f"ğŸš€ Phase A-8: OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, 0.0, "llm_api_error_a8"
        except Exception as e:
            logger.error(f"ğŸš€ Phase A-8: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            logger.error(f"ğŸš€ Phase A-8: ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
            return None, 0.0, "llm_unexpected_error_a8"
        
        finally:
            logger.info(f"ğŸš€ Phase A-8: === ChatGPT APIå‘¼ã³å‡ºã—çµ‚äº† ===")
    
    def _clean_negative_context(self, text: str, analysis_language: str = "Japanese") -> str:
        """
        ğŸš€ Phase A-9.2: å¦å®šçš„æ–‡è„ˆã®é™¤å»ï¼ˆå®Œå…¨å¤šè¨€èªå¯¾å¿œç‰ˆï¼‰
        
        Args:
            text: å…ƒã®Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            analysis_language: åˆ†æè¨€èª ("Japanese", "English", "French", "Spanish")
            
        Returns:
            å¦å®šçš„æ–‡è„ˆã‚’é™¤å»ã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆè¨€èªåˆ¥æ¨å¥¨æ–‡ä¿è­·ï¼‰
        """
        if not text:
            return text
        
        logger.info(f"ğŸš€ Phase A-9.2: å®Œå…¨å¤šè¨€èªå¯¾å¿œã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ (è¨€èª: {analysis_language})")
        
        # ğŸš€ Phase A-9.2: è¨€èªåˆ¥æ¨å¥¨æ–‡ä¿è­·ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        recommendation_keywords = {
            "Japanese": ['æœ€ã‚‚è‡ªç„¶ã§é©åˆ‡', 'æœ€ã‚‚é©åˆ‡', 'æœ€ã‚‚è‡ªç„¶', 'æ¨å¥¨', 'ãŠã™ã™ã‚', 'ãƒ™ã‚¹ãƒˆ', 'æœ€è‰¯', 'æœ€å–„', 
                        'ä¸€ç•ªè‰¯ã„', 'ä¸€ç•ªé©åˆ‡', 'æœ€é©', 'å„ªã‚Œã¦ã„ã‚‹', 'ç´ æ™´ã‚‰ã—ã„'],
            "English": ['most natural', 'most appropriate', 'most suitable', 'recommend', 'best choice', 'optimal', 
                       'preferred', 'ideal', 'I recommend', 'I suggest', 'should choose', 'should use', 'excellent'],
            "French": ['le plus naturel', 'le plus appropriÃ©', 'recommande', 'meilleur choix', 'optimal', 'idÃ©al', 
                      'prÃ©fÃ©rÃ©', 'je recommande', 'je suggÃ¨re', 'devrait choisir', 'excellent'],
            "Spanish": ['mÃ¡s natural', 'mÃ¡s apropiado', 'recomiendo', 'mejor opciÃ³n', 'Ã³ptimo', 'ideal', 
                       'preferido', 'sugiero', 'deberÃ­a elegir', 'excelente']
        }
        
        # ğŸš€ Phase A-9.2: è¨€èªåˆ¥å¦å®šçš„ãƒ‘ã‚¿ãƒ¼ãƒ³
        negative_patterns_by_language = {
            "Japanese": [
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:ã¯|ãŒ).*?(?:åŠ£ã‚‹|ä¸è¶³|å¼±ã„|è¶³ã‚Šãªã„|å•é¡ŒãŒã‚ã‚‹|é©åˆ‡ã§ã¯ãªã„).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:ã§ã¯|ã ã¨).*?(?:ä¸é©åˆ‡|ä¸è‡ªç„¶|é•å’Œæ„ŸãŒã‚ã‚‹|ãŠã‹ã—ã„).*',
                r'.*(?:æ‰¹åˆ¤|å¦å®š|æ¬ ç‚¹|å¼±ç‚¹|å•é¡Œç‚¹|èª²é¡Œ).*?(?:ChatGPT|Enhanced|Gemini).*',
                r'.*(?:ã—ã‹ã—|ãŸã ã—|ä¸€æ–¹ã§|ãŸã ).*?(?:ChatGPT|Enhanced|Gemini).*?(?:æ¬ ç‚¹|å•é¡Œ|èª²é¡Œ|ä¸ååˆ†).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*?(?:ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªå°è±¡|å …ã„å°è±¡|ç¡¬ã„å°è±¡|å†·ãŸã„å°è±¡).*',
            ],
            "English": [
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:is|are|has|have).*?(?:poor|inadequate|weak|problematic|unsuitable|inferior).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:translation|version).*?(?:is|are).*?(?:unnatural|awkward|strange|odd).*',
                r'.*(?:criticism|critique|weakness|flaw|problem|issue).*?(?:ChatGPT|Enhanced|Gemini).*',
                r'.*(?:however|but|although|though).*?(?:ChatGPT|Enhanced|Gemini).*?(?:lacks|fails|problems|issues).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*?(?:formal tone|stiff impression|cold feeling).*',
            ],
            "French": [
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:est|sont|a|ont).*?(?:pauvre|inadÃ©quat|faible|problÃ©matique|inappropriÃ©).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:traduction|version).*?(?:est|sont).*?(?:peu naturel|maladroit|Ã©trange|bizarre).*',
                r'.*(?:critique|faiblesse|dÃ©faut|problÃ¨me).*?(?:ChatGPT|Enhanced|Gemini).*',
                r'.*(?:cependant|mais|bien que|quoique).*?(?:ChatGPT|Enhanced|Gemini).*?(?:manque|Ã©choue|problÃ¨mes).*',
            ],
            "Spanish": [
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:es|son|tiene|tienen).*?(?:pobre|inadecuado|dÃ©bil|problemÃ¡tico|inapropiado).*',
                r'.*(?:ChatGPT|Enhanced|Gemini).*(?:traducciÃ³n|versiÃ³n).*?(?:es|son).*?(?:poco natural|torpe|extraÃ±o|raro).*',
                r'.*(?:crÃ­tica|debilidad|defecto|problema).*?(?:ChatGPT|Enhanced|Gemini).*',
                r'.*(?:sin embargo|pero|aunque).*?(?:ChatGPT|Enhanced|Gemini).*?(?:carece|falla|problemas).*',
            ]
        }
        
        # ğŸš€ Phase A-9.2: ç¾åœ¨ã®è¨€èªã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—
        current_keywords = recommendation_keywords.get(analysis_language, recommendation_keywords["Japanese"])
        negative_patterns = negative_patterns_by_language.get(analysis_language, negative_patterns_by_language["Japanese"])
        
        lines = text.split('\n')
        filtered_lines = []
        
        for line in lines:
            is_negative = False
            
            # ğŸš€ Phase A-9.2: è¨€èªåˆ¥æ¨å¥¨æ–‡ä¿è­·
            is_recommendation = any(keyword.lower() in line.lower() for keyword in current_keywords)
            
            if is_recommendation:
                # æ¨å¥¨æ–‡ã¯ä¿è­·ï¼ˆå‰Šé™¤ã—ãªã„ï¼‰
                logger.info(f"ğŸš€ Phase A-9.2: {analysis_language}æ¨å¥¨æ–‡ä¿è­·: {line[:50]}...")
                filtered_lines.append(line)
                continue
            
            # æ¨å¥¨æ–‡ä»¥å¤–ã§è¨€èªåˆ¥å¦å®šçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            for pattern in negative_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    logger.info(f"ğŸš€ Phase A-9.2: {analysis_language}å¦å®šçš„æ–‡é™¤å»: {line[:50]}...")
                    is_negative = True
                    break
            
            if not is_negative:
                filtered_lines.append(line)
        
        result = '\n'.join(filtered_lines)
        
        logger.info(f"ğŸš€ Phase A-9.2: {analysis_language}ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº† - å…ƒ: {len(lines)}è¡Œ â†’ å¾Œ: {len(filtered_lines)}è¡Œ")
        
        return result
    
    def _normalize_chatgpt_response(self, raw_response: str) -> str:
        """ChatGPTãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ­£è¦åŒ–"""
        # å°æ–‡å­—åŒ–ã€ç©ºç™½é™¤å»
        clean_response = raw_response.strip().lower()
        
        # ä½™åˆ†ãªæ–‡å­—ã‚„å¥èª­ç‚¹ã‚’é™¤å»
        clean_response = re.sub(r'[^\w]', '', clean_response)
        
        # éƒ¨åˆ†ãƒãƒƒãƒãƒ³ã‚°
        if 'chatgpt' in clean_response:
            return 'chatgpt'
        elif 'enhanced' in clean_response:
            return 'enhanced'
        elif 'gemini' in clean_response:
            return 'gemini'
        elif 'none' in clean_response or 'ãªã—' in clean_response or 'unclear' in clean_response:
            return 'none'
        else:
            return 'unknown'
    
    def validate_openai_api_key(self) -> Dict[str, Any]:
        """
        ğŸš¨ Phase A-8: OpenAI APIã‚­ãƒ¼æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆv1.xå¯¾å¿œç‰ˆï¼‰
        
        Returns:
            APIã‚­ãƒ¼æ¤œè¨¼çµæœã®è©³ç´°è¾æ›¸
        """
        logger.info("ğŸš¨ Phase A-8: OpenAI APIã‚­ãƒ¼æ¤œè¨¼é–‹å§‹ï¼ˆv1.xå¯¾å¿œï¼‰")
        
        validation_result = {
            "is_valid": False,
            "api_key_exists": False,
            "api_key_format_valid": False,
            "api_connection_test": False,
            "error_details": [],
            "recommendations": []
        }
        
        try:
            # 1. ç’°å¢ƒå¤‰æ•°ã®å­˜åœ¨ç¢ºèª
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                validation_result["error_details"].append("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                validation_result["recommendations"].append("ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return validation_result
            
            validation_result["api_key_exists"] = True
            logger.info(f"ğŸš¨ Phase A-8: APIã‚­ãƒ¼å­˜åœ¨ç¢ºèª - OK (é•·ã•: {len(api_key)}æ–‡å­—)")
            
            # 2. APIã‚­ãƒ¼å½¢å¼ã®æ¤œè¨¼
            if not api_key.startswith("sk-"):
                validation_result["error_details"].append("APIã‚­ãƒ¼ãŒ 'sk-' ã§å§‹ã¾ã£ã¦ã„ã¾ã›ã‚“")
                validation_result["recommendations"].append("æ­£ã—ã„OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return validation_result
            
            if len(api_key) < 40:
                validation_result["error_details"].append(f"APIã‚­ãƒ¼ãŒçŸ­ã™ãã¾ã™ (é•·ã•: {len(api_key)})")
                validation_result["recommendations"].append("å®Œå…¨ãªAPIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return validation_result
            
            validation_result["api_key_format_valid"] = True
            logger.info("ğŸš¨ Phase A-8: APIã‚­ãƒ¼å½¢å¼æ¤œè¨¼ - OK")
            
            # 3. ğŸš€ Phase A-8: OpenAI v1.x å¯¾å¿œã®APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
            import openai
            
            # ğŸš€ Phase A-8: æ–°ã—ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æ–¹å¼
            client = openai.OpenAI(api_key=api_key)
            
            # éå¸¸ã«ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            test_response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1,
                temperature=0
            )
            
            if test_response and hasattr(test_response, 'choices') and test_response.choices:
                validation_result["api_connection_test"] = True
                validation_result["is_valid"] = True
                logger.info("ğŸš¨ Phase A-8: APIæ¥ç¶šãƒ†ã‚¹ãƒˆ - OK (v1.x)")
                validation_result["recommendations"].append("APIã‚­ãƒ¼ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼ˆv1.xå¯¾å¿œï¼‰")
            else:
                validation_result["error_details"].append("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™")
                
        except openai.AuthenticationError as e:
            validation_result["error_details"].append(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            validation_result["recommendations"].append("APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚æ­£ã—ã„ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            logger.error(f"ğŸš¨ Phase A-8: èªè¨¼ã‚¨ãƒ©ãƒ¼ - {str(e)}")
            
        except openai.RateLimitError as e:
            validation_result["api_connection_test"] = True  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™=ã‚­ãƒ¼ã¯æœ‰åŠ¹
            validation_result["is_valid"] = True
            validation_result["error_details"].append(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {str(e)}")
            validation_result["recommendations"].append("APIã‚­ãƒ¼ã¯æœ‰åŠ¹ã§ã™ãŒã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¦ã„ã¾ã™")
            logger.warning(f"ğŸš¨ Phase A-8: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ - {str(e)}")
            
        except openai.APIError as e:
            validation_result["error_details"].append(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
            validation_result["recommendations"].append("OpenAI APIã‚µãƒ¼ãƒ“ã‚¹ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            logger.error(f"ğŸš¨ Phase A-8: APIã‚¨ãƒ©ãƒ¼ - {str(e)}")
            
        except Exception as e:
            validation_result["error_details"].append(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
            validation_result["recommendations"].append("ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            logger.error(f"ğŸš¨ Phase A-8: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ - {str(e)}")
        
        logger.info(f"ğŸš¨ Phase A-8: APIã‚­ãƒ¼æ¤œè¨¼å®Œäº† - æœ‰åŠ¹: {validation_result['is_valid']}")
        return validation_result
    
    def enhanced_recommendation_extraction(self, analysis_text: str, analysis_language: str = "Japanese") -> Tuple[Optional[str], float, str]:
        """
        ğŸš€ Phase A-6: LLMå®Œå…¨ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Œå…¨å»ƒæ­¢ï¼‰
        
        Args:
            analysis_text: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆå…¨æ–‡
            analysis_language: åˆ†æè¨€èª
            
        Returns:
            (recommendation, confidence, method) ã®ã‚¿ãƒ—ãƒ«
        """
        logger.info(f"ğŸš€ Phase A-6: LLMå®Œå…¨ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ - ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å»ƒæ­¢")
        
        try:
            # ğŸš€ Phase A-6: APIã‚­ãƒ¼æ¤œè¨¼ã‚’å®Ÿè¡Œï¼ˆå¤±æ•—æ™‚ã¯å³åº§ã«çµ‚äº†ï¼‰
            api_validation = self.validate_openai_api_key()
            if not api_validation["is_valid"]:
                logger.error("ğŸš¨ Phase A-6: OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ - å‡¦ç†ã‚’ä¸­æ–­")
                for error in api_validation["error_details"]:
                    logger.error(f"ğŸš¨ Phase A-6: {error}")
                for rec in api_validation["recommendations"]:
                    logger.info(f"ğŸš¨ Phase A-6: æ¨å¥¨äº‹é …: {rec}")
                
                # ğŸš€ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Œå…¨å»ƒæ­¢ - APIå¤±æ•—æ™‚ã¯ç´ ç›´ã«å¤±æ•—
                logger.warning("ğŸš€ Phase A-6: APIã‚­ãƒ¼ç„¡åŠ¹ã®ãŸã‚å‡¦ç†çµ‚äº†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å»ƒæ­¢ï¼‰")
                return None, 0.0, "api_key_invalid_no_fallback"
            
            logger.info("âœ… Phase A-6: OpenAI APIã‚­ãƒ¼æ¤œè¨¼æˆåŠŸ - LLMåˆ¤å®šã®ã¿å®Ÿè¡Œ")
            
            # 1. ãƒ†ã‚­ã‚¹ãƒˆæœ€é©åŒ–ï¼ˆæœ€å¾Œ10è¡ŒæŠ½å‡ºï¼‰
            analysis_tail = self.get_analysis_tail(analysis_text, 10)
            
            if not analysis_tail:
                logger.warning("ğŸš€ Phase A-6: åˆ†æãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™")
                return None, 0.0, "empty_text"
            
            # 2. ChatGPTåˆ¤å®šã®ã¿å®Ÿè¡Œï¼ˆPhase A-6å®Œå…¨ç§»è¡Œç‰ˆï¼‰
            recommendation, confidence, method = self.extract_recommendation_with_chatgpt(analysis_tail, analysis_language)
            
            # ğŸš€ Phase A-6: çµæœã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸€åˆ‡ãªã—ï¼‰
            if recommendation and method.startswith("llm_chatgpt"):
                logger.info(f"âœ… Phase A-6: ChatGPTåˆ¤å®šæˆåŠŸ - æ¨å¥¨: {recommendation}, ä¿¡é ¼åº¦: {confidence}")
                return recommendation, confidence, method
            elif method.startswith("llm_chatgpt_none"):
                logger.info(f"âœ… Phase A-6: ChatGPTåˆ¤å®šå®Œäº† - æ˜ç¢ºãªæ¨å¥¨ãªã—")
                return None, 0.5, method
            else:
                logger.warning(f"âŒ Phase A-6: ChatGPTåˆ¤å®šå¤±æ•— - ç†ç”±: {method}")
                return None, 0.0, method
                
        except Exception as e:
            logger.error(f"âŒ Phase A-6: LLMå®Œå…¨ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ğŸš€ Phase A-6: ç·Šæ€¥æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å»ƒæ­¢
            return None, 0.0, "llm_system_error"
    
    def _normalize_engine_name(self, raw_name: str) -> Optional[str]:
        """ã‚¨ãƒ³ã‚¸ãƒ³åã‚’æ­£è¦åŒ–"""
        raw_lower = raw_name.lower().strip()
        
        for engine, aliases in self.engine_mappings.items():
            for alias in aliases:
                if alias in raw_lower or raw_lower in alias:
                    return engine
        
        return None
    
    def _extract_by_score_analysis(self, text: str) -> Optional[str]:
        """ã‚¹ã‚³ã‚¢ã‚„è©•ä¾¡è¡¨ç¾ã‹ã‚‰æ¨å¥¨ã‚’æ¨å®š"""
        # ã‚¹ã‚³ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: "ChatGPT: 8/10", "Enhanced: â˜…â˜…â˜…â˜…â˜†"ï¼‰
        score_patterns = [
            r'(\w+)[ï¼š:]\s*(\d+)\s*[/ï¼]\s*\d+',  # æ•°å€¤ã‚¹ã‚³ã‚¢
            r'(\w+)[ï¼š:]\s*(â˜…+|â˜†+|â—+|â—‹+|â—¯+)',  # è¨˜å·ã‚¹ã‚³ã‚¢
        ]
        
        scores = {}
        for pattern in score_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                engine_raw = match.group(1)
                engine = self._normalize_engine_name(engine_raw)
                if engine:
                    # ã‚¹ã‚³ã‚¢ã®ç°¡æ˜“è©•ä¾¡
                    score_text = match.group(2)
                    if score_text.isdigit():
                        scores[engine] = int(score_text)
                    else:
                        # è¨˜å·ã®æ•°ã‚’ã‚¹ã‚³ã‚¢ã¨ã—ã¦ä½¿ç”¨
                        scores[engine] = len(score_text)
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚¨ãƒ³ã‚¸ãƒ³ã‚’è¿”ã™
        if scores:
            return max(scores, key=scores.get)
        
        return None
    
    def analyze_recommendation_vs_choice(self, 
                                       recommended: str, 
                                       actual_choice: str,
                                       session_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æ¨å¥¨vså®Ÿé¸æŠã®ä¹–é›¢åˆ†æ
        
        Args:
            recommended: Geminiæ¨å¥¨ã®ã‚¨ãƒ³ã‚¸ãƒ³
            actual_choice: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿéš›ã®é¸æŠ
            session_context: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            ä¹–é›¢åˆ†æçµæœ
        """
        analysis = {
            'recommended': recommended,
            'actual_choice': actual_choice,
            'followed_recommendation': recommended == actual_choice,
            'divergence_type': None,
            'potential_reasons': [],
            'confidence': 0.0,
            'timestamp': datetime.now().isoformat()
        }
        
        if recommended == actual_choice:
            analysis['divergence_type'] = 'aligned'
            analysis['confidence'] = 1.0
        else:
            analysis['divergence_type'] = 'diverged'
            
            # ä¹–é›¢ç†ç”±ã®æ¨å®š
            if session_context:
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ç†ç”±æ¨å®š
                if session_context.get('text_length', 0) > 500:
                    analysis['potential_reasons'].append('long_text_preference')
                    
                if session_context.get('has_technical_terms'):
                    analysis['potential_reasons'].append('technical_accuracy_priority')
                    
                if session_context.get('previous_choices', {}).get(actual_choice, 0) > 2:
                    analysis['potential_reasons'].append('engine_familiarity')
            
            # ä¸€èˆ¬çš„ãªä¹–é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³
            if recommended == 'gemini' and actual_choice == 'chatgpt':
                analysis['potential_reasons'].append('prefer_traditional_style')
            elif recommended == 'chatgpt' and actual_choice == 'gemini':
                analysis['potential_reasons'].append('prefer_modern_style')
            elif actual_choice == 'enhanced':
                analysis['potential_reasons'].append('prefer_contextual_enhancement')
        
        # åˆ†æå±¥æ­´ã«è¿½åŠ 
        self.analysis_history.append(analysis)
        
        return analysis
    
    def detect_preference_patterns(self, user_data: List[Dict]) -> Dict[str, Any]:
        """
        å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆå¾ªç’°åˆ†æã‚’å›é¿ï¼‰
        
        Args:
            user_data: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠå±¥æ­´ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            æ¤œå‡ºã•ã‚ŒãŸé¸å¥½ãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        patterns = {
            'engine_preferences': Counter(),
            'divergence_patterns': Counter(),
            'context_based_choices': defaultdict(Counter),
            'temporal_trends': [],
            'personalization_insights': []
        }
        
        # ã‚¨ãƒ³ã‚¸ãƒ³é¸å¥½ã®é›†è¨ˆ
        for data in user_data:
            choice = data.get('actual_choice')
            if choice:
                patterns['engine_preferences'][choice] += 1
            
            # ä¹–é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†è¨ˆ
            if data.get('followed_recommendation') is False:
                reasons = data.get('potential_reasons', [])
                for reason in reasons:
                    patterns['divergence_patterns'][reason] += 1
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¸æŠã®é›†è¨ˆ
            context = data.get('context_type', 'general')
            if choice:
                patterns['context_based_choices'][context][choice] += 1
        
        # å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®ç”Ÿæˆ
        total_choices = sum(patterns['engine_preferences'].values())
        if total_choices > 0:
            # æœ€é »ä½¿ç”¨ã‚¨ãƒ³ã‚¸ãƒ³
            top_engine = patterns['engine_preferences'].most_common(1)[0]
            preference_rate = (top_engine[1] / total_choices) * 100
            
            if preference_rate > 60:
                patterns['personalization_insights'].append(
                    f"Strong preference for {top_engine[0]} ({preference_rate:.1f}%)"
                )
            
            # æ¨å¥¨ã¸ã®å¾“é †åº¦
            aligned_count = sum(1 for d in user_data if d.get('followed_recommendation'))
            alignment_rate = (aligned_count / len(user_data)) * 100 if user_data else 0
            
            if alignment_rate < 40:
                patterns['personalization_insights'].append(
                    f"Independent decision maker (follows recommendations only {alignment_rate:.1f}%)"
                )
            elif alignment_rate > 80:
                patterns['personalization_insights'].append(
                    f"Trusts AI recommendations ({alignment_rate:.1f}% alignment)"
                )
        
        # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ¤œå‡º
        if len(user_data) >= 5:
            recent_choices = [d.get('actual_choice') for d in user_data[-5:]]
            recent_counter = Counter(recent_choices)
            if len(recent_counter) == 1:
                patterns['temporal_trends'].append(
                    f"Recent consistency: exclusively using {recent_choices[0]}"
                )
        
        return patterns
    
    def generate_personalization_report(self, user_id: str) -> Dict[str, Any]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥å€‹äººåŒ–ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            å€‹äººåŒ–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
        """
        # åˆ†æå±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        user_analyses = [a for a in self.analysis_history if a.get('user_id') == user_id]
        
        if not user_analyses:
            return {'error': 'No data available for user'}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        patterns = self.detect_preference_patterns(user_analyses)
        
        report = {
            'user_id': user_id,
            'total_translations': len(user_analyses),
            'preference_patterns': patterns,
            'recommendation_alignment': {
                'followed': sum(1 for a in user_analyses if a.get('followed_recommendation')),
                'diverged': sum(1 for a in user_analyses if not a.get('followed_recommendation'))
            },
            'personalization_ready': len(user_analyses) >= 10,  # 10å›ä»¥ä¸Šã§å€‹äººåŒ–å¯èƒ½
            'generated_at': datetime.now().isoformat()
        }
        
        return report


# ğŸš€ Phase A-8 ç·åˆãƒ†ã‚¹ãƒˆé–¢æ•°
def test_phase_a8_openai_v1_system():
    """ğŸš€ Phase A-8: OpenAI v1.xå®Œå…¨å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ ã®ç·åˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ Phase A-8: OpenAI v1.xå®Œå…¨å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ  - ç·åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 80)
    
    analyzer = GeminiRecommendationAnalyzer()
    
    # 1. APIã‚­ãƒ¼æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆPhase A-8ç‰ˆï¼‰
    print("ğŸ” Phase A-8: Step 1 - OpenAI APIã‚­ãƒ¼æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆv1.xå¯¾å¿œï¼‰")
    print("-" * 50)
    
    api_validation = analyzer.validate_openai_api_key()
    
    print(f"   APIã‚­ãƒ¼å­˜åœ¨: {api_validation['api_key_exists']}")
    print(f"   APIã‚­ãƒ¼å½¢å¼: {api_validation['api_key_format_valid']}")
    print(f"   APIæ¥ç¶šãƒ†ã‚¹ãƒˆ: {api_validation['api_connection_test']}")
    print(f"   ç·åˆåˆ¤å®š: {api_validation['is_valid']}")
    
    if api_validation['error_details']:
        print("   ğŸš¨ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
        for error in api_validation['error_details']:
            print(f"     - {error}")
    
    if api_validation['recommendations']:
        print("   ğŸ’¡ æ¨å¥¨äº‹é …:")
        for rec in api_validation['recommendations']:
            print(f"     - {rec}")
    
    # 2. OpenAI v1.xå¯¾å¿œæ¨å¥¨æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ§ª Phase A-8: Step 2 - OpenAI v1.xå¯¾å¿œæ¨å¥¨æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    test_cases = [
        {
            "name": "Enhanced Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹ï¼ˆPhase A-6æœ€é©åŒ–ï¼‰",
            "text": "åˆ†æçµæœ: Enhanced TranslationãŒæœ€ã‚‚é©åˆ‡ã§è‡ªç„¶ãªç¿»è¨³ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ååˆ†ã«è€ƒæ…®ã—ãŸå„ªç§€ãªç¿»è¨³ã§ã™ã€‚Enhanced Translationã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚",
            "expected": "enhanced"
        },
        {
            "name": "Gemini Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹",
            "text": "æ¯”è¼ƒåˆ†æã®çµæœã€Gemini TranslationãŒæœ€ã‚‚å‰µé€ æ€§ã«å¯Œã¿ã€è‡ªç„¶ãªè¡¨ç¾ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚æ–‡è„ˆç†è§£åº¦ã‚‚é«˜ãã€Gemini Translationã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            "expected": "gemini"
        },
        {
            "name": "ChatGPT Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹",
            "text": "ç·åˆçš„ãªè©•ä¾¡ã¨ã—ã¦ã€ChatGPT TranslationãŒæ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã®é¢ã§å„ªã‚Œã¦ã„ã¾ã™ã€‚åŸºæœ¬ç¿»è¨³ã¨ã—ã¦æœ€ã‚‚ä¿¡é ¼ã§ãã‚‹ãŸã‚ã€ChatGPT Translationã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            "expected": "chatgpt"
        },
        {
            "name": "æ˜ç¢ºãªæ¨å¥¨ãªã—ã‚±ãƒ¼ã‚¹",
            "text": "3ã¤ã®ç¿»è¨³ãã‚Œãã‚Œã«é•·æ‰€ã¨çŸ­æ‰€ãŒã‚ã‚Šã¾ã™ã€‚ã©ã®ç¿»è¨³ã‚‚ä¸€å®šã®å“è³ªã‚’æº€ãŸã—ã¦ãŠã‚Šã€æ˜ç¢ºãªå„ªåŠ£ã¯åˆ¤æ–­ã§ãã¾ã›ã‚“ã€‚åˆ©ç”¨ã‚·ãƒ¼ãƒ³ã«å¿œã˜ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚",
            "expected": "none"
        },
        {
            "name": "è¤‡é›‘æ··åœ¨ã‚±ãƒ¼ã‚¹ï¼ˆEnhancedæ¨å¥¨ï¼‰",
            "text": """
            ã€ç¿»è¨³æ¯”è¼ƒçµæœã€‘
            
            1. ChatGPT Translation: æ¨™æº–çš„ã§æ­£ç¢ºãªç¿»è¨³ã§ã™ã€‚
            2. Enhanced Translation: ã‚ˆã‚Šè‡ªç„¶ã§æµæš¢ãªç¿»è¨³ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆãç†è§£ã—ã¦ã„ã¾ã™ã€‚
            3. Gemini Translation: å‰µé€ çš„ã ãŒã€ã‚„ã‚„éåº¦ãªè¡¨ç¾ãŒã‚ã‚Šã¾ã™ã€‚
            
            ã€çµè«–ã€‘Enhanced TranslationãŒæœ€ã‚‚ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ãŠã‚Šã€æ¨å¥¨ã—ã¾ã™ã€‚
            """,
            "expected": "enhanced"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n  {i}. {case['name']}")
        print(f"     å…¥åŠ›: {case['text'][:100].replace(chr(10), ' ')}...")
        print(f"     æœŸå¾…: {case['expected']}")
        
        # ğŸš€ Phase A-6 LLMå®Œå…¨ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ ã§ãƒ†ã‚¹ãƒˆ
        recommendation, confidence, method = analyzer.enhanced_recommendation_extraction(case['text'], 'Japanese')
        
        print(f"     çµæœ: {recommendation}")
        print(f"     ä¿¡é ¼åº¦: {confidence}")
        print(f"     æ‰‹æ³•: {method}")
        
        # ğŸš€ Phase A-8 æˆåŠŸåˆ¤å®šï¼ˆOpenAI v1.xå¯¾å¿œï¼‰
        if method.startswith("llm_chatgpt_a8"):
            # OpenAI v1.xæˆåŠŸæ™‚
            success = recommendation == case['expected']
            print(f"     è©•ä¾¡: {'âœ… æˆåŠŸ (OpenAI v1.xå¯¾å¿œ)' if success else 'âŒ å¤±æ•— (LLMåˆ¤å®šãƒŸã‚¹)'}")
        elif method.startswith("llm_chatgpt_none_a8"):
            # OpenAI v1.x noneã®å ´åˆ
            success = case['expected'] == 'none'
            print(f"     è©•ä¾¡: {'âœ… æˆåŠŸ (OpenAI v1.x noneåˆ¤å®š)' if success else 'âŒ å¤±æ•— (noneåˆ¤å®šãƒŸã‚¹)'}")
        elif method.startswith("api_key_invalid_no_fallback"):
            # APIã‚­ãƒ¼ç„¡åŠ¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å»ƒæ­¢ï¼‰
            print(f"     è©•ä¾¡: âš ï¸ APIã‚­ãƒ¼ç„¡åŠ¹ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å»ƒæ­¢ã«ã‚ˆã‚Šå‡¦ç†çµ‚äº†)")
        else:
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
            print(f"     è©•ä¾¡: âŒ ã‚¨ãƒ©ãƒ¼ (method: {method})")
    
    # 3. APIã‚­ãƒ¼ç„¡åŠ¹æ™‚ã®å‹•ä½œãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ” Phase A-6: Step 3 - APIã‚­ãƒ¼ç„¡åŠ¹æ™‚å‹•ä½œãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    # ä¸€æ™‚çš„ã«APIã‚­ãƒ¼ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãƒ†ã‚¹ãƒˆ
    original_api_key = os.getenv("OPENAI_API_KEY")
    os.environ["OPENAI_API_KEY"] = "invalid_key"
    
    try:
        test_text = "Enhanced Translationã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        recommendation, confidence, method = analyzer.enhanced_recommendation_extraction(test_text, 'Japanese')
        
        print(f"   APIã‚­ãƒ¼ç„¡åŠ¹æ™‚ã®çµæœ: {recommendation}")
        print(f"   ä¿¡é ¼åº¦: {confidence}")
        print(f"   æ‰‹æ³•: {method}")
        
        if method == "api_key_invalid_no_fallback":
            print("   è©•ä¾¡: âœ… æ­£å¸¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å»ƒæ­¢ã«ã‚ˆã‚Šé©åˆ‡ã«å¤±æ•—ï¼‰")
        else:
            print("   è©•ä¾¡: âŒ ç•°å¸¸ï¼ˆäºˆæœŸã—ãªã„å‹•ä½œï¼‰")
            
    finally:
        # APIã‚­ãƒ¼ã‚’å¾©å…ƒ
        if original_api_key:
            os.environ["OPENAI_API_KEY"] = original_api_key
        else:
            os.environ.pop("OPENAI_API_KEY", None)
    
    # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    print(f"\nâš¡ Phase A-6: Step 4 - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    long_analysis_text = "\n".join([
        f"Line {i}: ã“ã®è¡Œã¯é•·ã„Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚" 
        for i in range(1, 30)
    ]) + "\n\nã€æœ€çµ‚çµè«–ã€‘Enhanced TranslationãŒæœ€ã‚‚å„ªç§€ã§ã€æ¨å¥¨ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ãŒå„ªã‚Œã¦ã„ã¾ã™ã€‚"
    
    original_length = len(long_analysis_text)
    tail_text = analyzer.get_analysis_tail(long_analysis_text, 10)
    optimized_length = len(tail_text)
    
    print(f"   å…ƒãƒ†ã‚­ã‚¹ãƒˆé•·: {original_length} æ–‡å­—")
    print(f"   æœ€é©åŒ–å¾Œé•·: {optimized_length} æ–‡å­—")
    print(f"   ã‚³ã‚¹ãƒˆå‰Šæ¸›ç‡: {((original_length - optimized_length) / original_length * 100):.1f}%")
    
    # æœ€é©åŒ–å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã§æ¨å¥¨æŠ½å‡ºãƒ†ã‚¹ãƒˆ
    import time
    start_time = time.time()
    recommendation, confidence, method = analyzer.enhanced_recommendation_extraction(long_analysis_text, 'Japanese')
    processing_time = time.time() - start_time
    
    print(f"   æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆã§ã®æ¨å¥¨: {recommendation}")
    print(f"   ä¿¡é ¼åº¦: {confidence}")
    print(f"   å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
    
    # 5. ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
    print(f"\nğŸ“Š Phase A-6: Step 5 - ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ")
    print("-" * 50)
    
    print("   ç’°å¢ƒå¤‰æ•°ç¢ºèª:")
    openai_key_exists = bool(os.getenv("OPENAI_API_KEY"))
    print(f"     - OPENAI_API_KEY: {'è¨­å®šæ¸ˆã¿' if openai_key_exists else 'æœªè¨­å®š'}")
    
    if openai_key_exists:
        api_key = os.getenv("OPENAI_API_KEY")
        print(f"     - ã‚­ãƒ¼é•·: {len(api_key)} æ–‡å­—")
        print(f"     - å½¢å¼ãƒã‚§ãƒƒã‚¯: {'OK' if api_key.startswith('sk-') else 'NG'}")
    
    print(f"\n   Phase A-8 ã‚·ã‚¹ãƒ†ãƒ ç‰¹å¾´:")
    print(f"     - ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°: å®Œå…¨å»ƒæ­¢ âœ…")
    print(f"     - LLMä¾å­˜åº¦: 100%")
    print(f"     - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å»ƒæ­¢")
    print(f"     - OpenAI v1.xå¯¾å¿œ: å®Œå…¨å®Ÿè£… âœ…")
    print(f"     - APIã‚­ãƒ¼æ¤œè¨¼: v1.xå¯¾å¿œå¼·åŒ–æ¸ˆã¿")
    print(f"     - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: å®Ÿè£…æ¸ˆã¿")
    
    print("\nâœ… Phase A-8 OpenAI v1.xå®Œå…¨å¯¾å¿œãƒ†ã‚¹ãƒˆå®Œäº†")
    print("ğŸš€ OpenAI v1.xäº’æ›æ€§ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§å‘ä¸Šã‚’æœŸå¾…")
    print("=" * 80)

# Phase A-4 ãƒ†ã‚¹ãƒˆé–¢æ•°ï¼ˆäº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
def test_phase_a4_system():
    """ğŸ¤– Phase A-4: LLMãƒ™ãƒ¼ã‚¹æ¨å¥¨æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ¤– Phase A-4: LLMãƒ™ãƒ¼ã‚¹æ¨å¥¨æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ  - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    
    analyzer = GeminiRecommendationAnalyzer()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®ã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "name": "Enhanced Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹",
            "text": "2. Enhanced Translation ã®ã€Œla volontÃ© d'Apple de ne pas prendre de retardã€ã¯ã€Appleã®æˆ¦ç•¥çš„ãªæ„å›³ã‚’çš„ç¢ºã«è¡¨ç¾ã—ã¦ã„ã¾ã™ã€‚Enhanced TranslationãŒæœ€ã‚‚é©åˆ‡ã§ã™ã€‚",
            "expected": "enhanced"
        },
        {
            "name": "Gemini Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹", 
            "text": "åˆ†æã®çµæœã€Gemini Translationã‚’æ¨å¥¨ã—ã¾ã™ã€‚è‡ªç„¶ãªè¡¨ç¾ã¨æ–‡è„ˆç†è§£ãŒå„ªã‚Œã¦ã„ã¾ã™ã€‚",
            "expected": "gemini"
        },
        {
            "name": "ChatGPT Translationæ¨å¥¨ã‚±ãƒ¼ã‚¹",
            "text": "ç·åˆçš„ã«åˆ¤æ–­ã™ã‚‹ã¨ã€ChatGPT TranslationãŒæœ€ã‚‚æ­£ç¢ºã§é©åˆ‡ãªç¿»è¨³ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚",
            "expected": "chatgpt"
        },
        {
            "name": "æ˜ç¢ºãªæ¨å¥¨ãªã—ã‚±ãƒ¼ã‚¹",
            "text": "å„ç¿»è¨³ã«ã¯ãã‚Œãã‚Œé•·æ‰€ã¨çŸ­æ‰€ãŒã‚ã‚Šã¾ã™ã€‚ã©ã‚Œã‚‚ä¸€é•·ä¸€çŸ­ã§ã™ã€‚",
            "expected": "none"
        }
    ]
    
    print("ğŸ§ª LLMãƒ™ãƒ¼ã‚¹æ¨å¥¨æŠ½å‡ºãƒ†ã‚¹ãƒˆ:")
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{i}. {case['name']}")
        print(f"   å…¥åŠ›: {case['text'][:80]}...")
        print(f"   æœŸå¾…: {case['expected']}")
        
        # Phase A-4 ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ†ã‚¹ãƒˆ
        recommendation, confidence, method = analyzer.enhanced_recommendation_extraction(case['text'], 'Japanese')
        
        print(f"   çµæœ: {recommendation} (ä¿¡é ¼åº¦: {confidence}, æ‰‹æ³•: {method})")
        
        if recommendation == case['expected']:
            print("   âœ… æˆåŠŸ")
        else:
            print("   âŒ å¤±æ•—")
    
    # ã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ’° ã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆ:")
    long_text = "\n".join([f"Line {i}: ã“ã®è¡Œã¯é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚" for i in range(1, 21)])
    tail = analyzer.get_analysis_tail(long_text, 10)
    print(f"   å…ƒãƒ†ã‚­ã‚¹ãƒˆ: {long_text.count(chr(10))}è¡Œ")
    print(f"   æœ€é©åŒ–å¾Œ: {tail.count(chr(10)) + 1}è¡Œ") 
    print(f"   ã‚³ã‚¹ãƒˆå‰Šæ¸›: {((len(long_text) - len(tail)) / len(long_text) * 100):.1f}%")
    
    print("\nâœ… Phase A-4 ãƒ†ã‚¹ãƒˆå®Œäº†")

# ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
if __name__ == "__main__":
    # ğŸš€ Phase A-8: OpenAI v1.xå®Œå…¨å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
    test_phase_a8_openai_v1_system()
    
    print("\n" + "=" * 80)
    print("ğŸ¤– Phase A-4: å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆï¼ˆå‚è€ƒï¼‰")
    print("=" * 80)
    
    # Phase A-4 ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆï¼ˆå‚è€ƒç”¨ï¼‰
    test_phase_a4_system()
    
    print("\n" + "=" * 80)
    print("ğŸ¯ å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ  - åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 80)
    
    analyzer = GeminiRecommendationAnalyzer()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: æ¨å¥¨æŠ½å‡ºãƒ†ã‚¹ãƒˆ
    test_texts = [
        "3ã¤ã®ç¿»è¨³ã‚’æ¯”è¼ƒã—ãŸçµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚è‡ªç„¶ã§é©åˆ‡ã§ã™ã€‚",
        "ChatGPT: â˜…â˜…â˜…â˜†â˜†\nEnhanced: â˜…â˜…â˜…â˜…â˜…\nGemini: â˜…â˜…â˜…â˜…â˜†\nç·åˆçš„ã«Enhancedã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
        "ç¿»è¨³ã®ç²¾åº¦ã¨è‡ªç„¶ã•ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€GeminiãŒä¸€ç•ªãŠã™ã™ã‚ã§ã™ã€‚",
        "1st: Gemini (æœ€ã‚‚æ–‡è„ˆã«é©åˆ)\n2nd: Enhanced\n3rd: ChatGPT"
    ]
    
    print("ğŸ“ æ¨å¥¨æŠ½å‡ºãƒ†ã‚¹ãƒˆ:")
    for i, text in enumerate(test_texts, 1):
        recommendation = analyzer.extract_gemini_recommendation(text)
        print(f"{i}. å…¥åŠ›: {text[:50]}...")
        print(f"   æ¨å¥¨: {recommendation}\n")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: æ¨å¥¨vsé¸æŠåˆ†æ
    print("\nğŸ” æ¨å¥¨vsé¸æŠåˆ†æãƒ†ã‚¹ãƒˆ:")
    test_analysis = analyzer.analyze_recommendation_vs_choice(
        recommended='enhanced',
        actual_choice='gemini',
        session_context={
            'text_length': 600,
            'has_technical_terms': True,
            'previous_choices': {'gemini': 3}
        }
    )
    print(f"åˆ†æçµæœ: {json.dumps(test_analysis, indent=2, ensure_ascii=False)}")
    
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")