#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ§ª Task 2.9.1.5 çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
=====================================
ç›®çš„: åŒ…æ‹¬çš„è¡Œå‹•è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ã®ç·Šæ€¥æ”¹å–„å¯¾å¿œã®
     å…¨æ©Ÿèƒ½ã‚’çµ±åˆçš„ã«ãƒ†ã‚¹ãƒˆã™ã‚‹
"""

import os
import sys
import json
import sqlite3
import time
from datetime import datetime
import unittest
from unittest.mock import patch, MagicMock

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# æ”¹å–„ç‰ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from gemini_recommendation_analyzer import GeminiRecommendationAnalyzer
from enhanced_satisfaction_estimator import (
    EnhancedSatisfactionEstimator,
    EnhancedBehaviorMetrics,
    OPTIMIZED_WEIGHTS
)
from satisfaction_estimator import SatisfactionEstimator


class TestTask291_5Integration(unittest.TestCase):
    """Task 2.9.1.5 çµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.test_db = "test_task_2_9_1_5.db"
        self.analyzer = GeminiRecommendationAnalyzer()
        self.enhanced_estimator = EnhancedSatisfactionEstimator(
            analytics_db_path=self.test_db
        )
        self.original_estimator = SatisfactionEstimator(
            analytics_db_path=self.test_db
        )
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        self._setup_test_database()
    
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if os.path.exists(self.test_db):
            os.remove(self.test_db)
    
    def _setup_test_database(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        with sqlite3.connect(self.test_db) as conn:
            cursor = conn.cursor()
            
            # analytics_eventsãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analytics_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    event_id TEXT UNIQUE NOT NULL,
                    event_type VARCHAR(50) NOT NULL,
                    timestamp INTEGER NOT NULL,
                    session_id VARCHAR(50),
                    ip_address VARCHAR(45),
                    user_agent TEXT,
                    custom_data TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥
            test_session_id = "test_session_2915"
            base_time = int(time.time() * 1000)
            
            test_events = [
                # ãƒ†ã‚­ã‚¹ãƒˆé¸æŠã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
                {
                    'event_type': 'text_selection',
                    'timestamp': base_time - 180000,
                    'custom_data': {
                        'selected_text': 'This is a selected phrase',
                        'selection_length': 24,
                        'selection_start': 10,
                        'selection_end': 34
                    }
                },
                {
                    'event_type': 'text_selection',
                    'timestamp': base_time - 175000,
                    'custom_data': {
                        'selected_text': 'Another important paragraph selection that is quite long',
                        'selection_length': 55,
                        'selection_start': 100,
                        'selection_end': 155
                    }
                },
                # CTAã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
                {
                    'event_type': 'cta_click',
                    'timestamp': base_time - 170000,
                    'custom_data': {
                        'button_id': 'try_now_button',
                        'page_section': 'hero'
                    }
                },
                {
                    'event_type': 'cta_click',
                    'timestamp': base_time - 160000,
                    'custom_data': {
                        'button_id': 'learn_more_button',
                        'page_section': 'features'
                    }
                },
                # æ—¢å­˜ã®ç¿»è¨³ã‚³ãƒ”ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
                {
                    'event_type': 'translation_copy',
                    'timestamp': base_time - 150000,
                    'custom_data': {
                        'translation_type': 'enhanced',
                        'copy_method': 'button_click',
                        'text_length': 150,
                        'user_choice_vs_recommendation': 'followed_recommendation'
                    }
                },
                # ãƒšãƒ¼ã‚¸æ»åœ¨æ™‚é–“ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
                {
                    'event_type': 'time_on_page',
                    'timestamp': base_time - 140000,
                    'custom_data': {
                        'page_url': '/translate',
                        'time_spent': 120.5
                    }
                },
                # ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼
                {
                    'event_type': 'page_view',
                    'timestamp': base_time - 200000,
                    'custom_data': {
                        'page_title': 'Translation Test'
                    }
                },
                # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ·±åº¦
                {
                    'event_type': 'scroll_depth',
                    'timestamp': base_time - 130000,
                    'custom_data': {
                        'scroll_percentage': 85
                    }
                }
            ]
            
            for i, event in enumerate(test_events):
                event_id = f"test_event_{test_session_id}_{i}"
                cursor.execute('''
                    INSERT INTO analytics_events (
                        event_id, event_type, timestamp, session_id,
                        ip_address, user_agent, custom_data
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    event_id,
                    event['event_type'],
                    event['timestamp'],
                    test_session_id,
                    '127.0.0.1',
                    'TestAgent/1.0',
                    json.dumps(event['custom_data'])
                ))
            
            conn.commit()
    
    def test_gemini_recommendation_extraction(self):
        """Geminiæ¨å¥¨æŠ½å‡ºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 1: Geminiæ¨å¥¨æŠ½å‡ºæ©Ÿèƒ½")
        
        test_cases = [
            {
                'text': "3ã¤ã®ç¿»è¨³ã‚’æ¯”è¼ƒã—ãŸçµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚è‡ªç„¶ã§é©åˆ‡ã§ã™ã€‚",
                'expected': 'enhanced'
            },
            {
                'text': "ç·åˆçš„ã«åˆ¤æ–­ã™ã‚‹ã¨ã€Geminiç¿»è¨³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                'expected': 'gemini'
            },
            {
                'text': "ChatGPT: â˜…â˜…â˜…â˜†â˜†\nEnhanced: â˜…â˜…â˜…â˜…â˜…\nGemini: â˜…â˜…â˜…â˜…â˜†",
                'expected': 'enhanced'
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            result = self.analyzer.extract_gemini_recommendation(test_case['text'])
            self.assertEqual(result, test_case['expected'], 
                           f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹{i}ã§æ¨å¥¨æŠ½å‡ºãŒå¤±æ•—")
            print(f"  âœ… ã‚±ãƒ¼ã‚¹{i}: {test_case['expected']}ã‚’æ­£ã—ãæŠ½å‡º")
    
    def test_recommendation_vs_choice_analysis(self):
        """æ¨å¥¨vså®Ÿé¸æŠåˆ†æãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 2: æ¨å¥¨vså®Ÿé¸æŠåˆ†æ")
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: æ¨å¥¨ã«å¾“ã£ãŸå ´åˆ
        analysis1 = self.analyzer.analyze_recommendation_vs_choice(
            recommended='enhanced',
            actual_choice='enhanced',
            session_context={'text_length': 200}
        )
        
        self.assertTrue(analysis1['followed_recommendation'])
        self.assertEqual(analysis1['divergence_type'], 'aligned')
        print("  âœ… æ¨å¥¨ã«å¾“ã£ãŸå ´åˆã®åˆ†æ: æ­£å¸¸")
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: æ¨å¥¨ã‹ã‚‰é€¸è„±ã—ãŸå ´åˆ
        analysis2 = self.analyzer.analyze_recommendation_vs_choice(
            recommended='enhanced',
            actual_choice='gemini',
            session_context={
                'text_length': 600,
                'has_technical_terms': True
            }
        )
        
        self.assertFalse(analysis2['followed_recommendation'])
        self.assertEqual(analysis2['divergence_type'], 'diverged')
        self.assertIn('long_text_preference', analysis2['potential_reasons'])
        print("  âœ… æ¨å¥¨ã‹ã‚‰é€¸è„±ã—ãŸå ´åˆã®åˆ†æ: æ­£å¸¸")
    
    def test_enhanced_satisfaction_calculation(self):
        """æ”¹å–„ç‰ˆæº€è¶³åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 3: æ”¹å–„ç‰ˆæº€è¶³åº¦è¨ˆç®—")
        
        # ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã®æº€è¶³åº¦è¨ˆç®—
        result = self.enhanced_estimator.calculate_satisfaction(
            session_id="test_session_2915",
            user_id="test_user"
        )
        
        self.assertNotIn('error', result)
        self.assertGreater(result['satisfaction_score'], 0)
        
        print(f"  ğŸ“Š ç·åˆæº€è¶³åº¦: {result['satisfaction_score']}/100")
        print(f"  ğŸ“Š ã‚³ãƒ”ãƒ¼è¡Œå‹•: {result['copy_behavior_score']}/100")
        print(f"  ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆæ“ä½œ: {result['text_interaction_score']}/100")
        print(f"  ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³è¡Œå‹•: {result['session_pattern_score']}/100")
        print(f"  ğŸ“Š ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: {result['engagement_score']}/100")
        
        # é‡ã¿è¨­å®šã®ç¢ºèª
        self.assertEqual(result['weights_used'], OPTIMIZED_WEIGHTS)
        print("  âœ… æœ€é©åŒ–ã•ã‚ŒãŸé‡ã¿ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã™")
    
    def test_no_more_fixed_scores(self):
        """50ç‚¹å›ºå®šå•é¡Œè§£æ±ºç¢ºèªãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 4: 50ç‚¹å›ºå®šå•é¡Œã®è§£æ±ºç¢ºèª")
        
        # ç•°ãªã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        with sqlite3.connect(self.test_db) as conn:
            cursor = conn.cursor()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³1: ãƒ†ã‚­ã‚¹ãƒˆé¸æŠãªã—
            session1_id = "test_no_text_selection"
            cursor.execute('''
                INSERT INTO analytics_events (
                    event_id, event_type, timestamp, session_id,
                    ip_address, user_agent, custom_data
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                f"test_event_{session1_id}_1",
                'page_view',
                int(time.time() * 1000),
                session1_id,
                '127.0.0.1',
                'TestAgent/1.0',
                '{}'
            ))
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³2: å¤šæ•°ã®ãƒ†ã‚­ã‚¹ãƒˆé¸æŠ
            session2_id = "test_many_text_selections"
            base_time = int(time.time() * 1000)
            for i in range(5):
                cursor.execute('''
                    INSERT INTO analytics_events (
                        event_id, event_type, timestamp, session_id,
                        ip_address, user_agent, custom_data
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    f"test_event_{session2_id}_{i}",
                    'text_selection',
                    base_time - (i * 1000),
                    session2_id,
                    '127.0.0.1',
                    'TestAgent/1.0',
                    json.dumps({
                        'selected_text': f'Selection {i}',
                        'selection_length': 20 + i * 10
                    })
                ))
            
            conn.commit()
        
        # ä¸¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§æº€è¶³åº¦è¨ˆç®—
        result1 = self.enhanced_estimator.calculate_satisfaction(session1_id)
        result2 = self.enhanced_estimator.calculate_satisfaction(session2_id)
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ“ä½œã‚¹ã‚³ã‚¢ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        self.assertNotEqual(result1['text_interaction_score'], 
                          result2['text_interaction_score'])
        self.assertNotEqual(result1['text_interaction_score'], 50.0)
        self.assertNotEqual(result2['text_interaction_score'], 50.0)
        
        print(f"  âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³1ã®ãƒ†ã‚­ã‚¹ãƒˆæ“ä½œã‚¹ã‚³ã‚¢: {result1['text_interaction_score']}")
        print(f"  âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³2ã®ãƒ†ã‚­ã‚¹ãƒˆæ“ä½œã‚¹ã‚³ã‚¢: {result2['text_interaction_score']}")
        print("  âœ… 50ç‚¹å›ºå®šå•é¡Œã¯è§£æ±ºã•ã‚Œã¾ã—ãŸï¼")
    
    def test_individual_preference_patterns(self):
        """çœŸã®å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 5: çœŸã®å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        
        # ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠå±¥æ­´ãƒ‡ãƒ¼ã‚¿
        user_data = [
            {
                'actual_choice': 'gemini',
                'followed_recommendation': False,
                'potential_reasons': ['prefer_modern_style'],
                'context_type': 'technical'
            },
            {
                'actual_choice': 'gemini',
                'followed_recommendation': True,
                'context_type': 'technical'
            },
            {
                'actual_choice': 'enhanced',
                'followed_recommendation': False,
                'potential_reasons': ['prefer_contextual_enhancement'],
                'context_type': 'casual'
            },
            {
                'actual_choice': 'gemini',
                'followed_recommendation': True,
                'context_type': 'business'
            },
            {
                'actual_choice': 'gemini',
                'followed_recommendation': True,
                'context_type': 'technical'
            }
        ]
        
        patterns = self.analyzer.detect_preference_patterns(user_data)
        
        # ã‚¨ãƒ³ã‚¸ãƒ³é¸å¥½ã®ç¢ºèª
        self.assertEqual(patterns['engine_preferences']['gemini'], 4)
        self.assertEqual(patterns['engine_preferences']['enhanced'], 1)
        
        # å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®ç¢ºèª
        self.assertGreater(len(patterns['personalization_insights']), 0)
        
        print("  ğŸ“Š ã‚¨ãƒ³ã‚¸ãƒ³é¸å¥½:")
        for engine, count in patterns['engine_preferences'].items():
            percentage = (count / len(user_data)) * 100
            print(f"    - {engine}: {count}å› ({percentage:.0f}%)")
        
        print("  ğŸ’¡ å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆ:")
        for insight in patterns['personalization_insights']:
            print(f"    - {insight}")
        
        print("  âœ… çœŸã®å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
    
    def test_system_integration(self):
        """å…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Test 6: å…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå‹•ä½œç¢ºèª")
        
        # 1. Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¨å¥¨æŠ½å‡º
        gemini_analysis = "è©³ç´°ãªåˆ†æã®çµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚æ–‡è„ˆã«é©ã—ã¦ã„ã¾ã™ã€‚"
        recommendation = self.analyzer.extract_gemini_recommendation(gemini_analysis)
        self.assertEqual(recommendation, 'enhanced')
        print("  âœ… Step 1: Geminiæ¨å¥¨æŠ½å‡ºå®Œäº†")
        
        # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿé¸æŠã¨æ¯”è¼ƒåˆ†æ
        actual_choice = 'gemini'  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ¨å¥¨ã¨ç•°ãªã‚‹é¸æŠ
        analysis = self.analyzer.analyze_recommendation_vs_choice(
            recommended=recommendation,
            actual_choice=actual_choice
        )
        self.assertFalse(analysis['followed_recommendation'])
        print("  âœ… Step 2: æ¨å¥¨vså®Ÿé¸æŠåˆ†æå®Œäº†")
        
        # 3. æ”¹å–„ç‰ˆæº€è¶³åº¦è¨ˆç®—
        satisfaction = self.enhanced_estimator.calculate_satisfaction(
            session_id="test_session_2915"
        )
        self.assertGreater(satisfaction['satisfaction_score'], 0)
        print(f"  âœ… Step 3: æº€è¶³åº¦è¨ˆç®—å®Œäº† ({satisfaction['satisfaction_score']}/100)")
        
        # 4. æ”¹å–„ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        insights = self.enhanced_estimator.generate_improvement_insights(
            "test_session_2915"
        )
        print("  âœ… Step 4: æ”¹å–„ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆå®Œäº†")
        
        print("\nğŸ‰ å…¨ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«çµ±åˆå‹•ä½œã—ã¦ã„ã¾ã™ï¼")


def run_comprehensive_tests():
    """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("=" * 60)
    print("ğŸ§ª Task 2.9.1.5 çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®ä½œæˆã¨å®Ÿè¡Œ
    suite = unittest.TestLoader().loadTestsFromTestCase(TestTask291_5Integration)
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±æ•—: {len(result.failures)}")
    print(f"ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    
    if result.wasSuccessful():
        print("\nâœ… å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼ï¼Task 2.9.1.5ã®å®Ÿè£…ã¯å®Œå…¨ã§ã™ã€‚")
        print("ğŸš€ Task 2.9.2ã¸ã®ç§»è¡Œæº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚")
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•— - ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_comprehensive_tests()
    sys.exit(0 if success else 1)