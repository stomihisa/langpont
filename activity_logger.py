#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Task 2.9.2 Phase B-3.5.10: Comprehensive Activity Logging System
LangPont çµ±åˆæ´»å‹•å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

å…¨ã¦ã®åˆ†ææ´»å‹•ï¼ˆé€šå¸¸åˆ©ç”¨ãƒ»æ‰‹å‹•ãƒ†ã‚¹ãƒˆãƒ»è‡ªå‹•ãƒ†ã‚¹ãƒˆï¼‰ã‚’çµ±ä¸€çš„ã«è¨˜éŒ²ãƒ»ç®¡ç†
"""

import sqlite3
import json
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, Optional, List
import os
import logging

# ğŸ—¾ JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å®šç¾©
JST = timezone(timedelta(hours=9))

def get_jst_now():
    """æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—"""
    return datetime.now(JST)

def get_jst_today():
    """æ—¥æœ¬æ™‚é–“ã§ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—"""
    return get_jst_now().date()

class ActivityLogger:
    """LangPontçµ±åˆæ´»å‹•ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = "langpont_activity_log.db"):
        self.db_path = db_path
        
        # ãƒ­ã‚°è¨­å®šã‚’æœ€åˆã«è¡Œã†ï¼ˆinit_databaseå‰ã«å¿…è¦ï¼‰
        self.setup_logger()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_database()
    
    def setup_logger(self):
        """ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # çµ±åˆæ´»å‹•ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS analysis_activity_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                
                -- æ´»å‹•åˆ†é¡
                activity_type TEXT NOT NULL,              -- 'normal_use' | 'manual_test' | 'automated_test'
                session_id TEXT,                          -- ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
                user_id TEXT,                             -- ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆadmin/developer/guestç­‰ï¼‰
                
                -- ãƒ†ã‚¹ãƒˆé–¢é€£ï¼ˆè‡ªå‹•ãƒ†ã‚¹ãƒˆã®å ´åˆï¼‰
                test_session_id TEXT,                     -- ãƒãƒƒãƒãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ID
                test_number INTEGER,                      -- ãƒ†ã‚¹ãƒˆç•ªå·
                sample_id INTEGER,                        -- ã‚µãƒ³ãƒ—ãƒ«ID
                sample_name TEXT,                         -- ã‚µãƒ³ãƒ—ãƒ«å
                
                -- å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
                japanese_text TEXT,                       -- æ—¥æœ¬èªåŸæ–‡
                target_language TEXT DEFAULT 'en',       -- å¯¾è±¡è¨€èªï¼ˆen/fr/esï¼‰
                language_pair TEXT DEFAULT 'ja-en',      -- è¨€èªãƒšã‚¢
                partner_message TEXT,                     -- ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                context_info TEXT,                        -- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                
                -- ç¿»è¨³çµæœ
                chatgpt_translation TEXT,                 -- ChatGPTç¿»è¨³
                enhanced_translation TEXT,                -- Enhancedç¿»è¨³ï¼ˆæ”¹å–„ChatGPTï¼‰
                gemini_translation TEXT,                  -- Geminiç¿»è¨³
                
                -- åˆ†æå®Ÿè¡Œãƒ‡ãƒ¼ã‚¿
                button_pressed TEXT,                      -- æŠ¼ä¸‹ãƒœã‚¿ãƒ³ï¼ˆChatGPT/Gemini/Claudeï¼‰
                actual_analysis_llm TEXT,                 -- å®Ÿéš›åˆ†æLLM
                llm_match BOOLEAN,                        -- ãƒœã‚¿ãƒ³ã¨LLMã®ä¸€è‡´ãƒ•ãƒ©ã‚°
                
                -- åˆ†æçµæœ
                recommendation_result TEXT,               -- æ¨å¥¨çµæœï¼ˆEnhanced/ChatGPT/Geminiï¼‰
                confidence REAL,                          -- ä¿¡é ¼åº¦ï¼ˆ0.0-1.0ï¼‰
                processing_method TEXT,                   -- æ¨å¥¨æŠ½å‡ºæ–¹æ³•
                extraction_method TEXT,                   -- æŠ½å‡ºè©³ç´°æ–¹æ³•
                
                -- åˆ†æå†…å®¹
                full_analysis_text TEXT,                  -- ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹åˆ†æçµæœå…¨æ–‡
                analysis_preview TEXT,                    -- åˆ†æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆ200æ–‡å­—ï¼‰
                
                -- å®Ÿè¡Œãƒ­ã‚°
                terminal_logs TEXT,                       -- é–¢é€£ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ­ã‚°
                debug_logs TEXT,                          -- ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                error_occurred BOOLEAN DEFAULT 0,        -- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ•ãƒ©ã‚°
                error_message TEXT,                       -- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                
                -- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
                processing_duration REAL,                -- å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
                translation_duration REAL,               -- ç¿»è¨³å‡¦ç†æ™‚é–“
                analysis_duration REAL,                  -- åˆ†æå‡¦ç†æ™‚é–“
                
                -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                ip_address TEXT,                          -- IPã‚¢ãƒ‰ãƒ¬ã‚¹
                user_agent TEXT,                          -- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
                request_headers TEXT,                     -- ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆJSONï¼‰
                
                -- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                year INTEGER,                             -- å¹´ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                month INTEGER,                            -- æœˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                day INTEGER,                              -- æ—¥ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                hour INTEGER,                             -- æ™‚ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                
                -- è¿½åŠ ãƒ¡ãƒ¢
                notes TEXT,                               -- æ‰‹å‹•ãƒ¡ãƒ¢
                tags TEXT                                 -- ã‚¿ã‚°ï¼ˆJSONé…åˆ—ï¼‰
            )
        """)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_activity_type ON analysis_activity_log(activity_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_id ON analysis_activity_log(user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON analysis_activity_log(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_year_month ON analysis_activity_log(year, month)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_button_pressed ON analysis_activity_log(button_pressed)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_actual_llm ON analysis_activity_log(actual_analysis_llm)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_error_occurred ON analysis_activity_log(error_occurred)")
            
            # ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS test_samples (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    sample_name TEXT NOT NULL,
                    japanese_text TEXT NOT NULL,
                    category TEXT DEFAULT 'general',          -- 'technical', 'business', 'casual'
                    description TEXT,
                    expected_result TEXT,                      -- æœŸå¾…ã•ã‚Œã‚‹çµæœ
                    difficulty_level INTEGER DEFAULT 1,       -- é›£æ˜“åº¦ 1-5
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_by TEXT,
                    is_active BOOLEAN DEFAULT 1
                )
            """)
        
            conn.commit()
            conn.close()
            
            if hasattr(self, 'logger'):
                self.logger.info(f"âœ… Activity Logger database initialized: {self.db_path}")
            else:
                print(f"âœ… Activity Logger database initialized: {self.db_path}")
                
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ Failed to initialize database: {str(e)}")
            else:
                print(f"âŒ Failed to initialize database: {str(e)}")
            raise
    
    def log_activity(self, activity_data: Dict[str, Any]) -> int:
        """æ´»å‹•ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # JSTåŸºæº–ã®ç¾åœ¨æ™‚åˆ»ã®è©³ç´°æƒ…å ±
            now = get_jst_now()
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
            activity_data.setdefault('activity_type', 'normal_use')
            activity_data.setdefault('user_id', 'anonymous')
            activity_data.setdefault('error_occurred', False)
            
            # LLMä¸€è‡´åˆ¤å®š
            button_pressed = activity_data.get('button_pressed', '').lower()
            actual_llm = activity_data.get('actual_analysis_llm', '').lower()
            llm_match = button_pressed == actual_llm if button_pressed and actual_llm else None
            
            # åˆ†æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
            full_analysis = activity_data.get('full_analysis_text', '')
            analysis_preview = full_analysis[:200] + '...' if len(full_analysis) > 200 else full_analysis
            
            # SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            cursor.execute("""
                INSERT INTO analysis_activity_log (
                    activity_type, session_id, user_id,
                    test_session_id, test_number, sample_id, sample_name,
                    japanese_text, target_language, language_pair, partner_message, context_info,
                    chatgpt_translation, enhanced_translation, gemini_translation,
                    button_pressed, actual_analysis_llm, llm_match,
                    recommendation_result, confidence, processing_method, extraction_method,
                    full_analysis_text, analysis_preview,
                    terminal_logs, debug_logs, error_occurred, error_message,
                    processing_duration, translation_duration, analysis_duration,
                    ip_address, user_agent, request_headers,
                    year, month, day, hour,
                    notes, tags
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                activity_data.get('activity_type'),
                activity_data.get('session_id'),
                activity_data.get('user_id'),
                activity_data.get('test_session_id'),
                activity_data.get('test_number'),
                activity_data.get('sample_id'),
                activity_data.get('sample_name'),
                activity_data.get('japanese_text'),
                activity_data.get('target_language', 'en'),
                activity_data.get('language_pair', 'ja-en'),
                activity_data.get('partner_message'),
                activity_data.get('context_info'),
                activity_data.get('chatgpt_translation'),
                activity_data.get('enhanced_translation'),
                activity_data.get('gemini_translation'),
                activity_data.get('button_pressed'),
                activity_data.get('actual_analysis_llm'),
                llm_match,
                activity_data.get('recommendation_result'),
                activity_data.get('confidence'),
                activity_data.get('processing_method'),
                activity_data.get('extraction_method'),
                activity_data.get('full_analysis_text'),
                analysis_preview,
                activity_data.get('terminal_logs'),
                activity_data.get('debug_logs'),
                activity_data.get('error_occurred', False),
                activity_data.get('error_message'),
                activity_data.get('processing_duration'),
                activity_data.get('translation_duration'),
                activity_data.get('analysis_duration'),
                activity_data.get('ip_address'),
                activity_data.get('user_agent'),
                json.dumps(activity_data.get('request_headers', {})),
                now.year,
                now.month,
                now.day,
                now.hour,
                activity_data.get('notes'),
                json.dumps(activity_data.get('tags', []))
            ))
            
            log_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            self.logger.info(f"âœ… Activity logged: ID={log_id}, Type={activity_data.get('activity_type')}")
            return log_id
            
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ Failed to log activity: {str(e)}")
            else:
                print(f"âŒ Failed to log activity: {str(e)}")
            return -1
    
    def get_activity_stats(self, filters: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ´»å‹•çµ±è¨ˆã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
        where_clause, params = self._build_where_clause(filters or {})
        
        # JSTåŸºæº–ã®åŸºæœ¬çµ±è¨ˆ
        today_jst = get_jst_today().strftime('%Y-%m-%d')
        cursor.execute(f"""
            SELECT 
                COUNT(*) as total_activities,
                COUNT(CASE WHEN DATE(created_at, '+9 hours') = ? THEN 1 END) as today_activities,
                COUNT(CASE WHEN error_occurred = 1 THEN 1 END) as error_count,
                AVG(processing_duration) as avg_processing_time,
                COUNT(CASE WHEN llm_match = 1 THEN 1 END) as llm_match_count,
                COUNT(CASE WHEN llm_match = 0 THEN 1 END) as llm_mismatch_count
            FROM analysis_activity_log
            {where_clause}
        """, [today_jst] + params)
        
        basic_stats = cursor.fetchone()
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥çµ±è¨ˆ
        cursor.execute(f"""
            SELECT 
                button_pressed,
                COUNT(*) as count,
                AVG(confidence) as avg_confidence,
                AVG(processing_duration) as avg_duration
            FROM analysis_activity_log
            {where_clause}
            GROUP BY button_pressed
            ORDER BY count DESC
        """, params)
        
        engine_stats = cursor.fetchall()
        
        # æ¨å¥¨çµæœçµ±è¨ˆ
        cursor.execute(f"""
            SELECT 
                recommendation_result,
                COUNT(*) as count
            FROM analysis_activity_log
            {where_clause}
            GROUP BY recommendation_result
            ORDER BY count DESC
        """, params)
        
        recommendation_stats = cursor.fetchall()
        
        conn.close()
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
        stats = {
            'basic': {
                'total_activities': basic_stats[0] or 0,
                'today_activities': basic_stats[1] or 0,
                'today_translations': basic_stats[1] or 0,  # ç¿»è¨³æ•°ã¨ã—ã¦è¡¨ç¤º
                'error_count': basic_stats[2] or 0,
                'error_rate': round((basic_stats[2] or 0) / max(basic_stats[0] or 1, 1) * 100, 2),
                'avg_processing_time': round(basic_stats[3] or 0, 2),
                'llm_match_count': basic_stats[4] or 0,
                'llm_mismatch_count': basic_stats[5] or 0,
                'llm_match_rate': round((basic_stats[4] or 0) / max((basic_stats[4] or 0) + (basic_stats[5] or 0), 1) * 100, 2)
            },
            'engines': [
                {
                    'engine': row[0] or 'unknown',
                    'count': row[1],
                    'avg_confidence': round(row[2] or 0, 2),
                    'avg_duration': round(row[3] or 0, 2)
                }
                for row in engine_stats
            ],
            'recommendations': [
                {
                    'result': row[0] or 'unknown',
                    'count': row[1]
                }
                for row in recommendation_stats
            ]
        }
        
        return stats
    
    def get_activities(self, filters: Dict[str, Any] = None, limit: int = 50, offset: int = 0) -> List[Dict[str, Any]]:
        """æ´»å‹•ãƒ­ã‚°ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°å¯¾å¿œï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
        where_clause, params = self._build_where_clause(filters or {})
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        cursor.execute(f"""
            SELECT 
                id, activity_type, user_id, created_at,
                japanese_text, button_pressed, actual_analysis_llm, llm_match,
                recommendation_result, confidence, processing_duration,
                error_occurred, error_message,
                test_session_id, sample_name
            FROM analysis_activity_log
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, params + [limit, offset])
        
        rows = cursor.fetchall()
        
        # ç·ä»¶æ•°å–å¾—
        cursor.execute(f"""
            SELECT COUNT(*) FROM analysis_activity_log {where_clause}
        """, params)
        
        total_count = cursor.fetchone()[0]
        
        conn.close()
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
        activities = []
        for row in rows:
            activities.append({
                'id': row[0],
                'activity_type': row[1],
                'user_id': row[2],
                'created_at': row[3],
                'japanese_text': row[4][:50] + '...' if row[4] and len(row[4]) > 50 else row[4],
                'button_pressed': row[5],
                'actual_analysis_llm': row[6],
                'llm_match': row[7],
                'recommendation_result': row[8],
                'confidence': row[9],
                'processing_duration': row[10],
                'error_occurred': row[11],
                'error_message': row[12],
                'test_session_id': row[13],
                'sample_name': row[14]
            })
        
        return {
            'activities': activities,
            'total_count': total_count,
            'page_count': (total_count + limit - 1) // limit,
            'current_page': offset // limit + 1
        }
    
    def get_activity_detail(self, activity_id: int) -> Optional[Dict[str, Any]]:
        """æ´»å‹•è©³ç´°ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT * FROM analysis_activity_log WHERE id = ?
        """, (activity_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return None
        
        # ã‚«ãƒ©ãƒ åå–å¾—
        columns = [description[0] for description in cursor.description]
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
        detail = dict(zip(columns, row))
        
        # JSON ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‘ãƒ¼ã‚¹
        try:
            detail['request_headers'] = json.loads(detail['request_headers'] or '{}')
            detail['tags'] = json.loads(detail['tags'] or '[]')
        except:
            detail['request_headers'] = {}
            detail['tags'] = []
        
        return detail
    
    def _build_where_clause(self, filters: Dict[str, Any]) -> tuple:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‹ã‚‰WHEREå¥ã‚’æ§‹ç¯‰"""
        conditions = []
        params = []
        
        if filters.get('activity_type'):
            conditions.append("activity_type = ?")
            params.append(filters['activity_type'])
        
        if filters.get('user_id'):
            conditions.append("user_id = ?")
            params.append(filters['user_id'])
        
        if filters.get('button_pressed'):
            conditions.append("button_pressed = ?")
            params.append(filters['button_pressed'])
        
        if filters.get('date_from'):
            conditions.append("DATE(created_at) >= ?")
            params.append(filters['date_from'])
        
        if filters.get('date_to'):
            conditions.append("DATE(created_at) <= ?")
            params.append(filters['date_to'])
        
        if filters.get('error_only'):
            conditions.append("error_occurred = 1")
        
        if filters.get('llm_mismatch_only'):
            conditions.append("llm_match = 0")
        
        where_clause = "WHERE " + " AND ".join(conditions) if conditions else ""
        
        return where_clause, params

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
activity_logger = ActivityLogger()

def log_analysis_activity(activity_data: Dict[str, Any]) -> int:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ï¼šåˆ†ææ´»å‹•ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    return activity_logger.log_activity(activity_data)

# ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_activity = {
        'activity_type': 'normal_use',
        'user_id': 'test_user',
        'japanese_text': 'ãƒ†ã‚¹ãƒˆç”¨ã®æ—¥æœ¬èªæ–‡ç« ã§ã™ã€‚',
        'button_pressed': 'Claude',
        'actual_analysis_llm': 'Claude',
        'recommendation_result': 'Enhanced',
        'confidence': 0.85,
        'full_analysis_text': 'ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†æçµæœã§ã™ã€‚éå¸¸ã«è©³ç´°ãªåˆ†æå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚',
        'processing_duration': 2.5
    }
    
    # ãƒ­ã‚°è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    log_id = activity_logger.log_activity(test_activity)
    print(f"âœ… Test activity logged: ID={log_id}")
    
    # çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ
    stats = activity_logger.get_activity_stats()
    print(f"ğŸ“Š Stats: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    # æ´»å‹•ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ
    activities = activity_logger.get_activities(limit=5)
    print(f"ğŸ“‹ Activities: {len(activities['activities'])} items")
    
    print("âœ… Activity Logger test completed")