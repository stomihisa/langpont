#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Task 2.9.2 Phase B-3.5.10: Comprehensive Activity Logging System
LangPont çµ±åˆæ´»å‹•å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

å…¨ã¦ã®åˆ†ææ´»å‹•ï¼ˆé€šå¸¸åˆ©ç”¨ãƒ»æ‰‹å‹•ãƒ†ã‚¹ãƒˆãƒ»è‡ªå‹•ãƒ†ã‚¹ãƒˆï¼‰ã‚’çµ±ä¸€çš„ã«è¨˜éŒ²ãƒ»ç®¡ç†
"""

import sqlite3
import json
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, Optional, List
import os
import logging

# ğŸ—¾ JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å®šç¾©
JST = timezone(timedelta(hours=9))

def get_jst_now():
    """æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—"""
    return datetime.now(JST)

def get_jst_today():
    """æ—¥æœ¬æ™‚é–“ã§ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—"""
    return get_jst_now().date()

class ActivityLogger:
    """LangPontçµ±åˆæ´»å‹•ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = "langpont_activity_log.db"):
        self.db_path = db_path
        
        # ãƒ­ã‚°è¨­å®šã‚’æœ€åˆã«è¡Œã†ï¼ˆinit_databaseå‰ã«å¿…è¦ï¼‰
        self.setup_logger()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_database()
    
    def setup_logger(self):
        """ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # çµ±åˆæ´»å‹•ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS analysis_activity_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                
                -- æ´»å‹•åˆ†é¡
                activity_type TEXT NOT NULL,              -- 'normal_use' | 'manual_test' | 'automated_test'
                session_id TEXT,                          -- ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
                user_id TEXT,                             -- ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆadmin/developer/guestç­‰ï¼‰
                
                -- ãƒ†ã‚¹ãƒˆé–¢é€£ï¼ˆè‡ªå‹•ãƒ†ã‚¹ãƒˆã®å ´åˆï¼‰
                test_session_id TEXT,                     -- ãƒãƒƒãƒãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ID
                test_number INTEGER,                      -- ãƒ†ã‚¹ãƒˆç•ªå·
                sample_id INTEGER,                        -- ã‚µãƒ³ãƒ—ãƒ«ID
                sample_name TEXT,                         -- ã‚µãƒ³ãƒ—ãƒ«å
                
                -- å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
                japanese_text TEXT,                       -- æ—¥æœ¬èªåŸæ–‡
                target_language TEXT DEFAULT 'en',       -- å¯¾è±¡è¨€èªï¼ˆen/fr/esï¼‰
                language_pair TEXT DEFAULT 'ja-en',      -- è¨€èªãƒšã‚¢
                partner_message TEXT,                     -- ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                context_info TEXT,                        -- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                
                -- ç¿»è¨³çµæœ
                chatgpt_translation TEXT,                 -- ChatGPTç¿»è¨³
                enhanced_translation TEXT,                -- Enhancedç¿»è¨³ï¼ˆæ”¹å–„ChatGPTï¼‰
                gemini_translation TEXT,                  -- Geminiç¿»è¨³
                
                -- åˆ†æå®Ÿè¡Œãƒ‡ãƒ¼ã‚¿
                button_pressed TEXT,                      -- æŠ¼ä¸‹ãƒœã‚¿ãƒ³ï¼ˆChatGPT/Gemini/Claudeï¼‰
                actual_analysis_llm TEXT,                 -- å®Ÿéš›åˆ†æLLM
                llm_match BOOLEAN,                        -- ãƒœã‚¿ãƒ³ã¨LLMã®ä¸€è‡´ãƒ•ãƒ©ã‚°
                
                -- åˆ†æçµæœ
                recommendation_result TEXT,               -- æ¨å¥¨çµæœï¼ˆEnhanced/ChatGPT/Geminiï¼‰
                confidence REAL,                          -- ä¿¡é ¼åº¦ï¼ˆ0.0-1.0ï¼‰
                processing_method TEXT,                   -- æ¨å¥¨æŠ½å‡ºæ–¹æ³•
                extraction_method TEXT,                   -- æŠ½å‡ºè©³ç´°æ–¹æ³•
                
                -- åˆ†æå†…å®¹
                full_analysis_text TEXT,                  -- ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹åˆ†æçµæœå…¨æ–‡
                analysis_preview TEXT,                    -- åˆ†æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆ200æ–‡å­—ï¼‰
                
                -- å®Ÿè¡Œãƒ­ã‚°
                terminal_logs TEXT,                       -- é–¢é€£ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ­ã‚°
                debug_logs TEXT,                          -- ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                error_occurred BOOLEAN DEFAULT 0,        -- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ•ãƒ©ã‚°
                error_message TEXT,                       -- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                
                -- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
                processing_duration REAL,                -- å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
                translation_duration REAL,               -- ç¿»è¨³å‡¦ç†æ™‚é–“
                analysis_duration REAL,                  -- åˆ†æå‡¦ç†æ™‚é–“
                
                -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                ip_address TEXT,                          -- IPã‚¢ãƒ‰ãƒ¬ã‚¹
                user_agent TEXT,                          -- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
                request_headers TEXT,                     -- ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆJSONï¼‰
                
                -- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                year INTEGER,                             -- å¹´ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                month INTEGER,                            -- æœˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                day INTEGER,                              -- æ—¥ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                hour INTEGER,                             -- æ™‚ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
                
                -- ç¬¬0æ®µéš: äººé–“ãƒã‚§ãƒƒã‚¯
                stage0_human_check TEXT,                  -- äººé–“ã«ã‚ˆã‚‹æ¨å¥¨åˆ¤å®š (ChatGPT/Enhanced/Gemini/None)
                stage0_human_check_date TIMESTAMP,        -- äººé–“ãƒã‚§ãƒƒã‚¯æ—¥æ™‚
                stage0_human_check_user TEXT,             -- ãƒã‚§ãƒƒã‚¯å®Ÿæ–½è€…
                
                -- è¿½åŠ ãƒ¡ãƒ¢
                notes TEXT,                               -- æ‰‹å‹•ãƒ¡ãƒ¢
                tags TEXT                                 -- ã‚¿ã‚°ï¼ˆJSONé…åˆ—ï¼‰
            )
        """)
            
            # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ–°ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆå®‰å…¨ã«ï¼‰
            try:
                cursor.execute("ALTER TABLE analysis_activity_log ADD COLUMN stage0_human_check TEXT")
                self.logger.info("Added stage0_human_check column")
            except sqlite3.OperationalError:
                pass  # ã‚«ãƒ©ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
                
            try:
                cursor.execute("ALTER TABLE analysis_activity_log ADD COLUMN stage0_human_check_date TIMESTAMP")
                self.logger.info("Added stage0_human_check_date column")
            except sqlite3.OperationalError:
                pass  # ã‚«ãƒ©ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
                
            try:
                cursor.execute("ALTER TABLE analysis_activity_log ADD COLUMN stage0_human_check_user TEXT")
                self.logger.info("Added stage0_human_check_user column")
            except sqlite3.OperationalError:
                pass  # ã‚«ãƒ©ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_activity_type ON analysis_activity_log(activity_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_id ON analysis_activity_log(user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON analysis_activity_log(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_year_month ON analysis_activity_log(year, month)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_button_pressed ON analysis_activity_log(button_pressed)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_actual_llm ON analysis_activity_log(actual_analysis_llm)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_error_occurred ON analysis_activity_log(error_occurred)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stage0_human_check ON analysis_activity_log(stage0_human_check)")
            
            # ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS test_samples (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    sample_name TEXT NOT NULL,
                    japanese_text TEXT NOT NULL,
                    category TEXT DEFAULT 'general',          -- 'technical', 'business', 'casual'
                    description TEXT,
                    expected_result TEXT,                      -- æœŸå¾…ã•ã‚Œã‚‹çµæœ
                    difficulty_level INTEGER DEFAULT 1,       -- é›£æ˜“åº¦ 1-5
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_by TEXT,
                    is_active BOOLEAN DEFAULT 1
                )
            """)
            
            # ğŸ¯ 4æ®µéšåˆ†æã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ‹¡å¼µï¼‰
            self._add_four_stage_analysis_columns(cursor)
        
            conn.commit()
            conn.close()
            
            if hasattr(self, 'logger'):
                self.logger.info(f"âœ… Activity Logger database initialized: {self.db_path}")
            else:
                print(f"âœ… Activity Logger database initialized: {self.db_path}")
                
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ Failed to initialize database: {str(e)}")
            else:
                print(f"âŒ Failed to initialize database: {str(e)}")
            raise
    
    def _add_four_stage_analysis_columns(self, cursor):
        """ğŸ¯ 4æ®µéšåˆ†æã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚«ãƒ©ãƒ ã‚’è¿½åŠ """
        try:
            # æ—¢å­˜ã®ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆã‚’å–å¾—
            cursor.execute("PRAGMA table_info(analysis_activity_log)")
            existing_columns = [row[1] for row in cursor.fetchall()]
            
            # 4æ®µéšåˆ†æç”¨ã®æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’å®šç¾©
            four_stage_columns = [
                # ç¬¬0æ®µéš: äººé–“ã«ã‚ˆã‚‹LLMæ¨å¥¨ãƒã‚§ãƒƒã‚¯
                ("human_check_result", "TEXT"),          # 'approved' | 'rejected' | 'pending'
                ("human_check_timestamp", "TIMESTAMP"),  # äººé–“ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œæ™‚åˆ»
                ("human_checker_id", "TEXT"),            # ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œè€…ID
                ("human_check_notes", "TEXT"),           # äººé–“ãƒã‚§ãƒƒã‚¯ãƒ¡ãƒ¢
                
                # ç¬¬1æ®µéš: LLMæ¨å¥¨æŠ½å‡ºãƒ»åˆ†æï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                ("stage1_extraction_method", "TEXT"),    # æ¨å¥¨æŠ½å‡ºæ‰‹æ³•è©³ç´°
                ("stage1_confidence_score", "REAL"),     # ç¬¬1æ®µéšã®ä¿¡é ¼åº¦
                ("stage1_processing_time", "REAL"),      # ç¬¬1æ®µéšå‡¦ç†æ™‚é–“
                ("stage1_metadata", "TEXT"),             # ç¬¬1æ®µéšãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰
                
                # ç¬¬1.5æ®µéš: è£œå®Œåˆ†æ
                ("stage15_supplementary_analysis", "TEXT"),    # è£œå®Œåˆ†æå†…å®¹
                ("stage15_context_evaluation", "TEXT"),        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡
                ("stage15_linguistic_notes", "TEXT"),          # è¨€èªå­¦çš„ãƒãƒ¼ãƒˆ
                
                # ç¬¬2æ®µéš: ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿé¸æŠãƒ»è¡Œå‹•åˆ†æï¼ˆå¼·åŒ–ç‰ˆï¼‰
                ("actual_user_choice", "TEXT"),          # å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠï¼ˆè¿½è·¡æ¸ˆã¿ï¼‰
                ("copy_behavior_tracked", "BOOLEAN"),    # ã‚³ãƒ”ãƒ¼è¡Œå‹•è¿½è·¡æ¸ˆã¿ãƒ•ãƒ©ã‚°
                ("copied_translation", "TEXT"),          # ã‚³ãƒ”ãƒ¼ã•ã‚ŒãŸç¿»è¨³å†…å®¹
                ("copy_method", "TEXT"),                 # ã‚³ãƒ”ãƒ¼æ–¹æ³•ï¼ˆbutton|keyboard|otherï¼‰
                ("copy_timestamp", "TIMESTAMP"),         # ã‚³ãƒ”ãƒ¼å®Ÿè¡Œæ™‚åˆ»
                ("selection_reasoning", "TEXT"),         # é¸æŠç†ç”±ï¼ˆæ¨å®šãƒ»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆï¼‰
                ("user_confidence_level", "REAL"),       # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¢ºä¿¡åº¦
                
                # ç¬¬3æ®µéš: æ¨å¥¨vså®Ÿé¸æŠã®ä¸€è‡´åˆ†æï¼ˆè©³ç´°ç‰ˆï¼‰
                ("recommendation_vs_choice_match", "BOOLEAN"),    # æ¨å¥¨ã¨å®Ÿé¸æŠã®ä¸€è‡´ãƒ•ãƒ©ã‚°
                ("divergence_analysis", "TEXT"),                 # ä¹–é›¢åˆ†æçµæœ
                ("divergence_category", "TEXT"),                 # ä¹–é›¢ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
                ("learning_value_score", "REAL"),                # å­¦ç¿’ä¾¡å€¤ã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰
                ("feedback_loop_data", "TEXT"),                  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰
                
                # çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                ("four_stage_completion_status", "TEXT"),        # 4æ®µéšå®Œäº†çŠ¶æ³
                ("data_quality_score", "REAL"),                  # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢
                ("analysis_revision_count", "INTEGER")           # åˆ†æä¿®æ­£å›æ•°
            ]
            
            # å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ã®ã¿è¿½åŠ 
            for column_name, column_type in four_stage_columns:
                if column_name not in existing_columns:
                    try:
                        cursor.execute(f"ALTER TABLE analysis_activity_log ADD COLUMN {column_name} {column_type}")
                        print(f"âœ… Added column: {column_name}")
                    except sqlite3.OperationalError as e:
                        if "duplicate column name" not in str(e):
                            print(f"âš ï¸ Failed to add column {column_name}: {e}")
            
            # 4æ®µéšåˆ†æç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
            four_stage_indexes = [
                ("idx_human_check_result", "human_check_result"),
                ("idx_actual_user_choice", "actual_user_choice"),
                ("idx_copy_behavior_tracked", "copy_behavior_tracked"),
                ("idx_recommendation_match", "recommendation_vs_choice_match"),
                ("idx_four_stage_completion", "four_stage_completion_status")
            ]
            
            for index_name, column_name in four_stage_indexes:
                try:
                    cursor.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON analysis_activity_log({column_name})")
                except sqlite3.OperationalError:
                    pass  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ç„¡è¦–
            
            print("ğŸ¯ 4æ®µéšåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒæ‹¡å¼µå®Œäº†")
            
        except Exception as e:
            print(f"âŒ 4æ®µéšåˆ†æã‚«ãƒ©ãƒ è¿½åŠ ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def log_activity(self, activity_data: Dict[str, Any]) -> int:
        """æ´»å‹•ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # JSTåŸºæº–ã®ç¾åœ¨æ™‚åˆ»ã®è©³ç´°æƒ…å ±
            now = get_jst_now()
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
            activity_data.setdefault('activity_type', 'normal_use')
            activity_data.setdefault('user_id', 'anonymous')
            activity_data.setdefault('error_occurred', False)
            
            # LLMä¸€è‡´åˆ¤å®š
            button_pressed = activity_data.get('button_pressed', '').lower()
            actual_llm = activity_data.get('actual_analysis_llm', '').lower()
            llm_match = button_pressed == actual_llm if button_pressed and actual_llm else None
            
            # åˆ†æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
            full_analysis = activity_data.get('full_analysis_text', '')
            analysis_preview = full_analysis[:200] + '...' if len(full_analysis) > 200 else full_analysis
            
            # SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            cursor.execute("""
                INSERT INTO analysis_activity_log (
                    activity_type, session_id, user_id,
                    test_session_id, test_number, sample_id, sample_name,
                    japanese_text, target_language, language_pair, partner_message, context_info,
                    chatgpt_translation, enhanced_translation, gemini_translation,
                    button_pressed, actual_analysis_llm, llm_match,
                    recommendation_result, confidence, processing_method, extraction_method,
                    full_analysis_text, analysis_preview,
                    terminal_logs, debug_logs, error_occurred, error_message,
                    processing_duration, translation_duration, analysis_duration,
                    ip_address, user_agent, request_headers,
                    year, month, day, hour,
                    notes, tags
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                activity_data.get('activity_type'),
                activity_data.get('session_id'),
                activity_data.get('user_id'),
                activity_data.get('test_session_id'),
                activity_data.get('test_number'),
                activity_data.get('sample_id'),
                activity_data.get('sample_name'),
                activity_data.get('japanese_text'),
                activity_data.get('target_language', 'en'),
                activity_data.get('language_pair', 'ja-en'),
                activity_data.get('partner_message'),
                activity_data.get('context_info'),
                activity_data.get('chatgpt_translation'),
                activity_data.get('enhanced_translation'),
                activity_data.get('gemini_translation'),
                activity_data.get('button_pressed'),
                activity_data.get('actual_analysis_llm'),
                llm_match,
                activity_data.get('recommendation_result'),
                activity_data.get('confidence'),
                activity_data.get('processing_method'),
                activity_data.get('extraction_method'),
                activity_data.get('full_analysis_text'),
                analysis_preview,
                activity_data.get('terminal_logs'),
                activity_data.get('debug_logs'),
                activity_data.get('error_occurred', False),
                activity_data.get('error_message'),
                activity_data.get('processing_duration'),
                activity_data.get('translation_duration'),
                activity_data.get('analysis_duration'),
                activity_data.get('ip_address'),
                activity_data.get('user_agent'),
                json.dumps(activity_data.get('request_headers', {})),
                now.year,
                now.month,
                now.day,
                now.hour,
                activity_data.get('notes'),
                json.dumps(activity_data.get('tags', []))
            ))
            
            log_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            self.logger.info(f"âœ… Activity logged: ID={log_id}, Type={activity_data.get('activity_type')}")
            return log_id
            
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ Failed to log activity: {str(e)}")
            else:
                print(f"âŒ Failed to log activity: {str(e)}")
            return -1
    
    def get_activity_stats(self, filters: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ´»å‹•çµ±è¨ˆã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
        where_clause, params = self._build_where_clause(filters or {})
        
        # JSTåŸºæº–ã®åŸºæœ¬çµ±è¨ˆ
        today_jst = get_jst_today().strftime('%Y-%m-%d')
        cursor.execute(f"""
            SELECT 
                COUNT(*) as total_activities,
                COUNT(CASE WHEN DATE(created_at, '+9 hours') = ? THEN 1 END) as today_activities,
                COUNT(CASE WHEN error_occurred = 1 THEN 1 END) as error_count,
                AVG(processing_duration) as avg_processing_time,
                COUNT(CASE WHEN llm_match = 1 THEN 1 END) as llm_match_count,
                COUNT(CASE WHEN llm_match = 0 THEN 1 END) as llm_mismatch_count
            FROM analysis_activity_log
            {where_clause}
        """, [today_jst] + params)
        
        basic_stats = cursor.fetchone()
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥çµ±è¨ˆ
        cursor.execute(f"""
            SELECT 
                button_pressed,
                COUNT(*) as count,
                AVG(confidence) as avg_confidence,
                AVG(processing_duration) as avg_duration
            FROM analysis_activity_log
            {where_clause}
            GROUP BY button_pressed
            ORDER BY count DESC
        """, params)
        
        engine_stats = cursor.fetchall()
        
        # æ¨å¥¨çµæœçµ±è¨ˆ
        cursor.execute(f"""
            SELECT 
                recommendation_result,
                COUNT(*) as count
            FROM analysis_activity_log
            {where_clause}
            GROUP BY recommendation_result
            ORDER BY count DESC
        """, params)
        
        recommendation_stats = cursor.fetchall()
        
        conn.close()
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
        stats = {
            'basic': {
                'total_activities': basic_stats[0] or 0,
                'today_activities': basic_stats[1] or 0,
                'today_translations': basic_stats[1] or 0,  # ç¿»è¨³æ•°ã¨ã—ã¦è¡¨ç¤º
                'error_count': basic_stats[2] or 0,
                'error_rate': round((basic_stats[2] or 0) / max(basic_stats[0] or 1, 1) * 100, 2),
                'avg_processing_time': round(basic_stats[3] or 0, 2),
                'llm_match_count': basic_stats[4] or 0,
                'llm_mismatch_count': basic_stats[5] or 0,
                'llm_match_rate': round((basic_stats[4] or 0) / max((basic_stats[4] or 0) + (basic_stats[5] or 0), 1) * 100, 2)
            },
            'engines': [
                {
                    'engine': row[0] or 'unknown',
                    'count': row[1],
                    'avg_confidence': round(row[2] or 0, 2),
                    'avg_duration': round(row[3] or 0, 2)
                }
                for row in engine_stats
            ],
            'recommendations': [
                {
                    'result': row[0] or 'unknown',
                    'count': row[1]
                }
                for row in recommendation_stats
            ]
        }
        
        return stats
    
    def get_activities(self, filters: Dict[str, Any] = None, limit: int = 50, offset: int = 0) -> List[Dict[str, Any]]:
        """æ´»å‹•ãƒ­ã‚°ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°å¯¾å¿œï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
        where_clause, params = self._build_where_clause(filters or {})
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        cursor.execute(f"""
            SELECT 
                id, activity_type, user_id, created_at,
                japanese_text, button_pressed, actual_analysis_llm, llm_match,
                recommendation_result, confidence, processing_duration,
                error_occurred, error_message,
                test_session_id, sample_name
            FROM analysis_activity_log
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, params + [limit, offset])
        
        rows = cursor.fetchall()
        
        # ç·ä»¶æ•°å–å¾—
        cursor.execute(f"""
            SELECT COUNT(*) FROM analysis_activity_log {where_clause}
        """, params)
        
        total_count = cursor.fetchone()[0]
        
        conn.close()
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
        activities = []
        for row in rows:
            activities.append({
                'id': row[0],
                'activity_type': row[1],
                'user_id': row[2],
                'created_at': row[3],
                'japanese_text': row[4][:50] + '...' if row[4] and len(row[4]) > 50 else row[4],
                'button_pressed': row[5],
                'actual_analysis_llm': row[6],
                'llm_match': row[7],
                'recommendation_result': row[8],
                'confidence': row[9],
                'processing_duration': row[10],
                'error_occurred': row[11],
                'error_message': row[12],
                'test_session_id': row[13],
                'sample_name': row[14]
            })
        
        return {
            'activities': activities,
            'total_count': total_count,
            'page_count': (total_count + limit - 1) // limit,
            'current_page': offset // limit + 1
        }
    
    def get_activity_detail(self, activity_id: int) -> Optional[Dict[str, Any]]:
        """æ´»å‹•è©³ç´°ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT * FROM analysis_activity_log WHERE id = ?
        """, (activity_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return None
        
        # ã‚«ãƒ©ãƒ åå–å¾—
        columns = [description[0] for description in cursor.description]
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
        detail = dict(zip(columns, row))
        
        # JSON ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‘ãƒ¼ã‚¹
        try:
            detail['request_headers'] = json.loads(detail['request_headers'] or '{}')
            detail['tags'] = json.loads(detail['tags'] or '[]')
        except:
            detail['request_headers'] = {}
            detail['tags'] = []
        
        return detail
    
    def _build_where_clause(self, filters: Dict[str, Any]) -> tuple:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‹ã‚‰WHEREå¥ã‚’æ§‹ç¯‰"""
        conditions = []
        params = []
        
        if filters.get('activity_type'):
            conditions.append("activity_type = ?")
            params.append(filters['activity_type'])
        
        if filters.get('user_id'):
            conditions.append("user_id = ?")
            params.append(filters['user_id'])
        
        if filters.get('button_pressed'):
            conditions.append("button_pressed = ?")
            params.append(filters['button_pressed'])
        
        if filters.get('date_from'):
            conditions.append("DATE(created_at) >= ?")
            params.append(filters['date_from'])
        
        if filters.get('date_to'):
            conditions.append("DATE(created_at) <= ?")
            params.append(filters['date_to'])
        
        if filters.get('error_only'):
            conditions.append("error_occurred = 1")
        
        if filters.get('llm_mismatch_only'):
            conditions.append("llm_match = 0")
        
        where_clause = "WHERE " + " AND ".join(conditions) if conditions else ""
        
        return where_clause, params

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
activity_logger = ActivityLogger()

def log_analysis_activity(activity_data: Dict[str, Any]) -> int:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ï¼šåˆ†ææ´»å‹•ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    return activity_logger.log_activity(activity_data)

# ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_activity = {
        'activity_type': 'normal_use',
        'user_id': 'test_user',
        'japanese_text': 'ãƒ†ã‚¹ãƒˆç”¨ã®æ—¥æœ¬èªæ–‡ç« ã§ã™ã€‚',
        'button_pressed': 'Claude',
        'actual_analysis_llm': 'Claude',
        'recommendation_result': 'Enhanced',
        'confidence': 0.85,
        'full_analysis_text': 'ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†æçµæœã§ã™ã€‚éå¸¸ã«è©³ç´°ãªåˆ†æå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚',
        'processing_duration': 2.5
    }
    
    # ãƒ­ã‚°è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    log_id = activity_logger.log_activity(test_activity)
    print(f"âœ… Test activity logged: ID={log_id}")
    
    # çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ
    stats = activity_logger.get_activity_stats()
    print(f"ğŸ“Š Stats: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    # æ´»å‹•ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ
    activities = activity_logger.get_activities(limit=5)
    print(f"ğŸ“‹ Activities: {len(activities['activities'])} items")
    
    print("âœ… Activity Logger test completed")


# =============================================================================
# ğŸ¯ 4æ®µéšåˆ†æã‚·ã‚¹ãƒ†ãƒ å°‚ç”¨æ©Ÿèƒ½
# =============================================================================

class FourStageAnalysisManager:
    """4æ®µéšçµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, activity_logger: ActivityLogger):
        self.activity_logger = activity_logger
        self.db_path = activity_logger.db_path
    
    def update_stage0_human_check(self, activity_id: int, check_result: str, checker_id: str, notes: str = "") -> bool:
        """ç¬¬0æ®µéš: äººé–“ã«ã‚ˆã‚‹LLMæ¨å¥¨ãƒã‚§ãƒƒã‚¯çµæœã‚’æ›´æ–°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            now = get_jst_now()
            
            cursor.execute("""
                UPDATE analysis_activity_log 
                SET human_check_result = ?, 
                    human_check_timestamp = ?, 
                    human_checker_id = ?, 
                    human_check_notes = ?
                WHERE id = ?
            """, (check_result, now.isoformat(), checker_id, notes, activity_id))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… Stage 0 updated: Activity {activity_id} - {check_result} by {checker_id}")
            return True
            
        except Exception as e:
            print(f"âŒ Stage 0 update failed: {str(e)}")
            return False
    
    def update_stage1_analysis(self, activity_id: int, extraction_method: str, confidence: float, processing_time: float, metadata: Dict[str, Any] = None) -> bool:
        """ç¬¬1æ®µéš: LLMæ¨å¥¨æŠ½å‡ºãƒ»åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            metadata_json = json.dumps(metadata) if metadata else None
            
            cursor.execute("""
                UPDATE analysis_activity_log 
                SET stage1_extraction_method = ?, 
                    stage1_confidence_score = ?, 
                    stage1_processing_time = ?, 
                    stage1_metadata = ?
                WHERE id = ?
            """, (extraction_method, confidence, processing_time, metadata_json, activity_id))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… Stage 1 updated: Activity {activity_id} - {extraction_method} (confidence: {confidence})")
            return True
            
        except Exception as e:
            print(f"âŒ Stage 1 update failed: {str(e)}")
            return False
    
    def update_stage15_supplementary(self, activity_id: int, supplementary_analysis: str, context_evaluation: str, linguistic_notes: str = "") -> bool:
        """ç¬¬1.5æ®µéš: è£œå®Œåˆ†æãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE analysis_activity_log 
                SET stage15_supplementary_analysis = ?, 
                    stage15_context_evaluation = ?, 
                    stage15_linguistic_notes = ?
                WHERE id = ?
            """, (supplementary_analysis, context_evaluation, linguistic_notes, activity_id))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… Stage 1.5 updated: Activity {activity_id} - supplementary analysis added")
            return True
            
        except Exception as e:
            print(f"âŒ Stage 1.5 update failed: {str(e)}")
            return False
    
    def update_stage2_user_behavior(self, activity_id: int, user_choice: str, copied_text: str, copy_method: str, reasoning: str = "", confidence: float = None) -> bool:
        """ç¬¬2æ®µéš: ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿé¸æŠãƒ»è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            now = get_jst_now()
            
            cursor.execute("""
                UPDATE analysis_activity_log 
                SET actual_user_choice = ?, 
                    copy_behavior_tracked = 1, 
                    copied_translation = ?, 
                    copy_method = ?, 
                    copy_timestamp = ?, 
                    selection_reasoning = ?, 
                    user_confidence_level = ?
                WHERE id = ?
            """, (user_choice, copied_text, copy_method, now.isoformat(), reasoning, confidence, activity_id))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… Stage 2 updated: Activity {activity_id} - User chose {user_choice}")
            return True
            
        except Exception as e:
            print(f"âŒ Stage 2 update failed: {str(e)}")
            return False
    
    def update_stage3_divergence_analysis(self, activity_id: int) -> bool:
        """ç¬¬3æ®µéš: æ¨å¥¨vså®Ÿé¸æŠã®ä¸€è‡´åˆ†æã‚’å®Ÿè¡Œãƒ»æ›´æ–°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cursor.execute("""
                SELECT recommendation_result, actual_user_choice, 
                       chatgpt_translation, enhanced_translation, gemini_translation,
                       copied_translation, japanese_text
                FROM analysis_activity_log 
                WHERE id = ?
            """, (activity_id,))
            
            row = cursor.fetchone()
            if not row:
                return False
            
            recommendation, user_choice, chatgpt, enhanced, gemini, copied_text, original = row
            
            # ä¸€è‡´åˆ¤å®š
            match = False
            divergence_category = "unknown"
            learning_value = 0.0
            
            if recommendation and user_choice:
                match = recommendation.lower() == user_choice.lower()
                
                if not match:
                    # ä¹–é›¢ã‚«ãƒ†ã‚´ãƒªåˆ†æ
                    if "enhanced" in recommendation.lower() and "chatgpt" in user_choice.lower():
                        divergence_category = "enhanced_to_original"
                    elif "chatgpt" in recommendation.lower() and "gemini" in user_choice.lower():
                        divergence_category = "chatgpt_to_gemini"
                    elif "gemini" in recommendation.lower() and "enhanced" in user_choice.lower():
                        divergence_category = "gemini_to_enhanced"
                    else:
                        divergence_category = "other_divergence"
                    
                    # å­¦ç¿’ä¾¡å€¤ã‚¹ã‚³ã‚¢ï¼ˆä¹–é›¢ã®å ´åˆã¯é«˜ã„ä¾¡å€¤ï¼‰
                    learning_value = 0.8
                else:
                    divergence_category = "perfect_match"
                    learning_value = 0.3
            
            # ä¹–é›¢åˆ†æçµæœ
            divergence_analysis = f"Recommendation: {recommendation}, User Choice: {user_choice}, Match: {match}, Category: {divergence_category}"
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿
            feedback_data = {
                "match": match,
                "divergence_category": divergence_category,
                "learning_value": learning_value,
                "analysis_timestamp": get_jst_now().isoformat(),
                "text_length": len(original) if original else 0
            }
            
            cursor.execute("""
                UPDATE analysis_activity_log 
                SET recommendation_vs_choice_match = ?, 
                    divergence_analysis = ?, 
                    divergence_category = ?, 
                    learning_value_score = ?, 
                    feedback_loop_data = ?
                WHERE id = ?
            """, (match, divergence_analysis, divergence_category, learning_value, json.dumps(feedback_data), activity_id))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… Stage 3 updated: Activity {activity_id} - Match: {match}, Category: {divergence_category}")
            return True
            
        except Exception as e:
            print(f"âŒ Stage 3 update failed: {str(e)}")
            return False
    
    def get_four_stage_analysis_data(self, period: str = "all", engine: str = "") -> Dict[str, Any]:
        """4æ®µéšåˆ†æçµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
            where_conditions = []
            params = []
            
            if period == 'today':
                where_conditions.append("DATE(created_at, '+9 hours') = DATE('now', '+9 hours')")
            elif period == 'week':
                where_conditions.append("created_at >= datetime('now', '-7 days')")
            elif period == 'month':
                where_conditions.append("created_at >= datetime('now', '-30 days')")
            
            if engine:
                where_conditions.append("actual_analysis_llm = ?")
                params.append(engine)
            
            where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
            
            # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor.execute(f"""
                SELECT 
                    COUNT(*) as total_cases,
                    COUNT(human_check_result) as stage0_completed,
                    COUNT(CASE WHEN recommendation_result IS NOT NULL THEN 1 END) as stage1_completed,
                    COUNT(CASE WHEN actual_user_choice IS NOT NULL THEN 1 END) as stage2_completed,
                    COUNT(CASE WHEN recommendation_vs_choice_match IS NOT NULL THEN 1 END) as stage3_completed,
                    COUNT(CASE WHEN copy_behavior_tracked = 1 THEN 1 END) as copy_tracked,
                    COUNT(CASE WHEN recommendation_vs_choice_match = 1 THEN 1 END) as stage3_matches,
                    COUNT(CASE WHEN recommendation_vs_choice_match = 0 THEN 1 END) as stage3_divergent
                FROM analysis_activity_log
                {where_clause}
            """, params)
            
            summary = cursor.fetchone()
            
            # è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor.execute(f"""
                SELECT 
                    id, created_at, japanese_text, actual_analysis_llm,
                    recommendation_result, actual_user_choice, 
                    human_check_result, human_check_timestamp,
                    copy_behavior_tracked, copied_translation, copy_method,
                    recommendation_vs_choice_match, divergence_category,
                    stage1_confidence_score, learning_value_score
                FROM analysis_activity_log
                {where_clause}
                ORDER BY created_at DESC
                LIMIT 100
            """, params)
            
            rows = cursor.fetchall()
            conn.close()
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
            items = []
            for row in rows:
                item = {
                    'id': row[0],
                    'created_at': row[1],
                    'japanese_text': row[2],
                    'analysis_engine': row[3],
                    'stage0': {
                        'status': row[6] or 'pending',
                        'timestamp': row[7]
                    } if row[6] else None,
                    'stage1': {
                        'recommendation': row[4],
                        'confidence': row[12]
                    } if row[4] else None,
                    'stage15': {
                        'status': 'completed' if row[4] else 'pending'
                    },
                    'stage2': {
                        'user_selection': row[5],
                        'copy_tracked': bool(row[8]),
                        'copy_method': row[10],
                        'data_source': 'actual_copy_tracking' if row[8] else 'button_tracking'
                    } if row[5] else None,
                    'stage3': {
                        'match': row[11] if row[11] is not None else None,
                        'category': row[12],
                        'learning_value': row[13]
                    } if row[11] is not None else None
                }
                items.append(item)
            
            return {
                'total_count': summary[0] if summary else 0,
                'stage0_completed': summary[1] if summary else 0,
                'stage1_completed': summary[2] if summary else 0,
                'stage2_completed': summary[3] if summary else 0,
                'stage3_completed': summary[4] if summary else 0,
                'copy_count': summary[5] if summary else 0,
                'match_rate': (summary[6] / summary[7] * 100) if summary and summary[7] > 0 else 0,
                'human_check_count': summary[1] if summary else 0,
                'items': items
            }
            
        except Exception as e:
            print(f"âŒ 4æ®µéšåˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'total_count': 0, 'items': []}
    
    def get_human_check_queue(self) -> List[Dict[str, Any]]:
        """ç¬¬0æ®µéš: äººé–“ãƒã‚§ãƒƒã‚¯å¾…ã¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT 
                    id, created_at, japanese_text, recommendation_result, 
                    confidence, actual_analysis_llm, full_analysis_text
                FROM analysis_activity_log 
                WHERE human_check_result IS NULL 
                   OR human_check_result = 'pending'
                ORDER BY created_at DESC 
                LIMIT 50
            """)
            
            rows = cursor.fetchall()
            conn.close()
            
            items = []
            for row in rows:
                items.append({
                    'id': row[0],
                    'created_at': row[1],
                    'japanese_text': row[2],
                    'recommendation_result': row[3],
                    'confidence': row[4],
                    'actual_analysis_llm': row[5],
                    'full_analysis_text': row[6]
                })
            
            return items
            
        except Exception as e:
            print(f"âŒ äººé–“ãƒã‚§ãƒƒã‚¯å¾…ã¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆç”¨é–¢æ•°
def create_four_stage_manager() -> FourStageAnalysisManager:
    """4æ®µéšåˆ†æãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
    activity_logger = ActivityLogger()
    return FourStageAnalysisManager(activity_logger)