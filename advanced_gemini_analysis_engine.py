#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ Task 2.9.2: é«˜åº¦Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ³ã‚¸ãƒ³
=====================================================
ç›®çš„: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã®æ·±å±¤è§£æã«ã‚ˆã‚Šã€æ¨å¥¨ç†ç”±ãƒ»ä¿¡é ¼åº¦ãƒ»
     å¤šè¨€èªå¯¾å¿œã‚’å®Ÿç¾ã—ã€å€‹äººåŒ–ç¿»è¨³AIæ§‹ç¯‰ã®ãŸã‚ã®
     é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹

ã€Task 2.9.1.5åŸºç›¤æ´»ç”¨ã€‘
- GeminiRecommendationAnalyzerã®æ©Ÿèƒ½ã‚’æ‹¡å¼µ
- éæ¥è§¦ãƒ‡ãƒ¼ã‚¿åé›†åŸå‰‡ã®ç¶™æ‰¿
- çœŸã®å€‹äººåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã®æ·±åŒ–
"""

import re
import json
import logging
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from datetime import datetime
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from enum import Enum
import hashlib

# Task 2.9.1.5åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from gemini_recommendation_analyzer import GeminiRecommendationAnalyzer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RecommendationStrength(Enum):
    """æ¨å¥¨å¼·åº¦ãƒ¬ãƒ™ãƒ«"""
    VERY_STRONG = "very_strong"  # æ˜ç¢ºãªæ¨å¥¨
    STRONG = "strong"           # å¼·ã„æ¨å¥¨
    MODERATE = "moderate"       # ä¸­ç¨‹åº¦ã®æ¨å¥¨
    WEAK = "weak"              # å¼±ã„æ¨å¥¨
    NONE = "none"              # æ¨å¥¨ãªã—

class RecommendationReason(Enum):
    """æ¨å¥¨ç†ç”±ã‚«ãƒ†ã‚´ãƒª"""
    ACCURACY = "accuracy"           # ç²¾åº¦ãƒ»æ­£ç¢ºæ€§
    NATURALNESS = "naturalness"     # è‡ªç„¶ã•
    CONTEXT_FIT = "context_fit"     # æ–‡è„ˆé©åˆæ€§
    STYLE = "style"                 # ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»æ–‡ä½“
    CLARITY = "clarity"             # æ˜ç¢ºæ€§
    FORMALITY = "formality"         # ä¸å¯§åº¦
    CULTURAL_FIT = "cultural_fit"   # æ–‡åŒ–çš„é©åˆæ€§
    LENGTH = "length"               # æ–‡ç« é•·
    TERMINOLOGY = "terminology"     # å°‚é–€ç”¨èª
    TONE = "tone"                   # ãƒˆãƒ¼ãƒ³ãƒ»èªèª¿

@dataclass
class StructuredRecommendation:
    """æ§‹é€ åŒ–æ¨å¥¨ãƒ‡ãƒ¼ã‚¿"""
    recommended_engine: str
    confidence_score: float
    strength_level: RecommendationStrength
    primary_reasons: List[RecommendationReason]
    secondary_reasons: List[RecommendationReason]
    reasoning_text: str
    language: str
    analysis_metadata: Dict[str, Any] = field(default_factory=dict)
    extraction_timestamp: str = field(default_factory=lambda: datetime.now().isoformat())

class AdvancedGeminiAnalysisEngine:
    """Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆã®æ·±å±¤è§£æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # Task 2.9.1.5åŸºç›¤ã®æ´»ç”¨
        self.base_analyzer = GeminiRecommendationAnalyzer()
        
        # å¤šè¨€èªå¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³
        self.multilingual_patterns = self._initialize_multilingual_patterns()
        
        # æ¨å¥¨ç†ç”±ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        self.reason_keywords = self._initialize_reason_keywords()
        
        # ä¿¡é ¼åº¦ç®—å‡ºç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.confidence_weights = {
            'explicit_recommendation': 0.4,  # æ˜ç¤ºçš„æ¨å¥¨
            'reasoning_depth': 0.3,          # ç†ç”±ã®è©³ç´°åº¦
            'comparative_analysis': 0.2,      # æ¯”è¼ƒåˆ†æã®æœ‰ç„¡
            'specific_examples': 0.1          # å…·ä½“ä¾‹ã®æœ‰ç„¡
        }
        
        logger.info("é«˜åº¦Geminiåˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_multilingual_patterns(self) -> Dict[str, List[str]]:
        """å¤šè¨€èªå¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        return {
            'ja': [
                # ğŸ†• ä¿®æ­£: ã€Œæœ€é©ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ ã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªãƒãƒƒãƒãƒ³ã‚°
                r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ãŒ|ã¯|ã‚’)?(?:æœ€ã‚‚|ã‚‚ã£ã¨ã‚‚|ä¸€ç•ª|ç‰¹ã«)?(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€|æ¨å¥¨|ãŠã™ã™ã‚|æœ€é©|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)',
                r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ãŒ|ã¯|ã‚’)?(?:æœ€é©|æœ€ã‚‚é©åˆ‡|ã‚‚ã£ã¨ã‚‚é©åˆ‡|ä¸€ç•ªé©åˆ‡|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)(?:ãª|ã®)?(?:é¸æŠ|é¸æŠè‚¢|ã‚ªãƒ—ã‚·ãƒ§ãƒ³|æ–¹æ³•|ç¿»è¨³)?',
                r'(?:æœ€ã‚‚|ã‚‚ã£ã¨ã‚‚|ä¸€ç•ª|ç‰¹ã«|æœ€ã‚‚é©åˆ‡|æœ€é©|æœ€è‰¯|æœ€å–„|ãƒ™ã‚¹ãƒˆ)(?:ãª|ã®)?(?:ç¿»è¨³|è¨³|é¸æŠè‚¢|é¸æŠ|ã‚ªãƒ—ã‚·ãƒ§ãƒ³)?(?:ã¯|ï¼š|:)?\s*([A-Za-z]+)',
                r'([A-Za-z]+)(?:ã‚’|ãŒ)(?:æ¨å¥¨|ãŠã™ã™ã‚|é¸æŠ|é¸ã¶ã¹ã|é¸æŠã™ã¹ã)',
                r'(?:æ¨å¥¨|ãŠã™ã™ã‚|ãƒ™ã‚¹ãƒˆ|æœ€é©|æœ€è‰¯|æœ€å–„)(?:ç¿»è¨³|è¨³|é¸æŠ|ã®é¸æŠè‚¢)?(?:ã¯|ï¼š|:)?\s*([A-Za-z]+)',
                # ğŸ†• æ–°è¿½åŠ : ã‚ˆãã‚ã‚‹è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                r'([A-Za-z]+)(?:ãŒ|ã®ç¿»è¨³ãŒ|ç¿»è¨³ã¯)(?:ã‚ˆã‚Š|ã‚‚ã£ã¨|æœ€ã‚‚)(?:é©ã—ã¦ã„ã‚‹|é©åˆ‡|è‡ªç„¶|è‰¯ã„)',
                r'([A-Za-z]+)(?:ç¿»è¨³|è¨³)(?:ã®æ–¹ãŒ|ã®ç¿»è¨³ã®æ–¹ãŒ)(?:é©åˆ‡|è‡ªç„¶|è‰¯ã„|å„ªç§€)'
            ],
            'en': [
                # ğŸ†• ä¿®æ­£: ã‚ˆã‚ŠæŸ”è»Ÿã§åŒ…æ‹¬çš„ãªè‹±èªãƒ‘ã‚¿ãƒ¼ãƒ³
                r'(?:recommend|suggest|prefer|choose|select)\s+(?:the\s+)?([A-Za-z]+)(?:\s+translation)?',
                r'([A-Za-z]+)(?:\s+translation)?\s+(?:is|would be|will be)\s+(?:the\s+)?(?:most\s+)?(?:recommended|best|appropriate|preferred|suitable|optimal)',
                r'(?:best|most appropriate|preferred|optimal|most suitable)\s+(?:translation|choice|option)?\s*(?:is|would be|:)?\s*(?:the\s+)?([A-Za-z]+)',
                r'(?:I would|I\'d|should|you should)\s+(?:recommend|suggest|choose|select|prefer)\s+(?:the\s+)?([A-Za-z]+)',
                # ğŸ†• æ–°è¿½åŠ : ã‚ˆã‚Šè‡ªç„¶ãªè‹±èªè¡¨ç¾
                r'([A-Za-z]+)(?:\s+translation)?\s+(?:is|would be)\s+(?:more|most)\s+(?:suitable|appropriate|accurate|natural)',
                r'(?:the\s+)?([A-Za-z]+)(?:\s+translation)?\s+(?:performs|works)\s+(?:better|best)',
                r'(?:go with|use|choose)\s+(?:the\s+)?([A-Za-z]+)(?:\s+translation)?'
            ],
            'fr': [
                # ãƒ•ãƒ©ãƒ³ã‚¹èªãƒ‘ã‚¿ãƒ¼ãƒ³
                r'(?:je recommande|recommandÃ©|prÃ©fÃ©rÃ©|optimal)\s+([A-Za-z]+)',
                r'([A-Za-z]+)\s+(?:est|serait)\s+(?:recommandÃ©|prÃ©fÃ©rable|optimal)',
                r'(?:la meilleure|le meilleur)\s+(?:traduction|choix)?\s*(?:est|:)?\s*([A-Za-z]+)',
            ],
            'es': [
                # ã‚¹ãƒšã‚¤ãƒ³èªãƒ‘ã‚¿ãƒ¼ãƒ³
                r'(?:recomiendo|recomendado|preferido|Ã³ptimo)\s+([A-Za-z]+)',
                r'([A-Za-z]+)\s+(?:es|serÃ­a)\s+(?:recomendado|preferible|Ã³ptimo)',
                r'(?:la mejor|el mejor)\s+(?:traducciÃ³n|opciÃ³n)?\s*(?:es|:)?\s*([A-Za-z]+)',
            ]
        }
    
    def _initialize_reason_keywords(self) -> Dict[RecommendationReason, Dict[str, List[str]]]:
        """æ¨å¥¨ç†ç”±ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åˆæœŸåŒ–"""
        return {
            RecommendationReason.ACCURACY: {
                'ja': ['æ­£ç¢º', 'ç²¾åº¦', 'æ­£ã—ã„', 'é–“é•ã„', 'ã‚¨ãƒ©ãƒ¼', 'èª¤è¨³'],
                'en': ['accurate', 'accuracy', 'correct', 'precise', 'error', 'mistake'],
                'fr': ['prÃ©cis', 'exactitude', 'correct', 'erreur'],
                'es': ['preciso', 'exactitud', 'correcto', 'error']
            },
            RecommendationReason.NATURALNESS: {
                'ja': ['è‡ªç„¶', 'ãƒŠãƒãƒ¥ãƒ©ãƒ«', 'æµæš¢', 'ä¸è‡ªç„¶', 'ã‚¹ãƒ ãƒ¼ã‚º'],
                'en': ['natural', 'fluent', 'smooth', 'awkward', 'unnatural'],
                'fr': ['naturel', 'fluide', 'maladroit'],
                'es': ['natural', 'fluido', 'torpe']
            },
            RecommendationReason.CONTEXT_FIT: {
                'ja': ['æ–‡è„ˆ', 'ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ', 'çŠ¶æ³', 'å ´é¢', 'é©åˆ'],
                'en': ['context', 'contextual', 'situation', 'situational', 'fit'],
                'fr': ['contexte', 'contextuel', 'situation'],
                'es': ['contexto', 'contextual', 'situaciÃ³n']
            },
            RecommendationReason.STYLE: {
                'ja': ['ã‚¹ã‚¿ã‚¤ãƒ«', 'æ–‡ä½“', 'æ›¸ãæ–¹', 'è¡¨ç¾', 'ãƒˆãƒ¼ãƒ³'],
                'en': ['style', 'stylistic', 'tone', 'expression', 'writing'],
                'fr': ['style', 'stylistique', 'ton', 'expression'],
                'es': ['estilo', 'estilÃ­stico', 'tono', 'expresiÃ³n']
            },
            RecommendationReason.CLARITY: {
                'ja': ['æ˜ç¢º', 'ã‚¯ãƒªã‚¢', 'åˆ†ã‹ã‚Šã‚„ã™ã„', 'ç†è§£', 'æ›–æ˜§'],
                'en': ['clear', 'clarity', 'understandable', 'ambiguous', 'vague'],
                'fr': ['clair', 'clartÃ©', 'comprÃ©hensible', 'ambigu'],
                'es': ['claro', 'claridad', 'comprensible', 'ambiguo']
            },
            RecommendationReason.FORMALITY: {
                'ja': ['ä¸å¯§', 'æ•¬èª', 'ãƒ•ã‚©ãƒ¼ãƒãƒ«', 'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«', 'ç¤¼å„€'],
                'en': ['formal', 'polite', 'casual', 'informal', 'courtesy'],
                'fr': ['formel', 'poli', 'dÃ©contractÃ©', 'courtoisie'],
                'es': ['formal', 'cortÃ©s', 'casual', 'cortesÃ­a']
            },
            RecommendationReason.CULTURAL_FIT: {
                'ja': ['æ–‡åŒ–', 'æ…£ç¿’', 'ç¿’æ…£', 'ç¤¾ä¼š', 'æ–‡åŒ–çš„'],
                'en': ['cultural', 'culture', 'social', 'custom', 'tradition'],
                'fr': ['culturel', 'culture', 'social', 'coutume'],
                'es': ['cultural', 'cultura', 'social', 'costumbre']
            },
            RecommendationReason.LENGTH: {
                'ja': ['é•·ã•', 'çŸ­ã„', 'é•·ã„', 'ç°¡æ½”', 'å†—é•·'],
                'en': ['length', 'short', 'long', 'concise', 'verbose'],
                'fr': ['longueur', 'court', 'long', 'concis', 'verbeux'],
                'es': ['longitud', 'corto', 'largo', 'conciso', 'verboso']
            },
            RecommendationReason.TERMINOLOGY: {
                'ja': ['å°‚é–€ç”¨èª', 'è¡“èª', 'æŠ€è¡“çš„', 'å°‚é–€', 'æ¥­ç•Œ'],
                'en': ['terminology', 'technical', 'specialized', 'jargon'],
                'fr': ['terminologie', 'technique', 'spÃ©cialisÃ©', 'jargon'],
                'es': ['terminologÃ­a', 'tÃ©cnico', 'especializado', 'jerga']
            },
            RecommendationReason.TONE: {
                'ja': ['ãƒˆãƒ¼ãƒ³', 'èªèª¿', 'é›°å›²æ°—', 'ãƒ ãƒ¼ãƒ‰', 'å°è±¡'],
                'en': ['tone', 'mood', 'atmosphere', 'impression', 'feeling'],
                'fr': ['ton', 'humeur', 'atmosphÃ¨re', 'impression'],
                'es': ['tono', 'humor', 'atmÃ³sfera', 'impresiÃ³n']
            }
        }
    
    def extract_structured_recommendations(self, analysis_text: str, language: str = 'ja') -> StructuredRecommendation:
        """
        æ§‹é€ åŒ–æ¨å¥¨æŠ½å‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        
        Args:
            analysis_text: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            language: åˆ†æè¨€èª ('ja', 'en', 'fr', 'es')
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸæ¨å¥¨ãƒ‡ãƒ¼ã‚¿
        """
        try:
            # Task 2.9.1.5åŸºç›¤ã‚’æ´»ç”¨ã—ãŸåŸºæœ¬æ¨å¥¨æŠ½å‡º
            base_recommendation = self.base_analyzer.extract_gemini_recommendation(analysis_text)
            
            if not base_recommendation:
                return StructuredRecommendation(
                    recommended_engine="none",
                    confidence_score=0.0,
                    strength_level=RecommendationStrength.NONE,
                    primary_reasons=[],
                    secondary_reasons=[],
                    reasoning_text="",
                    language=language
                )
            
            # æ¨å¥¨å¼·åº¦ã®åˆ†æ
            strength_level = self._analyze_recommendation_strength(analysis_text, language)
            
            # æ¨å¥¨ç†ç”±ã®åˆ†é¡
            primary_reasons, secondary_reasons = self.classify_recommendation_reasons(analysis_text, language)
            
            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®ç®—å‡º
            confidence_score = self.calculate_recommendation_confidence(analysis_text, language)
            
            # ç†ç”±ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡º
            reasoning_text = self._extract_reasoning_text(analysis_text, language)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
            metadata = {
                'text_length': len(analysis_text),
                'language_detected': language,
                'pattern_matches': self._count_pattern_matches(analysis_text, language),
                'reason_keyword_count': self._count_reason_keywords(analysis_text, language)
            }
            
            result = StructuredRecommendation(
                recommended_engine=base_recommendation,
                confidence_score=confidence_score,
                strength_level=strength_level,
                primary_reasons=primary_reasons,
                secondary_reasons=secondary_reasons,
                reasoning_text=reasoning_text,
                language=language,
                analysis_metadata=metadata
            )
            
            logger.info(f"æ§‹é€ åŒ–æ¨å¥¨æŠ½å‡ºå®Œäº†: {base_recommendation} (ä¿¡é ¼åº¦: {confidence_score:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"æ§‹é€ åŒ–æ¨å¥¨æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return StructuredRecommendation(
                recommended_engine="error",
                confidence_score=0.0,
                strength_level=RecommendationStrength.NONE,
                primary_reasons=[],
                secondary_reasons=[],
                reasoning_text=f"Error: {str(e)}",
                language=language
            )
    
    def classify_recommendation_reasons(self, analysis_text: str, language: str = 'ja') -> Tuple[List[RecommendationReason], List[RecommendationReason]]:
        """
        æ¨å¥¨ç†ç”±ã®è‡ªå‹•åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
        
        Args:
            analysis_text: Geminiåˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            language: åˆ†æè¨€èª
            
        Returns:
            (ä¸»è¦ç†ç”±ãƒªã‚¹ãƒˆ, å‰¯æ¬¡ç†ç”±ãƒªã‚¹ãƒˆ)
        """
        text_lower = analysis_text.lower()
        reason_scores = defaultdict(int)
        
        # å„ç†ç”±ã‚«ãƒ†ã‚´ãƒªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for reason, lang_keywords in self.reason_keywords.items():
            if language in lang_keywords:
                keywords = lang_keywords[language]
                for keyword in keywords:
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    count = text_lower.count(keyword.lower())
                    if count > 0:
                        # æ–‡è„ˆã§ã®é‡è¦åº¦ã‚’è€ƒæ…®
                        context_weight = self._calculate_context_weight(text_lower, keyword.lower())
                        reason_scores[reason] += count * context_weight
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸»è¦ãƒ»å‰¯æ¬¡ç†ç”±ã‚’åˆ†é¡
        sorted_reasons = sorted(reason_scores.items(), key=lambda x: x[1], reverse=True)
        
        # é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡
        primary_threshold = max(2, max(reason_scores.values()) * 0.6) if reason_scores else 2
        secondary_threshold = 1
        
        primary_reasons = [reason for reason, score in sorted_reasons if score >= primary_threshold]
        secondary_reasons = [reason for reason, score in sorted_reasons 
                           if secondary_threshold <= score < primary_threshold]
        
        # æœ€å¤§æ•°ã®åˆ¶é™
        primary_reasons = primary_reasons[:3]
        secondary_reasons = secondary_reasons[:3]
        
        logger.info(f"ç†ç”±åˆ†é¡å®Œäº†: ä¸»è¦={len(primary_reasons)}, å‰¯æ¬¡={len(secondary_reasons)}")
        return primary_reasons, secondary_reasons
    
    def _calculate_context_weight(self, text: str, keyword: str) -> float:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–‡è„ˆé‡è¦åº¦ã‚’è¨ˆç®—"""
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‘¨è¾ºã®æ–‡è„ˆã‚’åˆ†æ
        keyword_positions = []
        start = 0
        while True:
            pos = text.find(keyword, start)
            if pos == -1:
                break
            keyword_positions.append(pos)
            start = pos + 1
        
        if not keyword_positions:
            return 0.0
        
        total_weight = 0.0
        for pos in keyword_positions:
            # æ–‡ã®é–‹å§‹ä½ç½®ã§ã®é‡è¦åº¦ãŒé«˜ã„
            sentence_start_weight = 1.5 if self._is_sentence_start(text, pos) else 1.0
            
            # æ¯”è¼ƒè¡¨ç¾ã¨ã®è¿‘æ¥åº¦
            comparison_weight = 1.3 if self._near_comparison(text, pos) else 1.0
            
            # æ¨å¥¨è¡¨ç¾ã¨ã®è¿‘æ¥åº¦
            recommendation_weight = 1.4 if self._near_recommendation(text, pos) else 1.0
            
            total_weight += sentence_start_weight * comparison_weight * recommendation_weight
        
        return total_weight / len(keyword_positions)
    
    def _is_sentence_start(self, text: str, pos: int) -> bool:
        """æ–‡ã®é–‹å§‹ä½ç½®ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if pos < 10:
            return True
        
        preceding_text = text[max(0, pos-20):pos]
        return any(punct in preceding_text[-5:] for punct in ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?'])
    
    def _near_comparison(self, text: str, pos: int) -> bool:
        """æ¯”è¼ƒè¡¨ç¾ã¨ã®è¿‘æ¥åº¦ã‚’åˆ¤å®š"""
        window_size = 50
        start = max(0, pos - window_size)
        end = min(len(text), pos + window_size)
        context = text[start:end]
        
        comparison_words = ['æ¯”è¼ƒ', 'å¯¾æ¯”', 'ã‚ˆã‚Š', 'better', 'worse', 'compared', 'versus', 'vs']
        return any(word in context for word in comparison_words)
    
    def _near_recommendation(self, text: str, pos: int) -> bool:
        """æ¨å¥¨è¡¨ç¾ã¨ã®è¿‘æ¥åº¦ã‚’åˆ¤å®š"""
        window_size = 30
        start = max(0, pos - window_size)
        end = min(len(text), pos + window_size)
        context = text[start:end]
        
        recommendation_words = ['æ¨å¥¨', 'ãŠã™ã™ã‚', 'recommend', 'suggest', 'best', 'æœ€é©']
        return any(word in context for word in recommendation_words)
    
    def parse_multilingual_analysis(self, analysis_text: str, language: str) -> Dict[str, Any]:
        """
        å¤šè¨€èªåˆ†æãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ
        
        Args:
            analysis_text: åˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            
        Returns:
            å¤šè¨€èªè§£æçµæœ
        """
        result = {
            'detected_language': language,
            'supported_language': language in self.multilingual_patterns,
            'text_analysis': {},
            'cross_language_elements': []
        }
        
        if language not in self.multilingual_patterns:
            logger.warning(f"æœªå¯¾å¿œè¨€èª: {language}")
            result['text_analysis'] = {'error': f'Unsupported language: {language}'}
            return result
        
        # è¨€èªå›ºæœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = self.multilingual_patterns[language]
        matches = []
        
        for pattern in patterns:
            pattern_matches = re.finditer(pattern, analysis_text, re.IGNORECASE | re.MULTILINE)
            for match in pattern_matches:
                matches.append({
                    'pattern': pattern,
                    'match': match.group(0),
                    'engine': match.group(1) if match.groups() else None,
                    'position': match.span()
                })
        
        result['text_analysis'] = {
            'total_matches': len(matches),
            'pattern_matches': matches,
            'text_length': len(analysis_text),
            'confidence_indicators': self._extract_confidence_indicators(analysis_text, language)
        }
        
        # å¤šè¨€èªæ··åœ¨ã®æ¤œå‡º
        result['cross_language_elements'] = self._detect_cross_language_elements(analysis_text)
        
        return result
    
    def _extract_confidence_indicators(self, text: str, language: str) -> List[str]:
        """ä¿¡é ¼åº¦æŒ‡æ¨™ã®æŠ½å‡º"""
        indicators = []
        
        confidence_patterns = {
            'ja': ['æ˜ç¢ºã«', 'é–“é•ã„ãªã', 'ç¢ºå®Ÿã«', 'ã¯ã£ãã‚Šã¨', 'ç–‘ã„ãªã'],
            'en': ['clearly', 'definitely', 'certainly', 'obviously', 'undoubtedly'],
            'fr': ['clairement', 'dÃ©finitivement', 'certainement', 'Ã©videmment'],
            'es': ['claramente', 'definitivamente', 'ciertamente', 'obviamente']
        }
        
        if language in confidence_patterns:
            for indicator in confidence_patterns[language]:
                if indicator.lower() in text.lower():
                    indicators.append(indicator)
        
        return indicators
    
    def _detect_cross_language_elements(self, text: str) -> List[Dict[str, Any]]:
        """å¤šè¨€èªæ··åœ¨è¦ç´ ã®æ¤œå‡º"""
        elements = []
        
        # è‹±èªå˜èªã®æ¤œå‡ºï¼ˆæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå†…ï¼‰
        english_pattern = r'\b[A-Za-z]{2,}\b'
        english_matches = re.finditer(english_pattern, text)
        
        for match in english_matches:
            elements.append({
                'type': 'english_in_japanese',
                'text': match.group(0),
                'position': match.span()
            })
        
        return elements
    
    def calculate_recommendation_confidence(self, analysis_text: str, language: str = 'ja') -> float:
        """
        æ¨å¥¨å¼·åº¦ãƒ»ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç®—å‡º
        
        Args:
            analysis_text: åˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            
        Returns:
            ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        confidence_score = 0.0
        
        # 1. æ˜ç¤ºçš„æ¨å¥¨ã®è©•ä¾¡
        explicit_score = self._evaluate_explicit_recommendation(analysis_text, language)
        confidence_score += explicit_score * self.confidence_weights['explicit_recommendation']
        
        # 2. ç†ç”±ã®è©³ç´°åº¦è©•ä¾¡
        reasoning_score = self._evaluate_reasoning_depth(analysis_text, language)
        confidence_score += reasoning_score * self.confidence_weights['reasoning_depth']
        
        # 3. æ¯”è¼ƒåˆ†æã®æœ‰ç„¡
        comparative_score = self._evaluate_comparative_analysis(analysis_text, language)
        confidence_score += comparative_score * self.confidence_weights['comparative_analysis']
        
        # 4. å…·ä½“ä¾‹ã®æœ‰ç„¡
        example_score = self._evaluate_specific_examples(analysis_text, language)
        confidence_score += example_score * self.confidence_weights['specific_examples']
        
        # 0.0-1.0ã®ç¯„å›²ã«æ­£è¦åŒ–
        confidence_score = max(0.0, min(1.0, confidence_score))
        
        logger.info(f"ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç®—å‡ºå®Œäº†: {confidence_score:.3f}")
        return confidence_score
    
    def _evaluate_explicit_recommendation(self, text: str, language: str) -> float:
        """æ˜ç¤ºçš„æ¨å¥¨ã®è©•ä¾¡ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        explicit_patterns = {
            'ja': ['æ¨å¥¨', 'ãŠã™ã™ã‚', 'é¸ã¶ã¹ã', 'ãƒ™ã‚¹ãƒˆ', 'æœ€é©', 'æœ€è‰¯', 'æœ€å–„', 'é©åˆ‡', 'æœ€ã‚‚é©åˆ‡', 'ä¸€ç•ªè‰¯ã„', 'é¸æŠ', 'é¸æŠè‚¢'],
            'en': ['recommend', 'suggest', 'best', 'optimal', 'preferred', 'suitable', 'appropriate', 'choose', 'select', 'most suitable'],
            'fr': ['recommande', 'suggÃ¨re', 'meilleur', 'optimal', 'prÃ©fÃ©rÃ©', 'appropriÃ©', 'convenable'],
            'es': ['recomiendo', 'sugiero', 'mejor', 'Ã³ptimo', 'preferido', 'apropiado', 'adecuado']
        }
        
        if language not in explicit_patterns:
            return 0.0
        
        text_lower = text.lower()
        matches = sum(1 for pattern in explicit_patterns[language] 
                     if pattern.lower() in text_lower)
        
        # ğŸ†• ä¿®æ­£: ã‚ˆã‚Šå¯›å®¹ãªè©•ä¾¡ã§ã€1ã¤ã§ã‚‚è¦‹ã¤ã‹ã‚Œã°é«˜ã‚¹ã‚³ã‚¢
        if matches >= 2:
            return 1.0  # 2ã¤ä»¥ä¸Šãªã‚‰æº€ç‚¹
        elif matches == 1:
            return 0.8  # 1ã¤ã§ã‚‚é«˜è©•ä¾¡
        else:
            return 0.0
    
    def _evaluate_reasoning_depth(self, text: str, language: str) -> float:
        """ç†ç”±ã®è©³ç´°åº¦è©•ä¾¡"""
        # æ–‡ç« é•·ã«ã‚ˆã‚‹åŸºæœ¬è©•ä¾¡
        length_score = min(1.0, len(text) / 500)  # 500æ–‡å­—ã§æº€ç‚¹
        
        # ç†ç”±ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å¤šæ§˜æ€§
        unique_reasons = set()
        for reason, lang_keywords in self.reason_keywords.items():
            if language in lang_keywords:
                for keyword in lang_keywords[language]:
                    if keyword.lower() in text.lower():
                        unique_reasons.add(reason)
        
        diversity_score = min(1.0, len(unique_reasons) / 5)  # 5ç¨®é¡ã§æº€ç‚¹
        
        return (length_score + diversity_score) / 2
    
    def _evaluate_comparative_analysis(self, text: str, language: str) -> float:
        """æ¯”è¼ƒåˆ†æã®è©•ä¾¡"""
        comparison_patterns = {
            'ja': ['æ¯”è¼ƒ', 'ã‚ˆã‚Š', 'å¯¾ã—ã¦', 'ä¸€æ–¹', 'ã—ã‹ã—', 'ãŸã ã—'],
            'en': ['compare', 'versus', 'while', 'however', 'whereas', 'better'],
            'fr': ['comparÃ©', 'versus', 'tandis', 'cependant', 'alors', 'meilleur'],
            'es': ['comparado', 'versus', 'mientras', 'sin embargo', 'mejor']
        }
        
        if language not in comparison_patterns:
            return 0.0
        
        text_lower = text.lower()
        matches = sum(1 for pattern in comparison_patterns[language] 
                     if pattern.lower() in text_lower)
        
        return min(1.0, matches / 2.0)  # 2å›ã§æº€ç‚¹
    
    def _evaluate_specific_examples(self, text: str, language: str) -> float:
        """å…·ä½“ä¾‹ã®è©•ä¾¡"""
        example_patterns = {
            'ja': ['ä¾‹ãˆã°', 'ãŸã¨ãˆã°', 'å…·ä½“çš„', 'å®Ÿéš›', 'ã‚±ãƒ¼ã‚¹'],
            'en': ['example', 'instance', 'specifically', 'case', 'such as'],
            'fr': ['exemple', 'par exemple', 'spÃ©cifiquement', 'cas'],
            'es': ['ejemplo', 'por ejemplo', 'especÃ­ficamente', 'caso']
        }
        
        if language not in example_patterns:
            return 0.0
        
        text_lower = text.lower()
        matches = sum(1 for pattern in example_patterns[language] 
                     if pattern.lower() in text_lower)
        
        return min(1.0, matches / 2.0)  # 2å›ã§æº€ç‚¹
    
    def _analyze_recommendation_strength(self, text: str, language: str) -> RecommendationStrength:
        """æ¨å¥¨å¼·åº¦ã®åˆ†æ"""
        confidence_score = self.calculate_recommendation_confidence(text, language)
        
        if confidence_score >= 0.8:
            return RecommendationStrength.VERY_STRONG
        elif confidence_score >= 0.6:
            return RecommendationStrength.STRONG
        elif confidence_score >= 0.4:
            return RecommendationStrength.MODERATE
        elif confidence_score >= 0.2:
            return RecommendationStrength.WEAK
        else:
            return RecommendationStrength.NONE
    
    def _extract_reasoning_text(self, analysis_text: str, language: str) -> str:
        """æ¨å¥¨ç†ç”±ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡º"""
        # æ¨å¥¨éƒ¨åˆ†ã®å‰å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        lines = analysis_text.split('\n')
        reasoning_lines = []
        
        for i, line in enumerate(lines):
            # æ¨å¥¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€è¡Œã¨ãã®å‰å¾Œã‚’å–å¾—
            if any(keyword in line.lower() for keyword in ['æ¨å¥¨', 'recommend', 'æœ€é©', 'best']):
                # å‰ã®è¡Œ
                if i > 0:
                    reasoning_lines.append(lines[i-1])
                reasoning_lines.append(line)
                # æ¬¡ã®è¡Œ
                if i < len(lines) - 1:
                    reasoning_lines.append(lines[i+1])
        
        if reasoning_lines:
            return ' '.join(reasoning_lines).strip()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®100æ–‡å­—
        return analysis_text[:100] + "..." if len(analysis_text) > 100 else analysis_text
    
    def _count_pattern_matches(self, text: str, language: str) -> int:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        if language not in self.multilingual_patterns:
            return 0
        
        count = 0
        for pattern in self.multilingual_patterns[language]:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            count += len(list(matches))
        
        return count
    
    def _count_reason_keywords(self, text: str, language: str) -> int:
        """ç†ç”±ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        text_lower = text.lower()
        count = 0
        
        for reason, lang_keywords in self.reason_keywords.items():
            if language in lang_keywords:
                for keyword in lang_keywords[language]:
                    count += text_lower.count(keyword.lower())
        
        return count


# ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
if __name__ == "__main__":
    print("ğŸ¯ é«˜åº¦Geminiåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    
    engine = AdvancedGeminiAnalysisEngine()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            'text': """3ã¤ã®ç¿»è¨³ã‚’è©³ç´°ã«æ¯”è¼ƒåˆ†æã—ãŸçµæœã€Enhancedç¿»è¨³ãŒæœ€ã‚‚è‡ªç„¶ã§æ–‡è„ˆã«é©ã—ã¦ãŠã‚Šã€
                      ç‰¹ã«ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã§ã®ä¸å¯§ã•ã¨æ­£ç¢ºæ€§ã®è¦³ç‚¹ã‹ã‚‰æ¨å¥¨ã—ã¾ã™ã€‚
                      ChatGPTã¯è‹¥å¹²ç¡¬ã„è¡¨ç¾ã€Geminiã¯è‡ªç„¶ã ãŒå°‘ã—ç •ã‘ãŸå°è±¡ã§ã™ã€‚""",
            'language': 'ja'
        },
        {
            'text': """After thorough analysis, I would recommend the Enhanced translation
                      for its superior clarity and professional tone. While ChatGPT provides
                      good accuracy, Enhanced better captures the nuanced meaning.""",
            'language': 'en'
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ({test_case['language']}):")
        
        # æ§‹é€ åŒ–æ¨å¥¨æŠ½å‡º
        result = engine.extract_structured_recommendations(
            test_case['text'], 
            test_case['language']
        )
        
        print(f"æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³: {result.recommended_engine}")
        print(f"ä¿¡é ¼åº¦: {result.confidence_score:.3f}")
        print(f"å¼·åº¦: {result.strength_level.value}")
        print(f"ä¸»è¦ç†ç”±: {[r.value for r in result.primary_reasons]}")
        print(f"å‰¯æ¬¡ç†ç”±: {[r.value for r in result.secondary_reasons]}")
        
        # å¤šè¨€èªè§£æ
        multilingual_result = engine.parse_multilingual_analysis(
            test_case['text'], 
            test_case['language']
        )
        
        print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæ•°: {multilingual_result['text_analysis']['total_matches']}")
        print(f"ä¿¡é ¼åº¦æŒ‡æ¨™: {multilingual_result['text_analysis']['confidence_indicators']}")
    
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº† - é«˜åº¦åˆ†æã‚¨ãƒ³ã‚¸ãƒ³æ­£å¸¸å‹•ä½œ")