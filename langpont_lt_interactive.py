import os
import sys
from dotenv import load_dotenv

# ğŸ†• ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®å®šç¾©
VERSION_INFO = {
    "file_name": "langpont_lt_interactive.py",
    "version": "ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ä»˜ãè»½é‡ç‰ˆ", 
    "created_date": "2025/5/30",
    "optimization": "27%é«˜é€ŸåŒ– + 90%ã‚³ã‚¹ãƒˆå‰Šæ¸› + ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•æ©Ÿèƒ½",
    "status": "é‹ç”¨ä¸­"
}

# .env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã“ã®1è¡Œã§ååˆ†ï¼‰
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))

from flask import Flask, render_template, request, session, redirect, url_for, jsonify
from openai import OpenAI
from textwrap import dedent
from concurrent.futures import ThreadPoolExecutor
from datetime import timedelta
import requests
import time
import re
from labels import labels

# APIã‚­ãƒ¼
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# Flask
app = Flask(__name__)
app.config["TEMPLATES_AUTO_RELOAD"] = True

app.secret_key = os.environ.get("FLASK_SECRET_KEY", "default_secret_key")
app.permanent_session_lifetime = timedelta(hours=1)

# OpenAI client
client = OpenAI(api_key=api_key)

# ====== ğŸ†• ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ  ======

class TranslationContext:
    """ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def save_context(input_text, translations, analysis, metadata):
        """ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜"""
        session["translation_context"] = {
            "input_text": input_text,
            "translations": translations,
            "analysis": analysis,
            "metadata": metadata,
            "timestamp": time.time()
        }
        
    @staticmethod
    def get_context():
        """ä¿å­˜ã•ã‚ŒãŸç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        return session.get("translation_context", {})
    
    @staticmethod
    def clear_context():
        """ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢"""
        session.pop("translation_context", None)

class QuestionAnalyzer:
    """è³ªå•ã®ç¨®é¡ã‚’åˆ†æã—ã€é©åˆ‡ãªå‡¦ç†ã‚’æ±ºå®šã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    # è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
    PATTERNS = {
        "style_adjustment": [
            r"(è¦ªè¿‘æ„Ÿ|è¦ªã—ã¿|ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼|ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«).*è¡¨ç¾",
            r"(ãƒ•ã‚©ãƒ¼ãƒãƒ«|ä¸å¯§|æ•¬èª).*è¡¨ç¾",
            r"ã‚‚ã£ã¨.*ãª.*è¡¨ç¾",
            r"(å„ªã—ã|å³ã—ã|å¼·ã).*è¡¨ç¾",
            r"(å£èª¿|æ–‡ä½“|ãƒˆãƒ¼ãƒ³).*å¤‰",
        ],
        "term_explanation": [
            r".*ã®.*æ„å‘³",
            r".*ã¨ã¯.*ä½•",  
            r".*ã«ã¤ã„ã¦.*èª¬æ˜",
            r".*ã®.*å®šç¾©",
            r"\d+ç•ªç›®.*æ„å‘³",
        ],
        "custom_translation": [
            r".*çµ„ã¿åˆã‚ã›",
            r".*æ··ãœ",
            r".*å‚è€ƒ.*æ–°ã—ã„",
            r".*è¦ç´ .*å–ã‚Šå…¥ã‚Œ",
            r".*ãƒ™ãƒ¼ã‚¹.*èª¿æ•´",
        ],
        "comparison": [
            r"é•ã„.*ä½•",
            r"ã©ã¡ã‚‰.*è‰¯ã„",
            r"æ¯”è¼ƒ.*ã—ã¦",
            r".*ã¨.*ã©ã†é•ã†",
        ],
        "contextual_adjustment": [
            r".*å ´é¢.*é©åˆ‡",
            r".*çŠ¶æ³.*ä½¿ã†",
            r".*ç›¸æ‰‹.*å¿œã˜",
            r"ãƒ“ã‚¸ãƒã‚¹.*å ´é¢",
            r"ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ.*å ´é¢",
        ]
    }
    
    @classmethod
    def analyze_question(cls, question):
        """è³ªå•ã‚’åˆ†æã—ã¦å‡¦ç†ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š"""
        question_lower = question.lower()
        
        for question_type, patterns in cls.PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, question_lower):
                    return question_type
        
        return "general_question"
    
    @classmethod
    def extract_reference_number(cls, question):
        """è³ªå•ã‹ã‚‰ç¿»è¨³ç•ªå·ã‚’æŠ½å‡ºï¼ˆã€Œ1ç•ªç›®ã®ã€ã€Œ2ã¤ç›®ã®ã€ãªã©ï¼‰"""
        number_patterns = [
            r"(\d+)ç•ªç›®",
            r"(\d+)ã¤ç›®",
            r"(\d+)å€‹ç›®",
            r"ç¬¬(\d+)",
        ]
        
        for pattern in number_patterns:
            match = re.search(pattern, question)
            if match:
                return int(match.group(1))
        
        return None

class InteractiveTranslationProcessor:
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªç¿»è¨³å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, client):
        self.client = client
    
    def process_question(self, question, context):
        """è³ªå•ã‚’å‡¦ç†ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        
        question_type = QuestionAnalyzer.analyze_question(question)
        reference_number = QuestionAnalyzer.extract_reference_number(question)
        
        print(f"ğŸ§  è³ªå•ã‚¿ã‚¤ãƒ—: {question_type}")
        print(f"ğŸ”¢ å‚ç…§ç•ªå·: {reference_number}")
        
        # å‡¦ç†ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
        if question_type == "style_adjustment":
            return self._handle_style_adjustment(question, context)
        elif question_type == "term_explanation":
            return self._handle_term_explanation(question, context, reference_number)
        elif question_type == "custom_translation":
            return self._handle_custom_translation(question, context)
        elif question_type == "comparison":
            return self._handle_comparison(question, context)
        elif question_type == "contextual_adjustment":
            return self._handle_contextual_adjustment(question, context)
        else:
            return self._handle_general_question(question, context)
    
    def _handle_style_adjustment(self, question, context):
        """æ–‡ä½“èª¿æ•´ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        
        translations = context.get("translations", {})
        input_text = context.get("input_text", "")
        metadata = context.get("metadata", {})
        
        # èª¿æ•´è¦æ±‚ã‚’åˆ†æ
        style_keywords = {
            "è¦ªè¿‘æ„Ÿ": "è¦ªã—ã¿ã‚„ã™ãè¦ªè¿‘æ„Ÿã®ã‚ã‚‹",
            "è¦ªã—ã¿": "è¦ªã—ã¿ã‚„ã™ãè¦ªè¿‘æ„Ÿã®ã‚ã‚‹", 
            "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼": "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãª",
            "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«": "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸ",
            "ãƒ•ã‚©ãƒ¼ãƒãƒ«": "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãª",
            "ä¸å¯§": "ä¸å¯§ã§æ•¬æ„ã®ã“ã‚‚ã£ãŸ",
            "æ•¬èª": "æ•¬èªã‚’ä½¿ã£ãŸéå¸¸ã«ä¸å¯§ãª",
            "å„ªã—ã": "å„ªã—ãè¦ªåˆ‡ãª",
            "å³ã—ã": "å³æ ¼ã§å¼·ã„",
            "å¼·ã": "å¼·ãæ–­å®šçš„ãª",
            "ãƒ“ã‚¸ãƒã‚¹": "ãƒ“ã‚¸ãƒã‚¹ã‚·ãƒ¼ãƒ³ã«é©ã—ãŸ"
        }
        
        detected_style = "ã‚ˆã‚Šè‡ªç„¶ã§é©åˆ‡ãª"
        for keyword, style_desc in style_keywords.items():
            if keyword in question:
                detected_style = style_desc
                break
        
        # æ–°ã—ã„ç¿»è¨³ã‚’ç”Ÿæˆ
        source_lang = metadata.get("source_lang", "ja")
        target_lang = metadata.get("target_lang", "fr")
        
        lang_map = {"ja": "æ—¥æœ¬èª", "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª", "en": "è‹±èª"}
        source_label = lang_map.get(source_lang, source_lang)
        target_label = lang_map.get(target_lang, target_lang)
        
        prompt = f"""ä»¥ä¸‹ã®{source_label}ã®æ–‡ç« ã‚’ã€{detected_style}ã‚¹ã‚¿ã‚¤ãƒ«ã§{target_label}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

å…ƒã®æ–‡: {input_text}

å‚è€ƒã¨ãªã‚‹æ—¢å­˜ã®ç¿»è¨³:
1. ChatGPTç‰ˆ: {translations.get('chatgpt', '')}
2. æ”¹å–„ç‰ˆ: {translations.get('enhanced', '')}
3. Geminiç‰ˆ: {translations.get('gemini', '')}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {question}

{detected_style}è¡¨ç¾ã§æ–°ã—ã„{target_label}ç¿»è¨³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ç¿»è¨³æ–‡ã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=400
            )
            
            new_translation = response.choices[0].message.content.strip()
            
            return {
                "type": "style_adjustment",
                "result": new_translation,
                "explanation": f"ã€Œ{detected_style}ã€ã®ã‚¹ã‚¿ã‚¤ãƒ«ã§æ–°ã—ã„ç¿»è¨³ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
            }
            
        except Exception as e:
            return {
                "type": "error",
                "result": f"æ–‡ä½“èª¿æ•´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _handle_term_explanation(self, question, context, reference_number):
        """ç”¨èªè§£èª¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        
        translations = context.get("translations", {})
        input_text = context.get("input_text", "")
        metadata = context.get("metadata", {})
        
        # å‚ç…§ã™ã‚‹ç¿»è¨³ã‚’æ±ºå®š
        translation_to_explain = ""
        translation_label = ""
        
        if reference_number == 1:
            translation_to_explain = translations.get('chatgpt', '')
            translation_label = "1ç•ªç›®ï¼ˆChatGPTï¼‰"
        elif reference_number == 2:
            translation_to_explain = translations.get('enhanced', '')
            translation_label = "2ç•ªç›®ï¼ˆæ”¹å–„ç‰ˆï¼‰"
        elif reference_number == 3:
            translation_to_explain = translations.get('gemini', '')
            translation_label = "3ç•ªç›®ï¼ˆGeminiï¼‰"
        else:
            # å…¨ç¿»è¨³ã‹ã‚‰è©²å½“ã™ã‚‹ç”¨èªã‚’æ¢ã™
            all_translations = f"1ç•ªç›®: {translations.get('chatgpt', '')}\n2ç•ªç›®: {translations.get('enhanced', '')}\n3ç•ªç›®: {translations.get('gemini', '')}"
            translation_to_explain = all_translations
            translation_label = "å…¨ç¿»è¨³"
        
        # è³ªå•ã‹ã‚‰ç”¨èªã‚’æŠ½å‡º
        import re
        term_match = re.search(r'ã€Œ([^ã€]+)ã€|([A-Za-z]+)', question)
        if term_match:
            term = term_match.group(1) or term_match.group(2)
        else:
            term = "æŒ‡å®šã•ã‚ŒãŸç”¨èª"
        
        prompt = f"""ä»¥ä¸‹ã®ç¿»è¨³çµæœã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚

å…ƒã®æ–‡: {input_text}

ç¿»è¨³çµæœ:
{translation_to_explain}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {question}

ç‰¹ã«ã€Œ{term}ã€ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã“ã®ç”¨èªã®ï¼š
1. æ„å‘³ãƒ»å®šç¾©
2. ãªãœã“ã®ç¿»è¨³ã§ã“ã®ç”¨èªãŒé¸ã°ã‚ŒãŸã®ã‹
3. ä»–ã®è¡¨ç¾æ–¹æ³•ãŒã‚ã‚Œã°ä»£æ›¿æ¡ˆã‚‚æç¤º

å›ç­”ã¯æ—¥æœ¬èªã§ã€åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=500
            )
            
            explanation = response.choices[0].message.content.strip()
            
            return {
                "type": "term_explanation",
                "result": explanation,
                "reference": translation_label
            }
            
        except Exception as e:
            return {
                "type": "error", 
                "result": f"ç”¨èªè§£èª¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _handle_custom_translation(self, question, context):
        """ã‚«ã‚¹ã‚¿ãƒ ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        
        translations = context.get("translations", {})
        input_text = context.get("input_text", "")
        metadata = context.get("metadata", {})
        
        source_lang = metadata.get("source_lang", "ja")
        target_lang = metadata.get("target_lang", "fr")
        
        lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
        target_label = lang_map.get(target_lang, target_lang)
        
        prompt = f"""Create a new {target_label} translation by combining elements from the existing translations as requested by the user.

Original text: {input_text}

Existing translations:
1. ChatGPT: {translations.get('chatgpt', '')}
2. Enhanced: {translations.get('enhanced', '')}
3. Gemini: {translations.get('gemini', '')}

User request: {question}

Create a new translation that incorporates the requested elements. Provide only the new {target_label} translation."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=400
            )
            
            custom_translation = response.choices[0].message.content.strip()
            
            return {
                "type": "custom_translation",
                "result": custom_translation,
                "explanation": "æ—¢å­˜ã®ç¿»è¨³ã‚’çµ„ã¿åˆã‚ã›ã¦æ–°ã—ã„ç¿»è¨³ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
            }
            
        except Exception as e:
            return {
                "type": "error",
                "result": f"ã‚«ã‚¹ã‚¿ãƒ ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _handle_comparison(self, question, context):
        """ç¿»è¨³æ¯”è¼ƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        
        translations = context.get("translations", {})
        analysis = context.get("analysis", "")
        
        prompt = f"""User is asking for a comparison of these translations:

1. ChatGPT: {translations.get('chatgpt', '')}
2. Enhanced: {translations.get('enhanced', '')}  
3. Gemini: {translations.get('gemini', '')}

Previous analysis: {analysis}

User question: {question}

Provide a detailed comparison in Japanese focusing on what the user is specifically asking about."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo", 
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=600
            )
            
            comparison = response.choices[0].message.content.strip()
            
            return {
                "type": "comparison",
                "result": comparison
            }
            
        except Exception as e:
            return {
                "type": "error",
                "result": f"æ¯”è¼ƒåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _handle_contextual_adjustment(self, question, context):
        """æ–‡è„ˆèª¿æ•´ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        
        translations = context.get("translations", {})
        input_text = context.get("input_text", "")
        metadata = context.get("metadata", {})
        
        source_lang = metadata.get("source_lang", "ja")
        target_lang = metadata.get("target_lang", "fr")
        
        lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
        target_label = lang_map.get(target_lang, target_lang)
        
        prompt = f"""Create a {target_label} translation that is appropriate for the specific context/situation mentioned by the user.

Original text: {input_text}

Existing translations:
1. ChatGPT: {translations.get('chatgpt', '')}
2. Enhanced: {translations.get('enhanced', '')}
3. Gemini: {translations.get('gemini', '')}

User's context request: {question}

Provide a new {target_label} translation that is appropriate for the specified context/situation."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=400
            )
            
            contextual_translation = response.choices[0].message.content.strip()
            
            return {
                "type": "contextual_adjustment",
                "result": contextual_translation,
                "explanation": "æŒ‡å®šã•ã‚ŒãŸå ´é¢ãƒ»çŠ¶æ³ã«é©ã—ãŸç¿»è¨³ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
            }
            
        except Exception as e:
            return {
                "type": "error",
                "result": f"æ–‡è„ˆèª¿æ•´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _handle_general_question(self, question, context):
        """ä¸€èˆ¬çš„ãªè³ªå•ã‚’å‡¦ç†ï¼ˆå‹•çš„è¨€èªå¯¾å¿œç‰ˆï¼‰"""
        
        translations = context.get("translations", {})
        input_text = context.get("input_text", "")
        analysis = context.get("analysis", "")
        metadata = context.get("metadata", {})
        
        # ğŸ†• ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰è¡¨ç¤ºè¨€èªã‚’å–å¾—
        display_lang = session.get("lang", "jp")
        response_lang_map = {
            "jp": "Japanese",
            "en": "English", 
            "fr": "French"
        }
        response_language = response_lang_map.get(display_lang, "Japanese")
        
        # çŠ¶æ³å¤‰æ›´ã‚„æ–°ã—ã„ç¿»è¨³ãŒå¿…è¦ã‹ã‚’åˆ¤å®š
        situation_change_keywords = [
            "ä¸Šå¸", "éƒ¨ä¼š", "æŒ‡ç¤º", "ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³", "å ´åˆ", "çŠ¶æ³",
            "ã‚‚ã£ã¨", "ã‚ˆã‚Š", "é©åˆ‡", "æ–°ã—ã„", "åˆ¥ã®", "ä»–ã®",
            "boss", "supervisor", "situation", "context", "case", "more", "better", "new", "different",
            "patron", "superviseur", "situation", "contexte", "cas", "plus", "mieux", "nouveau", "diffÃ©rent"
        ]
        
        needs_new_translation = any(keyword in question.lower() for keyword in situation_change_keywords)
        
        if needs_new_translation:
            # æ–°ã—ã„ç¿»è¨³ã‚’ç”Ÿæˆ
            source_lang = metadata.get("source_lang", "ja")
            target_lang = metadata.get("target_lang", "fr")
            
            lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
            source_label = lang_map.get(source_lang, source_lang)
            target_label = lang_map.get(target_lang, target_lang)
            
            # ğŸ†• å‹•çš„è¨€èªå¯¾å¿œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = f"""Based on the user's question, create a new {target_label} translation suitable for the new situation/context.

IMPORTANT: Respond entirely in {response_language}.

Original {source_label} text: {input_text}

Existing translations:
1. ChatGPT version: {translations.get('chatgpt', '')}
2. Enhanced version: {translations.get('enhanced', '')}
3. Gemini version: {translations.get('gemini', '')}

User's question: {question}

Based on the question content, create a {target_label} translation suitable for the new situation/context.

Response format (in {response_language}):
1. New {target_label} translation for the situation: [translation]
2. Reason for selection: [explanation of why this translation is appropriate]

Always provide a new {target_label} translation and respond entirely in {response_language}."""

            try:
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=600
                )
                
                answer = response.choices[0].message.content.strip()
                
                return {
                    "type": "contextual_adjustment",
                    "result": answer
                }
                
            except Exception as e:
                error_messages = {
                    "jp": f"æ–°ã—ã„ç¿»è¨³ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "en": f"Error occurred while generating new translation: {str(e)}",
                    "fr": f"Erreur lors de la gÃ©nÃ©ration d'une nouvelle traduction: {str(e)}"
                }
                return {
                    "type": "error",
                    "result": error_messages.get(display_lang, error_messages["jp"])
                }
        
        else:
            # å¾“æ¥ã®ä¸€èˆ¬è³ªå•å‡¦ç†ï¼ˆå‹•çš„è¨€èªå¯¾å¿œï¼‰
            prompt = f"""Answer the user's question about these translations.

IMPORTANT: Respond entirely in {response_language}.

Original text: {input_text}

Translation results:
1. ChatGPT: {translations.get('chatgpt', '')}
2. Enhanced: {translations.get('enhanced', '')}
3. Gemini: {translations.get('gemini', '')}

Previous analysis: {analysis}

User's question: {question}

Provide a helpful answer in {response_language}."""

            try:
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=500
                )
                
                answer = response.choices[0].message.content.strip()
                
                return {
                    "type": "general_question",
                    "result": answer
                }
                
            except Exception as e:
                error_messages = {
                    "jp": f"è³ªå•å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "en": f"Error occurred while processing question: {str(e)}",
                    "fr": f"Erreur lors du traitement de la question: {str(e)}"
                }
                return {
                    "type": "error",
                    "result": error_messages.get(display_lang, error_messages["jp"])
                }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
interactive_processor = InteractiveTranslationProcessor(client)

# ====== æ—¢å­˜ã®ç¿»è¨³é–¢æ•°ç¾¤ï¼ˆå¤‰æ›´ãªã—ï¼‰ ======

def f_translate_to_lightweight_premium(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """ğŸŒŸ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰ˆ: æ–‡åŒ–çš„é…æ…®ã‚’é‡è¦–ã—ãŸé«˜å“è³ªç¿»è¨³é–¢æ•°ï¼ˆèƒŒæ™¯æƒ…å ±å¼·åŒ–ç‰ˆï¼‰"""
    
    print(f"ğŸŒŸ f_translate_to_lightweight_premium é–‹å§‹ - {source_lang} -> {target_lang}")
    
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    target_label = lang_map.get(target_lang, target_lang)
    
    if partner_message.strip() or context_info.strip():
        context_sections = []
        
        if partner_message.strip():
            context_sections.append(f"PREVIOUS CONVERSATION:\n{partner_message.strip()}")
        
        if context_info.strip():
            context_sections.append(f"BACKGROUND & RELATIONSHIP:\n{context_info.strip()}")
        
        context_text = "\n\n".join(context_sections)
        
        prompt = f"""You are a professional translator specializing in culturally appropriate {target_label} translation.

IMPORTANT CONTEXT TO CONSIDER:
{context_text}

TRANSLATION INSTRUCTIONS:
- Consider the relationship and background information carefully
- Use appropriate formality level based on the context
- Ensure cultural sensitivity and business appropriateness
- Translate naturally while respecting the contextual nuances

TRANSLATE TO {target_label.upper()}:
{input_text}

Remember: The context above is crucial for determining the appropriate tone, formality, and cultural considerations."""
        
        print(f"ğŸ§± ãƒ—ãƒ¬ãƒŸã‚¢ãƒ èƒŒæ™¯å¼·åŒ–ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
        print(f"ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè©³ç´°: {context_text[:100]}...")
        
    else:
        prompt = f"Professional, culturally appropriate translation to {target_label}:\n\n{input_text}"
        print(f"ğŸ§± ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚·ãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
    
    estimated_tokens = len(prompt.split()) * 1.3
    print(f"ğŸ“Š ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰ˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f}")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=400
        )
        
        result = response.choices[0].message.content.strip()
        
        if not result or len(result.strip()) < 2:
            raise ValueError("ç¿»è¨³çµæœãŒçŸ­ã™ãã¾ã™")
            
        if result.strip() == input_text.strip():
            raise ValueError("ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        print(f"âœ… ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç¿»è¨³å®Œäº†: {result[:50]}...")
        return result

    except Exception as e:
        print(f"âŒ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰ˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        print("ğŸ”„ æ¨™æº–æ”¹å–„ç‰ˆã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
        return f_translate_to_lightweight_normal(input_text, source_lang, target_lang, partner_message, context_info)

def f_translate_to_lightweight_normal(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """ğŸš€ æ¨™æº–æ”¹å–„ç‰ˆ: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’é‡è¦–ã—ãŸãƒãƒ©ãƒ³ã‚¹å‹ç¿»è¨³é–¢æ•°ï¼ˆèƒŒæ™¯æƒ…å ±å¼·åŒ–ç‰ˆï¼‰"""
    
    print(f"ğŸš€ f_translate_to_lightweight_normal é–‹å§‹ - {source_lang} -> {target_lang}")
    
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    target_label = lang_map.get(target_lang, target_lang)
    
    if partner_message.strip() or context_info.strip():
        context_info_clean = []
        
        if partner_message.strip():
            context_info_clean.append(f"Previous: {partner_message.strip()}")
        
        if context_info.strip():
            context_info_clean.append(f"Background: {context_info.strip()}")
        
        context_summary = " | ".join(context_info_clean)
        
        prompt = f"""Translate to {target_label}, carefully considering this context for appropriate tone and formality:

CONTEXT: {context_summary}

Based on the context above, translate this text with appropriate cultural sensitivity:

{input_text}"""
        
        print(f"ğŸ§± æ¨™æº–èƒŒæ™¯å¼·åŒ–ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
        print(f"ğŸ“ èƒŒæ™¯è¦ç´„: {context_summary}")
        
    else:
        prompt = f"Translate to {target_label}:\n{input_text}"
        print(f"ğŸ§± æ¨™æº–ã‚·ãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
    
    estimated_tokens = len(prompt.split()) * 1.3
    print(f"ğŸ“Š æ¨™æº–ç‰ˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f}")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=400
        )
        
        result = response.choices[0].message.content.strip()
        
        if not result or len(result.strip()) < 2:
            raise ValueError("ç¿»è¨³çµæœãŒçŸ­ã™ãã¾ã™")
            
        if result.strip() == input_text.strip():
            raise ValueError("ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        print(f"âœ… æ¨™æº–ç¿»è¨³å®Œäº†: {result[:50]}...")
        return result

    except Exception as e:
        print(f"âŒ æ¨™æº–ç‰ˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise

def update_usage_count(mode):
    """ç¿»è¨³ä½¿ç”¨å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆèª²é‡‘è¨ˆç®—ç”¨ï¼‰"""
    
    if mode == "premium":
        session["premium_usage_count"] = session.get("premium_usage_count", 0) + 1
        print(f"ğŸ“ˆ Premiumä½¿ç”¨å›æ•°: {session['premium_usage_count']}")
    else:
        session["normal_usage_count"] = session.get("normal_usage_count", 0) + 1
        print(f"ğŸ“ˆ Normalä½¿ç”¨å›æ•°: {session['normal_usage_count']}")

def f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """ğŸ”„ ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆå¯¾å¿œãƒ¡ã‚¤ãƒ³ç¿»è¨³é–¢æ•°"""
    
    translation_mode = session.get("translation_mode", "normal")
    
    print(f"ğŸ”„ ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰: {translation_mode.upper()}")
    
    if translation_mode == "premium":
        return f_translate_to_lightweight_premium(input_text, source_lang, target_lang, partner_message, context_info)
    else:
        return f_translate_to_lightweight_normal(input_text, source_lang, target_lang, partner_message, context_info)

def f_reverse_translation(translated_text, target_lang, source_lang):
    """ğŸš€ è»½é‡ç‰ˆé€†ç¿»è¨³é–¢æ•°ï¼ˆè‹±èªæœ€å°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰"""
    if not translated_text:
        print("âš ï¸ f_reverse_translation(è»½é‡ç‰ˆ): ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã—ãŸ")
        return "(ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™)"

    print(f"ğŸ”„ f_reverse_translation(è»½é‡ç‰ˆ) å®Ÿè¡Œ:")
    print(f" - translated_text: {translated_text}")
    print(f" - source_lang: {source_lang}")
    print(f" - target_lang: {target_lang}")

    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    source_label = lang_map.get(source_lang, source_lang)
    
    prompt = f"Translate to {source_label}:\n{translated_text}"

    estimated_tokens = len(prompt.split()) * 1.3
    print(f"ğŸ§± è»½é‡ç‰ˆé€†ç¿»è¨³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº† (æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f})")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=300
        )
        
        result = response.choices[0].message.content.strip()
        
        if not result or len(result.strip()) < 2:
            raise ValueError("é€†ç¿»è¨³çµæœãŒçŸ­ã™ãã¾ã™")
        
        print("ğŸ“¥ è»½é‡ç‰ˆé€†ç¿»è¨³çµæœ:", result)
        return result

    except Exception as e:
        print("âŒ f_reverse_translation(è»½é‡ç‰ˆ) ã‚¨ãƒ©ãƒ¼:", str(e))
        return f"é€†ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}"

def f_better_translation(text_to_improve, source_lang="fr", target_lang="en"):
    """ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šè‡ªç„¶ã«æ”¹å–„ã™ã‚‹é–¢æ•°"""
    lang_map = {"ja": "æ—¥æœ¬èª", "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª", "en": "è‹±èª"}

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    print(f"âœ¨ f_better_translation é–‹å§‹:")
    print(f" - text_to_improve: {text_to_improve}")
    print(f" - source_lang: {source_lang} ({source_label})")
    print(f" - target_lang: {target_lang} ({target_label})")

    system_message = f"{target_label}ã®ç¿»è¨³ã‚’ã‚ˆã‚Šè‡ªç„¶ã«æ”¹å–„ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
    user_prompt = f"ã“ã®{target_label}ã‚’ã‚‚ã£ã¨è‡ªç„¶ãª{target_label}ã®æ–‡ç« ã«æ”¹å–„ã—ã¦ãã ã•ã„ï¼š{text_to_improve}"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_prompt}
        ]
    )

    result = response.choices[0].message.content.strip()
    print(f"âœ… æ”¹å–„çµæœ: {result}")
    return result

def f_translate_with_gemini(text, source_lang, target_lang, partner_message="", context_info=""):
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        return "âš ï¸ Gemini APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“"

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={GEMINI_API_KEY}"

    prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãª{source_lang}â†’{target_lang}ã®ç¿»è¨³è€…ã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ï¼ˆç›´å‰ã®ã‚„ã‚Šã¨ã‚Šã€èƒŒæ™¯ï¼‰ã‚’å‚è€ƒã«ã€
**{target_lang}ã®ç¿»è¨³æ–‡ã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆè§£èª¬ã‚„æ³¨é‡ˆã¯ä¸è¦ã§ã™ï¼‰ã€‚

--- ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ---
{partner_message or "(ãªã—)"}

--- èƒŒæ™¯æƒ…å ± ---
{context_info or "(ãªã—)"}

--- ç¿»è¨³å¯¾è±¡ ---
{text}
    """.strip()

    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    else:
        return f"Gemini API error: {response.status_code} - {response.text}"

def f_gemini_3way_analysis(translated_text, better_translation, gemini_translation):
    """3ã¤ã®ç¿»è¨³çµæœã‚’èƒŒæ™¯æƒ…å ±ã®å†…å®¹ã«å¿œã˜ã¦å‹•çš„ã«åˆ†æã™ã‚‹é–¢æ•°"""

    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        return "âš ï¸ Gemini APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“"

    display_lang = session.get("lang", "jp")
    
    print(f"ğŸŒ Geminiåˆ†æè¡¨ç¤ºè¨€èª: {display_lang}")
    
    analysis_lang_map = {
        "jp": "Japanese",
        "en": "English", 
        "fr": "French"
    }
    
    analysis_language = analysis_lang_map.get(display_lang, "Japanese")
    
    language_pair = session.get("language_pair", "ja-fr")
    
    try:
        source_lang, target_lang = language_pair.split("-")
        print(f"ğŸ” ç¿»è¨³è¨€èªãƒšã‚¢: {source_lang} -> {target_lang}")
    except:
        source_lang = session.get("source_lang", "ja")
        target_lang = session.get("target_lang", "fr") 
        print(f"âš ï¸ language_pairåˆ†å‰²å¤±æ•—ã€å€‹åˆ¥å–å¾—: {source_lang} -> {target_lang}")

    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    total_input = translated_text + better_translation + gemini_translation
    warning = "âš ï¸ å…¥åŠ›ãŒé•·ã„ãŸã‚ã€åˆ†æçµæœã¯è¦ç´„ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n" if len(total_input) > 2000 else ""

    # èƒŒæ™¯æƒ…å ±ã‚’å–å¾—
    input_text = session.get("input_text", "")
    partner_message = session.get("partner_message", "")
    context_info = session.get("context_info", "")

    # ç¿»è¨³è¨€èªã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå†…å®¹åˆ†æç”¨ï¼‰
    lang_map = {
        "ja": "Japanese", "fr": "French", "en": "English",
        "es": "Spanish", "de": "German", "it": "Italian",
        "pt": "Portuguese", "ru": "Russian", "ko": "Korean", "zh": "Chinese"
    }

    # ç¿»è¨³å¯¾è±¡è¨€èªãƒ©ãƒ™ãƒ«å–å¾—
    source_label = lang_map.get(source_lang, source_lang.capitalize())
    target_label = lang_map.get(target_lang, target_lang.capitalize())
    
    print(f"ğŸŒ ç¿»è¨³å¯¾è±¡: {source_label} -> {target_label}")
    print(f"ğŸ“ åˆ†æè¡¨ç¤ºè¨€èª: {analysis_language}")

    # èƒŒæ™¯æƒ…å ±ã®å†…å®¹ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    if context_info.strip():
        context_section = f"""
CONTEXT PROVIDED:
- Previous conversation: {partner_message or "None"}
- Situation/Background: {context_info.strip()}

Based on this specific context, analyze which translation is most appropriate."""
        
        analysis_instruction = "Analyze: formality, tone, and appropriateness for the given situation/relationship."
        
    else:
        context_section = f"""
CONTEXT: General conversation (no specific context provided)
- Previous conversation: {partner_message or "None"}

Analyze as general daily conversation."""
        
        analysis_instruction = "Analyze: formality, tone, and general conversational appropriateness."

    prompt = f"""Compare these 3 {target_label} translations considering the specific context. 

IMPORTANT: Respond in {analysis_language} with clear, readable format using bullet points and clear sections.

ORIGINAL TEXT ({source_label}): {input_text}

{context_section}

TRANSLATIONS:
1. ChatGPT: {translated_text}
2. ChatGPT Enhanced: {better_translation}  
3. Gemini: {gemini_translation}

{analysis_instruction}

CONCLUSION: Which translation best fits this specific situation and why? 

REMEMBER: Your entire response must be in {analysis_language}."""

    print("ğŸ“¤ Gemini è¨€èªå¯¾å¿œåˆ†æ:")
    print(f" - ç¿»è¨³è¨€èªãƒšã‚¢: {source_lang} -> {target_lang}")
    print(f" - åˆ†æè¡¨ç¤ºè¨€èª: {analysis_language}")
    print(f" - æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(prompt.split()) * 1.3:.0f}")

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        if response.status_code == 200:
            result_text = response.json()["candidates"][0]["content"]["parts"][0]["text"]
            print(f"ğŸ“¥ Gemini è¨€èªå¯¾å¿œåˆ†æçµæœ: {result_text[:100]}...")
            return warning + result_text.strip()
        else:
            error_msg = f"âš ï¸ Gemini API error: {response.status_code} - {response.text}"
            print("âŒ", error_msg)
            return error_msg

    except requests.exceptions.Timeout:
        return "âš ï¸ Gemini APIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ30ç§’ä»¥å†…ã«å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"

    except Exception as e:
        import traceback
        error_msg = f"âš ï¸ Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(error_msg)
        print(traceback.format_exc())
        return error_msg

# ====== ğŸ†• ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ======

@app.route("/clear_chat_history", methods=["POST"])
def clear_chat_history():
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ä¿æŒï¼‰"""
    try:
        # ğŸ”§ ä¿®æ­£: ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã¿ã‚¯ãƒªã‚¢ï¼ˆç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ä¿æŒï¼‰
        session["chat_history"] = []
        
        # ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ä¿æŒã™ã‚‹ãŸã‚ã€TranslationContext.clear_context() ã¯å‘¼ã³å‡ºã•ãªã„
        
        return jsonify({
            "success": True,
            "message": "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"
        })
        
    except Exception as e:
        print(f"âŒ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        })

@app.route("/reverse_better_translation", methods=["POST"])
def reverse_better_translation():
    """æ”¹å–„ã•ã‚ŒãŸç¿»è¨³ã‚’é€†ç¿»è¨³ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        data = request.get_json() or {}
        improved_text = data.get("french_text", "")
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        print("ğŸ” reverse_better_translation:")
        print(" - improved_text:", improved_text)
        print(" - language_pair:", language_pair)
        print(" - source_lang:", source_lang)
        print(" - target_lang:", target_lang)

        # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
        if not improved_text:
            return jsonify({
                "success": False,
                "error": "é€†ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            })

        # âœ… æ”¹å–„ç¿»è¨³ã¯ target_lang ã®è¨€èªãªã®ã§ã€é€†ç¿»è¨³ã¯ target_lang â†’ source_lang
        reversed_text = f_reverse_translation(improved_text, target_lang, source_lang)

        print("ğŸ” æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³å¯¾è±¡:", improved_text)
        print("ğŸŸ¢ æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³çµæœ:", reversed_text)

        return jsonify({
            "success": True,
            "reversed_text": reversed_text
        })

    except Exception as e:
        import traceback
        print("âŒ reverse_better_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e)
        })

@app.route("/interactive_question", methods=["POST"])
def interactive_question():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè³ªå•ã‚’å‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json() or {}
        question = data.get("question", "").strip()
        
        if not question:
            return jsonify({
                "success": False,
                "error": "è³ªå•ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            })
        
        # ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        context = TranslationContext.get_context()
        
        if not context:
            return jsonify({
                "success": False,
                "error": "ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãšç¿»è¨³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            })
        
        print(f"ğŸ§  ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•å—ä¿¡: {question}")
        
        # è³ªå•ã‚’å‡¦ç†
        result = interactive_processor.process_question(question, context)
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        chat_history = session.get("chat_history", [])
        chat_history.append({
            "question": question,
            "answer": result.get("result", ""),
            "type": result.get("type", "general"),
            "timestamp": time.time()
        })
        session["chat_history"] = chat_history
        
        print(f"âœ… ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•å‡¦ç†å®Œäº†: {result.get('type')}")
        
        return jsonify({
            "success": True,
            "result": result,
            "chat_history": chat_history
        })
        
    except Exception as e:
        import traceback
        print(f"âŒ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e)
        })

# ====== æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆä¿®æ­£ç‰ˆï¼‰ ======

@app.route("/translate_chatgpt", methods=["POST"])
def translate_chatgpt_only():
    try:
        data = request.get_json() or {}
        input_text = data.get("japanese_text", "").strip()
        partner_message = data.get("partner_message", "")
        context_info = data.get("context_info", "")
        language_pair = data.get("language_pair", "ja-fr")  
        
        source_lang, target_lang = language_pair.split("-")  

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªã‚¢
        critical_keys = ["translated_text", "reverse_translated_text"]
        for key in critical_keys:
            session.pop(key, None)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
        session["source_lang"] = source_lang
        session["target_lang"] = target_lang
        session["language_pair"] = language_pair
        session["input_text"] = input_text
        session["partner_message"] = partner_message
        session["context_info"] = context_info

        print(f"ğŸŸ¦ [è»½é‡ç‰ˆ/translate_chatgpt] ç¿»è¨³å®Ÿè¡Œ: {source_lang} -> {target_lang}")
        print(f"ğŸ”µ å…¥åŠ›: {input_text[:30]}...")

        if not input_text:
            return {
                "success": False,
                "error": "ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
            }

        # ãƒ¢ãƒ¼ãƒ‰å–å¾—ã¨ä½¿ç”¨ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
        translation_mode = session.get("translation_mode", "normal")
        update_usage_count(translation_mode)

        # ç¿»è¨³å®Ÿè¡Œ
        translated = f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message, context_info)
        print(f"ğŸ”µ ç¿»è¨³çµæœ: {translated[:30]}...")
        
        # ç°¡å˜ãªæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        if translated.strip() == input_text.strip():
            print("âš ï¸ ç¿»è¨³çµæœãŒå…¥åŠ›ã¨åŒã˜ - è¡¨ç¤ºç”¨ã«ãƒãƒ¼ã‚­ãƒ³ã‚°")
            translated = f"[ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ] {translated}"
        
        # é€†ç¿»è¨³å®Ÿè¡Œ
        reverse = f_reverse_translation(translated, target_lang, source_lang)
        print(f"ğŸŸ¢ é€†ç¿»è¨³: {reverse[:30]}...")

        # Geminiç¿»è¨³ã‚’å–å¾—
        try:
            gemini_translation = f_translate_with_gemini(input_text, source_lang, target_lang, partner_message, context_info)
            print(f"ğŸ”· Geminiç¿»è¨³: {gemini_translation[:30]}...")
        except Exception as gemini_error:
            print(f"âš ï¸ Geminiç¿»è¨³ã‚¨ãƒ©ãƒ¼:", str(gemini_error))
            gemini_translation = f"Geminiç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(gemini_error)}"

        # æ”¹å–„ç¿»è¨³ã‚’å–å¾—
        better_translation = ""
        reverse_better = ""
        try:
            better_translation = f_better_translation(translated, source_lang, target_lang)
            print(f"âœ¨ æ”¹å–„ç¿»è¨³: {better_translation[:30]}...")
            
            # æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³ã‚‚å®Ÿè¡Œ
            if better_translation and not better_translation.startswith("æ”¹å–„ç¿»è¨³ã‚¨ãƒ©ãƒ¼"):
                reverse_better = f_reverse_translation(better_translation, target_lang, source_lang)
                print(f"ğŸ”„ æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³: {reverse_better[:30]}...")
            
        except Exception as better_error:
            print(f"âš ï¸ æ”¹å–„ç¿»è¨³ã‚¨ãƒ©ãƒ¼:", str(better_error))
            better_translation = f"æ”¹å–„ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(better_error)}"
            reverse_better = ""

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
        session["translated_text"] = translated
        session["reverse_translated_text"] = reverse
        session["gemini_translation"] = gemini_translation
        session["better_translation"] = better_translation
        session["reverse_better_translation"] = reverse_better

        # ğŸ†• ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ç”¨ï¼‰
        TranslationContext.save_context(
            input_text=input_text,
            translations={
                "chatgpt": translated,
                "enhanced": better_translation,
                "gemini": gemini_translation
            },
            analysis="", # å¾Œã§åˆ†æçµæœã‚’è¿½åŠ 
            metadata={
                "source_lang": source_lang,
                "target_lang": target_lang,
                "partner_message": partner_message,
                "context_info": context_info
            }
        )

        return {
            "success": True,
            "source_lang": source_lang,
            "target_lang": target_lang,  
            "input_text": input_text,
            "translated_text": translated,
            "reverse_translated_text": reverse,
            "gemini_translation": gemini_translation,
            "better_translation": better_translation,
            "reverse_better_translation": reverse_better
        }
    
    except Exception as e:
        import traceback
        print(f"âŒ è»½é‡ç‰ˆtranslate_chatgpt_only ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

@app.route("/get_nuance", methods=["POST"])
def get_nuance():
    try:
        translated_text = session.get("translated_text", "")
        better_translation = session.get("better_translation", "")
        gemini_translation = session.get("gemini_translation", "")

        print("ğŸ§  /get_nuance ã«ã‚¢ã‚¯ã‚»ã‚¹ãŒæ¥ã¾ã—ãŸ")

        if not (len(translated_text.strip()) > 0 and
                len(better_translation.strip()) > 0 and
                len(gemini_translation.strip()) > 0):
            return {"error": "å¿…è¦ãªç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}, 400

        result = f_gemini_3way_analysis(translated_text, better_translation, gemini_translation)
        print("âœ… Geminiåˆ†æçµæœ:", result)

        session["gemini_3way_analysis"] = result
        
        # ğŸ†• åˆ†æçµæœã‚’ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
        context = TranslationContext.get_context()
        if context:
            context["analysis"] = result
            TranslationContext.save_context(
                context["input_text"],
                context["translations"],
                result,
                context["metadata"]
            )
        
        return {"nuance": result}
    except Exception as e:
        import traceback
        print("âŒ get_nuance ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {"error": str(e)}, 500

# ====== æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆå¤‰æ›´ãªã—ï¼‰ ======

@app.route("/login", methods=["GET", "POST"])
def login():
    error = ""
    if request.method == "POST":
        password = request.form.get("password", "").strip()

        if not password:
            error = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        else:
            correct_pw = os.getenv("APP_PASSWORD", "linguru2025")
            if password == correct_pw:
                session["logged_in"] = True
                return redirect(url_for("index"))
            else:
                error = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™"

    return render_template("login.html", error=error)

@app.route("/", methods=["GET", "POST"])
def index():
    lang = session.get("lang", "jp")
    label = labels.get(lang, labels["jp"])

    if not session.get("logged_in"):
        return redirect(url_for("login"))

    # ğŸ†• ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’æœ€åˆã«å®šç¾©ï¼ˆé–¢æ•°ã®æœ€åˆã§å®šç¾©ï¼‰
    current_mode = session.get("translation_mode", "normal")
    mode_message = session.get("mode_message", "")

    language_pair = request.form.get("language_pair", "ja-fr") if request.method == "POST" else "ja-fr"
    source_lang, target_lang = language_pair.split("-")
        
    japanese_text = ""
    translated_text = reverse_translated_text = ""
    better_translation = reverse_better_text = nuances_analysis = ""
    gemini_translation = gemini_3way_analysis = gemini_reverse_translation = ""
    nuance_question = nuance_answer = partner_message = context_info = ""
    chat_history = session.get("chat_history", [])

    if request.method == "POST":
        if request.form.get("reset") == "true":
            # ğŸ”§ ä¿®æ­£: å®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼ˆç¿»è¨³çµæœã‚‚è³ªå•å±¥æ­´ã‚‚å…¨ã¦å‰Šé™¤ï¼‰
            keys_to_clear = [
                "chat_history", "translated_text", "better_translation", "gemini_translation",
                "partner_message", "context_info", "gemini_3way_analysis",
                "nuance_question", "nuance_answer", "reverse_better_translation"
            ]
            for key in keys_to_clear:
                session.pop(key, None)
            
            # å®Œå…¨ãƒªã‚»ãƒƒãƒˆã®å ´åˆã®ã¿ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã‚¯ãƒªã‚¢
            TranslationContext.clear_context()

            japanese_text = ""
            partner_message = ""
            context_info = ""
            nuance_question = ""
        else:
            japanese_text = request.form.get("japanese_text", "").strip()
            partner_message = request.form.get("partner_message", "").strip()
            context_info = request.form.get("context_info", "").strip()
            nuance_question = request.form.get("nuance_question", "").strip()

    return render_template("index_lt_interactive.html",
        japanese_text=japanese_text,
        translated_text=translated_text,
        reverse_translated_text=reverse_translated_text,
        better_translation=better_translation,
        reverse_better_text=reverse_better_text,
        gemini_translation=gemini_translation,
        gemini_reverse_translation=gemini_reverse_translation,
        gemini_3way_analysis=gemini_3way_analysis,
        nuance_question=nuance_question,
        nuance_answer=nuance_answer,
        chat_history=chat_history,
        partner_message=partner_message,
        context_info=context_info,
        current_mode=current_mode,
        mode_message=mode_message,
        labels=label,
        source_lang=source_lang,
        target_lang=target_lang,
        version_info=VERSION_INFO
    )

@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("login"))

@app.route("/set_language/<lang>")
def set_language(lang):
    session["lang"] = lang
    return redirect(url_for("index"))

@app.route("/set_translation_mode/<mode>")
def set_translation_mode(mode):
    """ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    
    if mode in ["normal", "premium"]:
        session["translation_mode"] = mode
        print(f"ğŸ›ï¸ ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰ã‚’ {mode.upper()} ã«å¤‰æ›´ã—ã¾ã—ãŸ")
        
        if mode == "premium":
            session["mode_message"] = "Premium Mode ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚ã‚ˆã‚Šé«˜å“è³ªãªç¿»è¨³ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚"
        else:
            session["mode_message"] = "Normal Mode ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚"
    else:
        session["mode_message"] = "ç„¡åŠ¹ãªãƒ¢ãƒ¼ãƒ‰ã§ã™ã€‚"
    
    return redirect(url_for("index"))

@app.route("/get_usage_stats")
def get_usage_stats():
    """ä½¿ç”¨çŠ¶æ³çµ±è¨ˆã‚’å–å¾—"""
    
    return {
        "normal_usage": session.get("normal_usage_count", 0),
        "premium_usage": session.get("premium_usage_count", 0),
        "current_mode": session.get("translation_mode", "normal")
    }

if __name__ == "__main__":
    port = int(sys.argv[1]) if len(sys.argv) > 1 else int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port, debug=True)