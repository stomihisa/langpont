"""
LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - å®‰å…¨éƒ¨åˆ†ã®ã¿
Task B2-10-Phase1c: æ®µéšçš„ç§»è¡Œã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯LangPontTranslationExpertAIã‚¯ãƒ©ã‚¹ã®å®‰å…¨ãªéƒ¨åˆ†ã®ã¿ã‚’å«ã¿ã¾ã™ã€‚
Flask sessionä¾å­˜ã‚„app_loggerä¾å­˜ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
"""

import re
from typing import Dict, Any


class LangPontTranslationExpertAI:
    """ğŸ¯ LangPontå¤šè¨€èªç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - å®‰å…¨éƒ¨åˆ†ç§»è¡Œç‰ˆ"""

    def __init__(self, client: Any) -> None:
        self.client = client
        self.supported_languages = {
            'ja': {'name': 'Japanese', 'æ—¥æœ¬èª': True},
            'en': {'name': 'English', 'English': True}, 
            'fr': {'name': 'French', 'FranÃ§ais': True},
            'es': {'name': 'Spanish', 'EspaÃ±ol': True}
        }

        # ğŸŒ å¤šè¨€èªå¯¾å¿œ: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨€èªãƒãƒƒãƒ—
        self.response_lang_map = {
            "jp": "Japanese",
            "en": "English", 
            "fr": "French",
            "es": "Spanish"  # â† ã‚¹ãƒšã‚¤ãƒ³èªã‚’è¿½åŠ 
        }

        # ğŸŒ å¤šè¨€èªå¯¾å¿œ: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.error_messages = {
            "jp": {
                "question_processing": "è³ªå•å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
                "translation_modification": "ç¿»è¨³ä¿®æ­£ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
                "analysis_inquiry": "åˆ†æè§£èª¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
                "linguistic_question": "è¨€èªå­¦çš„è³ªå•å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
                "context_variation": "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›´å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
                "comparison_analysis": "æ¯”è¼ƒåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}"
            },
            "en": {
                "question_processing": "Error occurred while processing question: {}",
                "translation_modification": "Error occurred during translation modification: {}",
                "analysis_inquiry": "Error occurred during analysis inquiry: {}",
                "linguistic_question": "Error occurred while processing linguistic question: {}",
                "context_variation": "Error occurred during context variation: {}",
                "comparison_analysis": "Error occurred during comparison analysis: {}"
            },
            "fr": {
                "question_processing": "Erreur lors du traitement de la question: {}",
                "translation_modification": "Erreur lors de la modification de traduction: {}",
                "analysis_inquiry": "Erreur lors de l'analyse d'enquÃªte: {}",
                "linguistic_question": "Erreur lors du traitement de la question linguistique: {}",
                "context_variation": "Erreur lors de la variation de contexte: {}",
                "comparison_analysis": "Erreur lors de l'analyse comparative: {}"
            },
            "es": {
                "question_processing": "Error al procesar la pregunta: {}",
                "translation_modification": "Error durante la modificaciÃ³n de traducciÃ³n: {}",
                "analysis_inquiry": "Error durante la consulta de anÃ¡lisis: {}",
                "linguistic_question": "Error al procesar la pregunta lingÃ¼Ã­stica: {}",
                "context_variation": "Error durante la variaciÃ³n de contexto: {}",
                "comparison_analysis": "Error durante el anÃ¡lisis comparativo: {}"
            }
        }

    def _get_error_message(self, context: Dict[str, Any], error_type: str, error_details: str) -> str:
        """ğŸŒ å¤šè¨€èªå¯¾å¿œã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
        display_lang = context.get('display_language', 'jp')
        lang_errors = self.error_messages.get(display_lang, self.error_messages["jp"])
        error_template = lang_errors.get(error_type, lang_errors["question_processing"])
        return error_template.format(error_details)

    def _analyze_question_intent(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ¯ è³ªå•ã®æ„å›³ã‚’è©³ç´°ã«åˆ†æ"""

        question_lower = question.lower()

        # ç¿»è¨³ä¿®æ­£è¦æ±‚ã®æ¤œå‡º
        modification_patterns = [
            r'(\d+)ç•ªç›®.*?((å£èª|ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«|ãƒ•ã‚©ãƒ¼ãƒãƒ«|ä¸å¯§|è¦ªã—ã¿|ãƒ“ã‚¸ãƒã‚¹).*?(ã«|ã§|é¢¨ã«))',
            r'(\d+).*?(ã‚‚ã£ã¨|ã‚ˆã‚Š).*?(å£èª|ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«|ãƒ•ã‚©ãƒ¼ãƒãƒ«|ä¸å¯§|è¦ªã—ã¿|ãƒ“ã‚¸ãƒã‚¹)',
            r'(\d+).*?(å¤‰æ›´|ä¿®æ­£|ç›´ã—|èª¿æ•´).*?(ã—ã¦|ã—ã¦ãã ã•ã„)',
            r'(ãƒ•ãƒ©ãƒ³ã‚¹èª|è‹±èª|ã‚¹ãƒšã‚¤ãƒ³èª).*?(å£èª|ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«|ãƒ•ã‚©ãƒ¼ãƒãƒ«).*?(ã«|ã§)'
        ]

        for pattern in modification_patterns:
            match = re.search(pattern, question)
            if match:
                # ç•ªå·æŠ½å‡º
                number_match = re.search(r'(\d+)ç•ªç›®', question)
                target_number = int(number_match.group(1)) if number_match else None

                # ã‚¹ã‚¿ã‚¤ãƒ«æŠ½å‡º
                style_match = re.search(r'(å£èª|ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«|ãƒ•ã‚©ãƒ¼ãƒãƒ«|ä¸å¯§|è¦ªã—ã¿|ãƒ“ã‚¸ãƒã‚¹)', question)
                target_style = style_match.group(1) if style_match else None

                return {
                    'type': 'translation_modification',
                    'target_number': target_number,
                    'target_style': target_style,
                    'target_language': context['target_lang'],
                    'confidence': 0.9
                }

        # åˆ†æå†…å®¹ã¸ã®è³ªå•
        if any(word in question_lower for word in ['åˆ†æ', 'ãªãœ', 'ç†ç”±', 'æ¨å¥¨', 'gemini', 'chatgpt']):
            return {
                'type': 'analysis_inquiry',
                'confidence': 0.8
            }

        # è¨€èªå­¦çš„è³ªå•
        if any(word in question_lower for word in ['æ´»ç”¨', 'æ–‡æ³•', 'æ§‹é€ ', 'æ„å‘³', 'é•ã„', 'é¡ç¾©èª']):
            return {
                'type': 'linguistic_question', 
                'confidence': 0.8
            }

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›´è¦æ±‚
        if any(word in question_lower for word in ['æ€’ã£', 'å‹é”', 'ãƒ“ã‚¸ãƒã‚¹', 'å ´åˆ', 'ã ã£ãŸã‚‰']):
            return {
                'type': 'context_variation',
                'confidence': 0.7
            }

        # æ¯”è¼ƒè³ªå•
        if any(word in question_lower for word in ['æ¯”è¼ƒ', 'é•ã„', 'ã©ã¡ã‚‰', '1ç•ªç›®', '2ç•ªç›®', '3ç•ªç›®']):
            return {
                'type': 'comparison_analysis',
                'confidence': 0.8
            }

        return {
            'type': 'general_expert',
            'confidence': 0.5
        }

    def _handle_translation_modification(self, question: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”§ ç¿»è¨³ä¿®æ­£è¦æ±‚ã‚’å‡¦ç†"""

        target_number = analysis.get('target_number')
        target_style = analysis.get('target_style') 
        target_lang = context['target_lang']

        # å¯¾è±¡ç¿»è¨³ã‚’ç‰¹å®š
        translations = context['translations']
        translation_map = {
            1: ('ChatGPT', translations['chatgpt']),
            2: ('Enhanced', translations['enhanced']), 
            3: ('Gemini', translations['gemini'])
        }

        if target_number and target_number in translation_map:
            engine_name, original_translation = translation_map[target_number]
        else:
            # ç•ªå·ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€æœ€æ–°ã®åˆ†æã§æ¨å¥¨ã•ã‚ŒãŸç¿»è¨³ã‚’ä½¿ç”¨
            engine_name = "Enhanced"
            original_translation = translations['enhanced']

        # è¨€èªåˆ¥ã®ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
        style_instructions = {
            'fr': {
                'å£èª': 'trÃ¨s familier et oral, utilise des contractions et expressions quotidiennes',
                'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«': 'dÃ©tendu et amical, style conversationnel sans formalitÃ© excessive',
                'ãƒ•ã‚©ãƒ¼ãƒãƒ«': 'trÃ¨s formel et professionnel, style soutenu et respectueux',
                'ãƒ“ã‚¸ãƒã‚¹': 'style commercial professionnel, adaptÃ© aux communications d\'entreprise',
                'ä¸å¯§': 'poli et courtois, utilise les formules de politesse appropriÃ©es'
            },
            'en': {
                'å£èª': 'very casual and colloquial, use contractions and everyday expressions',
                'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«': 'relaxed and friendly, conversational style without excessive formality',
                'ãƒ•ã‚©ãƒ¼ãƒãƒ«': 'very formal and professional, elevated and respectful style',
                'ãƒ“ã‚¸ãƒã‚¹': 'professional business style, suitable for corporate communications',
                'ä¸å¯§': 'polite and courteous, use appropriate politeness formulas'
            },
            'es': {
                'å£èª': 'muy familiar y coloquial, usa contracciones y expresiones cotidianas',
                'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«': 'relajado y amistoso, estilo conversacional sin formalidad excesiva',
                'ãƒ•ã‚©ãƒ¼ãƒãƒ«': 'muy formal y profesional, estilo elevado y respetuoso',
                'ãƒ“ã‚¸ãƒã‚¹': 'estilo comercial profesional, adecuado para comunicaciones empresariales',
                'ä¸å¯§': 'cortÃ©s y educado, usa las fÃ³rmulas de cortesÃ­a apropiadas'
            }
        }

        style_instruction = style_instructions.get(target_lang, {}).get(target_style, f'{target_style}çš„ãªã‚¹ã‚¿ã‚¤ãƒ«')

        # å°‚é–€çš„ãªä¿®æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""ã€LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAIã€‘
ã‚ãªãŸã¯å¤šè¨€èªç¿»è¨³ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç¿»è¨³ã‚’æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®æ–‡ç« ï¼ˆæ—¥æœ¬èªï¼‰ã€‘
{context['original_text']}

ã€ç¾åœ¨ã®{engine_name}ç¿»è¨³ï¼ˆ{target_lang.upper()}ï¼‰ã€‘
{original_translation}

ã€ä¿®æ­£æŒ‡ç¤ºã€‘
ã“ã®ç¿»è¨³ã‚’ã€Œ{target_style}ã€ãªã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
è¨€èª: {target_lang.upper()}
ã‚¹ã‚¿ã‚¤ãƒ«è¦ä»¶: {style_instruction}

ã€ä¿®æ­£ç‰ˆç¿»è¨³ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‘
- å…ƒã®æ„å‘³ã¯å®Œå…¨ã«ä¿æŒ
- {target_style}ãªã‚¹ã‚¿ã‚¤ãƒ«ã«å®Œå…¨ã«é©å¿œ
- æ–‡åŒ–çš„ã«è‡ªç„¶ãªè¡¨ç¾ã‚’ä½¿ç”¨
- ä¿®æ­£ã®ãƒã‚¤ãƒ³ãƒˆã‚‚èª¬æ˜

ä¿®æ­£ç‰ˆ:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",  # ã‚ˆã‚Šé«˜å“è³ªãªç¿»è¨³ã®ãŸã‚GPT-4ã‚’ä½¿ç”¨
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=800
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "translation_modification",
                "result": result,
                "original_engine": engine_name,
                "target_style": target_style,
                "target_language": target_lang
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "translation_modification", str(e))
            return {
                "type": "error",
                "result": error_msg
            }

    def _handle_analysis_inquiry(self, question: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ§  åˆ†æå†…å®¹ã¸ã®è³ªå•ã‚’å‡¦ç†"""

        nuance_analysis = context.get('nuance_analysis', '')
        selected_engine = context.get('selected_engine', 'gemini')

        prompt = f"""ã€LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - åˆ†æè§£èª¬ã€‘
ã‚ãªãŸã¯ç¿»è¨³å“è³ªåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®åˆ†æçµæœã«ã¤ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€å…ƒã®æ–‡ç« ã€‘
{context['original_text']}

ã€3ã¤ã®ç¿»è¨³ã€‘
1. ChatGPT: {context['translations']['chatgpt']}
2. Enhanced: {context['translations']['enhanced']}
3. Gemini: {context['translations']['gemini']}

ã€{selected_engine.upper()}ã«ã‚ˆã‚‹åˆ†æçµæœã€‘
{nuance_analysis}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{question}

ã€å›ç­”è¦ä»¶ã€‘
- åˆ†æå†…å®¹ã‚’è©³ã—ãè§£èª¬
- ç¿»è¨³ã®å“è³ªè©•ä¾¡åŸºæº–ã‚’èª¬æ˜
- æ¨å¥¨ç†ç”±ã®è¨€èªå­¦çš„æ ¹æ‹ ã‚’æç¤º
- å…·ä½“ä¾‹ã‚’ç”¨ã„ã¦èª¬æ˜

å›ç­”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=700
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "analysis_inquiry",
                "result": result,
                "analyzed_engine": selected_engine
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "analysis_inquiry", str(e))
            return {
                "type": "error", 
                "result": error_msg
            }

    def _handle_linguistic_question(self, question: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ“š è¨€èªå­¦çš„è³ªå•ã‚’å‡¦ç†"""

        prompt = f"""ã€LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - è¨€èªå­¦ç¿’æ”¯æ´ã€‘
ã‚ãªãŸã¯å¤šè¨€èªã®è¨€èªå­¦å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç¿»è¨³ã«é–¢ã™ã‚‹è¨€èªå­¦çš„è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€ç¿»è¨³ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã€‘
å…ƒã®æ–‡ç« : {context['original_text']}
è¨€èªãƒšã‚¢: {context['source_lang']} â†’ {context['target_lang']}

ã€3ã¤ã®ç¿»è¨³çµæœã€‘
1. ChatGPT: {context['translations']['chatgpt']}
2. Enhanced: {context['translations']['enhanced']}
3. Gemini: {context['translations']['gemini']}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{question}

ã€å›ç­”è¦ä»¶ã€‘
- è¨€èªå­¦çš„ã«æ­£ç¢ºãªèª¬æ˜
- æ–‡æ³•æ§‹é€ ã®è©³ç´°è§£èª¬
- èªå½™ã®ä½¿ã„åˆ†ã‘ã®èª¬æ˜
- å®Ÿç”¨çš„ãªå­¦ç¿’ã‚¢ãƒ‰ãƒã‚¤ã‚¹
- å…·ä½“ä¾‹ã‚’ç”¨ã„ãŸèª¬æ˜

å›ç­”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=700
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "linguistic_question",
                "result": result
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "linguistic_question", str(e))
            return {
                "type": "error",
                "result": error_msg
            }

    def _handle_context_variation(self, question: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ­ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›´è¦æ±‚ã‚’å‡¦ç†"""

        # æ¨å¥¨ç¿»è¨³ã‚’åŸºæº–ã¨ã™ã‚‹
        base_translation = context['translations']['enhanced']

        prompt = f"""ã€LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé©å¿œã€‘
ã‚ãªãŸã¯å¤šè¨€èªç¿»è¨³ã®å°‚é–€å®¶ã§ã™ã€‚ç•°ãªã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®ç¿»è¨³ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®æ–‡ç« ã€‘
{context['original_text']}

ã€ç¾åœ¨ã®ç¿»è¨³ï¼ˆ{context['target_lang'].upper()}ï¼‰ã€‘
{base_translation}

ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›´è¦æ±‚ã€‘
{question}

ã€æä¾›ã—ã¦ãã ã•ã„ã€‘
- æ–°ã—ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é©ã—ãŸç¿»è¨³
- å¤‰æ›´ã®ãƒã‚¤ãƒ³ãƒˆã¨ç†ç”±
- æ–‡åŒ–çš„é…æ…®äº‹é …
- ä½¿ç”¨å ´é¢ã®èª¬æ˜

å›ç­”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=700
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "context_variation",
                "result": result
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "context_variation", str(e))
            return {
                "type": "error",
                "result": error_msg
            }

    def handle_comparison_analysis_safe(self, question: str, context: Dict[str, Any], 
                                      analysis: Dict[str, Any], logger_adapter) -> Dict[str, Any]:
        """âš–ï¸ æ¯”è¼ƒåˆ†æã‚’å‡¦ç†ï¼ˆå®‰å…¨ç‰ˆ - app_loggerä¾å­˜ãªã—ï¼‰"""
        
        translations = context['translations']

        # ğŸ†• ãƒ‡ãƒãƒƒã‚°ï¼šåˆ©ç”¨å¯èƒ½ãªç¿»è¨³ã‚­ãƒ¼ã‚’ç¢ºèªï¼ˆSafeLoggerAdapterä½¿ç”¨ï¼‰
        logger_adapter.info(f"ğŸ” Available translation keys: {list(translations.keys())}")

        # ğŸ†• å¿…è¦ãªã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
        required_keys = ['chatgpt', 'enhanced', 'gemini', 'chatgpt_reverse', 'enhanced_reverse', 'gemini_reverse']
        missing_keys = [key for key in required_keys if key not in translations]
        if missing_keys:
            logger_adapter.warning(f"âš ï¸ Missing translation keys: {missing_keys}")
            return {
                "type": "error",
                "result": f"ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™ã€‚ä¸è¶³ã‚­ãƒ¼: {missing_keys}"
            }

        # ğŸ“ æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Œå…¨ç§»è¡Œ
        prompt = f"""ã€LangPontç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAI - æ¯”è¼ƒåˆ†æã€‘
ã‚ãªãŸã¯ç¿»è¨³å“è³ªåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç¿»è¨³ã‚’è©³ç´°ã«æ¯”è¼ƒåˆ†æã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®æ–‡ç« ã€‘
{context['original_text']}

ã€æ¯”è¼ƒå¯¾è±¡ã®ç¿»è¨³ã€‘
1. ChatGPT: {translations['chatgpt']}
2. Enhanced: {translations['enhanced']}
3. Gemini: {translations['gemini']}

ã€é€†ç¿»è¨³ã‚‚å‚è€ƒæƒ…å ±ã¨ã—ã¦ã€‘
1. ChatGPTé€†ç¿»è¨³: {translations['chatgpt_reverse']}
2. Enhancedé€†ç¿»è¨³: {translations['enhanced_reverse']}
3. Geminié€†ç¿»è¨³: {translations['gemini_reverse']}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{question}

ã€åˆ†æè¦³ç‚¹ã€‘
- æ­£ç¢ºæ€§ï¼ˆå…ƒã®æ„å‘³ã®ä¿æŒåº¦ï¼‰
- è‡ªç„¶ã•ï¼ˆç›®æ¨™è¨€èªã¨ã—ã¦ã®æµæš¢ã•ï¼‰
- æ–‡åŒ–çš„é©åˆ‡æ€§
- èªå½™é¸æŠã®å¦¥å½“æ€§
- æ–‡ä½“ã®ä¸€è²«æ€§

å›ç­”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=800
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "comparison_analysis",
                "result": result
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "comparison_analysis", str(e))
            return {
                "type": "error",
                "result": error_msg
            }

    def handle_general_expert_question_safe(self, question: str, context: Dict[str, Any], 
                                          analysis: Dict[str, Any], logger_adapter) -> Dict[str, Any]:
        """ğŸ“ ä¸€èˆ¬çš„ãªç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè³ªå•ã‚’å‡¦ç†ï¼ˆå®‰å…¨ç‰ˆ - app_loggerä¾å­˜ãªã—ï¼‰"""

        display_lang = context.get('display_language', 'jp')
        response_language = self.response_lang_map.get(display_lang, "Japanese")

        # ğŸ†• ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°è¿½åŠ ï¼ˆSafeLoggerAdapterä½¿ç”¨ï¼‰
        logger_adapter.info(f"Interactive question language: display_lang={display_lang}, response_language={response_language}")

        prompt = f"""ã€LangPont Translation Expert AIã€‘
You are a multilingual translation expert. Please answer the following question about the translation session.

ã€Translation Session Informationã€‘
Original text: {context['original_text']}
Language pair: {context['source_lang']} â†’ {context['target_lang']}
Context information: {context.get('context_info', 'None')}
Message to partner: {context.get('partner_message', 'None')}

ã€Three Translation Resultsã€‘
1. ChatGPT: {context['translations']['chatgpt']}
2. Enhanced: {context['translations']['enhanced']}
3. Gemini: {context['translations']['gemini']}

ã€Analysis Resultsã€‘
{context.get('nuance_analysis', 'Analysis not performed')}

ã€User's Questionã€‘
{question}

ã€Response Requirementsã€‘
- Comprehensive answer as a translation expert
- Practical and constructive advice
- Information helpful for language learning
- Explanations including cultural considerations

IMPORTANT: Please provide your response in {response_language}.

Response:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=700
            )

            result = response.choices[0].message.content.strip()

            return {
                "type": "general_expert",
                "result": result
            }

        except Exception as e:
            error_msg = self._get_error_message(context, "question_processing", str(e))
            return {
                "type": "error",
                "result": error_msg
            }

    def get_complete_translation_context_safe(self, context: Dict[str, Any], 
                                            session_adapter) -> Dict[str, Any]:
        """ğŸ” ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å®Œå…¨ãªç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆå®‰å…¨ç‰ˆ - Flaskä¾å­˜ãªã—ï¼‰"""
        
        # SessionContextAdapterã‹ã‚‰ç¿»è¨³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        session_data = session_adapter.get_translation_context()
        
        # åŸºæœ¬ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨çµ±åˆ
        session_data.update(context)
        
        return session_data

    def process_question_safe(self, question: str, context: Dict[str, Any], 
                             input_validator, security_logger, session_adapter, logger_adapter) -> Dict[str, Any]:
        """ğŸ§  ç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã—ã¦è³ªå•ã‚’åŒ…æ‹¬çš„ã«å‡¦ç†ï¼ˆçµ±åˆå®‰å…¨ç‰ˆï¼‰"""
        
        # å…¥åŠ›å€¤æ¤œè¨¼ï¼ˆä¾å­˜æ³¨å…¥ï¼‰
        is_valid, error_msg = input_validator.validate_text_input(
            question, max_length=1000, min_length=5, field_name="è³ªå•"
        )
        if not is_valid:
            security_logger(
                'INVALID_QUESTION_INPUT',
                f'Question validation failed: {error_msg}',
                'WARNING'
            )
            raise ValueError(error_msg)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±å–å¾—ï¼ˆæ—¢å­˜safeç‰ˆä½¿ç”¨ï¼‰
        full_context = self.get_complete_translation_context_safe(context, session_adapter)

        # è³ªå•æ„å›³åˆ†æï¼ˆæ—¢å­˜å®‰å…¨ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
        question_analysis = self._analyze_question_intent(question, full_context)

        # è³ªå•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ï¼ˆå…¨ã¦æ—¢å­˜å®‰å…¨ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
        if question_analysis['type'] == 'translation_modification':
            return self._handle_translation_modification(question, full_context, question_analysis)
        elif question_analysis['type'] == 'analysis_inquiry':
            return self._handle_analysis_inquiry(question, full_context, question_analysis)
        elif question_analysis['type'] == 'linguistic_question':
            return self._handle_linguistic_question(question, full_context, question_analysis)
        elif question_analysis['type'] == 'context_variation':
            return self._handle_context_variation(question, full_context, question_analysis)
        elif question_analysis['type'] == 'comparison_analysis':
            return self.handle_comparison_analysis_safe(question, full_context, question_analysis, logger_adapter)
        else:
            return self.handle_general_expert_question_safe(question, full_context, question_analysis, logger_adapter)

    def process_question(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ§  ç¿»è¨³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã—ã¦è³ªå•ã‚’åŒ…æ‹¬çš„ã«å‡¦ç†ï¼ˆçµ±åˆç‰ˆ - Flaskå¯¾å¿œï¼‰"""
        # å¿…è¦ãªä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’import
        from security.input_validation import EnhancedInputValidator
        from security.security_logger import log_security_event
        from translation.adapters import SessionContextAdapter, SafeLoggerAdapter
        
        # ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
        session_adapter = SessionContextAdapter()
        logger_adapter = SafeLoggerAdapter()
        
        # çµ±åˆå®‰å…¨ç‰ˆã‚’å‘¼ã³å‡ºã—
        return self.process_question_safe(
            question, context, EnhancedInputValidator, log_security_event,
            session_adapter, logger_adapter
        )