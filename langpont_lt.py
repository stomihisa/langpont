import os
import sys
from dotenv import load_dotenv

# ğŸ†• ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®å®šç¾©
VERSION_INFO = {
    "file_name": "langpont_lt.py",
    "version": "è»½é‡ç‰ˆï¼ˆè‹±èªæœ€å°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰", 
    "created_date": "2025/5/26",
    "optimization": "27%é«˜é€ŸåŒ– + 90%ã‚³ã‚¹ãƒˆå‰Šæ¸›",
    "status": "é‹ç”¨ä¸­"
}

# .env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã“ã®1è¡Œã§ååˆ†ï¼‰
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))

from flask import Flask, render_template, request, session, redirect, url_for
from openai import OpenAI
from textwrap import dedent
from concurrent.futures import ThreadPoolExecutor
from datetime import timedelta
import requests
import time
from labels import labels

# APIã‚­ãƒ¼
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# Flask
app = Flask(__name__)
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "default_secret_key")
app.permanent_session_lifetime = timedelta(hours=1)

# OpenAI client
client = OpenAI(api_key=api_key)

# ====== ChatGPT ç”¨ é–¢æ•° ======
def f_translate_to(input_text, source_lang, target_lang, partner_message="", context_info=""):

    print("ğŸš€ f_translate_to é–‹å§‹")   # â†â˜…ã“ã“ã‚’è¿½åŠ 

    # è¨€èªã‚³ãƒ¼ãƒ‰ â†’ è¡¨ç¤ºç”¨åç§°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "en": "è‹±èª"
    }

    # è¡¨ç¤ºç”¨ã®ç¿»è¨³ãƒšã‚¢åã‚’å–å¾—ï¼ˆä¾‹: æ—¥æœ¬èªâ†’ãƒ•ãƒ©ãƒ³ã‚¹èªï¼‰
    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨€èªãƒšã‚¢ã«å¿œã˜ã¦çµ„ã¿ç«‹ã¦ã‚‹
    system_message = f"ã‚ãªãŸã¯{source_label}ãŠã‚ˆã³{target_label}ã®å„ªç§€ãªç¿»è¨³è€…ã§ã™ã€‚"
    system_message += f" ä¸‹è¨˜ã®ç›´å‰ã®ã‚„ã‚Šã¨ã‚Šã¨èƒŒæ™¯æƒ…å ±ã‚’å‚è€ƒã«ã—ã€è‡ªç„¶ã§ä¸å¯§ã§å¤±ç¤¼ã®ãªã„æ–‡ç« ã«{target_label}ã§ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®çµ„ã¿ç«‹ã¦
    context = f"""
    ï½ ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ï½
    {partner_message or "(ãªã—)"}

    ï½ èƒŒæ™¯æƒ…å ± ï½
    {context_info or "(ãªã—)"}
    """.strip()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ç¿»è¨³æŒ‡ç¤º
    user_prompt = f"""
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
    - å…ƒã®è¨€èª: {source_label}
    - ç¿»è¨³å¾Œã®è¨€èª: {target_label}
    - ä¸å¯§ã§è‡ªç„¶ã€ã‹ã¤å¤±ç¤¼ã®ãªã„æ–‡ä½“ã§{target_label}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

    â–¼ç¿»è¨³å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆï¼š
    {input_text}
    """.strip()

    print("ğŸ§± ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")   # â†â˜…ã“ã“ã‚’è¿½åŠ 

    print("ğŸ“¥ f_translate_to å‘¼ã³å‡ºã—å†…å®¹ï¼š")
    print(" - å…¥åŠ›:", input_text)
    print(" - source_lang:", source_lang)
    print(" - target_lang:", target_lang)
    print(" - æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    print(user_prompt)

    # ChatGPTã¸ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "assistant", "content": context},
            {"role": "user", "content": user_prompt}
        ]
    )

    print("ğŸ“¬ APIã‹ã‚‰ã®å¿œç­”ã‚’å—ä¿¡")   # â†â˜…ã“ã“ã‚’è¿½åŠ 

    # ğŸš€ è»½é‡ç‰ˆ: æ–°ã—ã„ç¿»è¨³é–¢æ•°ï¼ˆã“ã“ã«è¿½åŠ ï¼‰
# ğŸ”„ ==== ç¿»è¨³é–¢æ•°ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† ==== ğŸ”„

# ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: å…ƒã®æ—¥æœ¬èªç‰ˆè»½é‡ç¿»è¨³é–¢æ•°ï¼ˆå®Ÿé¨“å‰ã®åŸºæº–ç‰ˆï¼‰
# âš ï¸ æ³¨æ„: ã“ã®é–¢æ•°ã¯ç¾åœ¨ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ãŒã€å¿…è¦æ™‚ã« f_translate_to_lightweight ã¨ç½®ãæ›ãˆå¯èƒ½
def f_translate_to_lightweight_japanese_backup(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """
    ğŸ‡¯ğŸ‡µ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç‰ˆ: æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè»½é‡ç¿»è¨³é–¢æ•°
    
    å®Ÿé¨“çµæœ:
    - å¹³å‡é€Ÿåº¦: åŸºæº– (1.0x)
    - ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ç´„600-1200 (å¤šã„)
    - ç¿»è¨³å“è³ª: é«˜å“è³ª
    
    åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•: ã“ã®é–¢æ•°ã®å†…å®¹ã‚’ f_translate_to_lightweight ã«ã‚³ãƒ”ãƒ¼ã—ã¦ç½®ãæ›ãˆ
    """
    
    print(f"ğŸš€ f_translate_to_lightweight_japanese_backup é–‹å§‹ - {source_lang} -> {target_lang}")
    
    # è¨€èªã‚³ãƒ¼ãƒ‰ â†’ è¡¨ç¤ºç”¨åç§°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª", 
        "en": "è‹±èª"
    }

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    # ğŸ”§ é‡è¦: ã‚ˆã‚Šæ˜ç¢ºãªç¿»è¨³æŒ‡ç¤º
    system_message = f"ã‚ãªãŸã¯{source_label}ã‹ã‚‰{target_label}ã¸ã®å°‚é–€ç¿»è¨³è€…ã§ã™ã€‚"
    system_message += f" å¿…ãš{target_label}ã§å›ç­”ã—ã€{source_label}ã‚’ãã®ã¾ã¾è¿”ã™ã“ã¨ã¯çµ¶å¯¾ã«ã—ãªã„ã§ãã ã•ã„ã€‚"

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®çµ„ã¿ç«‹ã¦
    context = f"""
    ï½ ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ï½
    {partner_message or "(ãªã—)"}

    ï½ èƒŒæ™¯æƒ…å ± ï½
    {context_info or "(ãªã—)"}
    """.strip()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ç¿»è¨³æŒ‡ç¤º
    user_prompt = f"""
    ä»¥ä¸‹ã®{source_label}ã‚’{target_label}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š
    
    {input_text}
    
    æ³¨æ„: å¿…ãš{target_label}ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚å…ƒã®{source_label}ã‚’ãã®ã¾ã‚‰è¿”ã•ãªã„ã§ãã ã•ã„ã€‚
    """.strip()

    print("ğŸ§± æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")

    try:
        # ChatGPTã¸ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3  # ä¸€è²«æ€§å‘ä¸Š
        )
        
        result = response.choices[0].message.content.strip()
        
        # ğŸ”§ åŸºæœ¬çš„ãªæ¤œè¨¼ã®ã¿  
        if not result:
            raise ValueError("ChatGPTã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")
        
        print(f"âœ… æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¿»è¨³å®Œäº†: {result[:50]}...")
        return result

    except Exception as e:
        print(f"âŒ f_translate_to_lightweight_japanese_backup ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise Exception(f"ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ğŸš€ ç¾åœ¨ä½¿ç”¨ä¸­: è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€å°ç‰ˆè»½é‡ç¿»è¨³é–¢æ•°
# ğŸ“Š å®Ÿé¨“çµæœ: å¹³å‡-2.9% (ã»ã¼åŒç­‰é€Ÿåº¦) + 90%ã‚³ã‚¹ãƒˆå‰Šæ¸› + åŒç­‰å“è³ª
# ğŸ”§ ä¿®æ­£ç‰ˆ: è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€å°ç‰ˆè»½é‡ç¿»è¨³é–¢æ•°
def f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """
    ğŸš€ ä¿®æ­£ç‰ˆ: è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€å°ç‰ˆè»½é‡ç¿»è¨³é–¢æ•°
    
    ä¿®æ­£å†…å®¹:
    - ã€Œç¿»è¨³ã®ã¿ã€ã‚’æ˜ç¢ºã«æŒ‡ç¤º
    - ä½™è¨ˆãªèª¬æ˜æ–‡ã®æ’é™¤
    - ã‚ˆã‚Šç›´æ¥çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    
    print(f"ğŸš€ f_translate_to_lightweight(è‹±èªæœ€å°ç‰ˆãƒ»ä¿®æ­£) é–‹å§‹ - {source_lang} -> {target_lang}")
    
    # è¨€èªãƒãƒƒãƒ”ãƒ³ã‚°
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    target_label = lang_map.get(target_lang, target_lang)
    
    # ğŸ”§ ä¿®æ­£: ã‚ˆã‚Šç›´æ¥çš„ã§æ˜ç¢ºãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    if partner_message.strip() or context_info.strip():
        context = f" Context: {partner_message} {context_info}".strip()
        prompt = f"Translate to {target_label}. Output only the translation:\n\n{input_text}\n\n{context}"
    else:
        # ğŸ”§ ä¿®æ­£: "Output only the translation" ã‚’æ˜è¨˜
        prompt = f"Translate to {target_label}. Output only the translation:\n\n{input_text}"

    print(f"ğŸ§± è‹±èªæœ€å°ç‰ˆ(ä¿®æ­£)ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}...")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,    # ã•ã‚‰ã«ä¸‹ã’ã¦ä¸€è²«æ€§å‘ä¸Š
            max_tokens=300      # é©åº¦ã«åˆ¶é™
        )
        
        result = response.choices[0].message.content.strip()
        
        # ğŸ”§ ä¿®æ­£: ä½™è¨ˆãªå‰ç½®ãã‚’é™¤å»
        # "ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š" ã‚„ "---" ãªã©ã‚’é™¤å»
        unwanted_prefixes = [
            "ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š",
            "ä»¥ä¸‹ã®é€šã‚Šã§ã™:",
            "ç¿»è¨³ï¼š",
            "ç¿»è¨³:",
            "---",
            "ç¿»è¨³çµæœï¼š",
            "ç¿»è¨³çµæœ:",
            "Here is the translation:",
            "Translation:"
        ]
        
        for prefix in unwanted_prefixes:
            if result.startswith(prefix):
                result = result[len(prefix):].strip()
                print(f"ğŸ§¹ ä¸è¦ãªå‰ç½®ãã€Œ{prefix}ã€ã‚’é™¤å»ã—ã¾ã—ãŸ")
        
        # æ”¹è¡Œã§å§‹ã¾ã‚‹å ´åˆã‚‚é™¤å»
        while result.startswith('\n') or result.startswith('\r'):
            result = result[1:].strip()
        
        # ç°¡å˜ãªæ¤œè¨¼
        if not result or len(result.strip()) < 2:
            raise ValueError("ç¿»è¨³çµæœãŒçŸ­ã™ãã¾ã™")
            
        if result.strip() == input_text.strip():
            raise ValueError("ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        print(f"âœ… è‹±èªæœ€å°ç‰ˆ(ä¿®æ­£)ç¿»è¨³å®Œäº†: {result[:50]}...")
        return result

    except Exception as e:
        print(f"âŒ f_translate_to_lightweight(è‹±èªæœ€å°ç‰ˆãƒ»ä¿®æ­£) ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨
        print("ğŸ”„ æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
        return f_translate_to_lightweight_japanese_backup(input_text, source_lang, target_lang, partner_message, context_info)

# ğŸ§ª å®Ÿé¨“ç”¨: ã•ã‚‰ã«æ”¹è‰¯ã—ãŸç‰ˆã‚‚ç”¨æ„
# ğŸš€ æœ€çµ‚æ¨å¥¨ç‰ˆ: è‹±èªæœ€å°ç‰ˆï¼ˆå¾Œå‡¦ç†ãªã—ãƒ»é«˜é€Ÿé‡è¦–ï¼‰
def f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """
    ğŸš€ æœ€çµ‚æ¨å¥¨ç‰ˆ: è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€å°ç‰ˆè»½é‡ç¿»è¨³é–¢æ•°
    
    å®Ÿé¨“çµæœ (æœ€æ–°ãƒ‡ãƒ¼ã‚¿):
    - å¹³å‡é€Ÿåº¦å‘ä¸Š: +27.1% é«˜é€ŸåŒ–
    - ãƒˆãƒ¼ã‚¯ãƒ³æ•°å‰Šæ¸›: 90%ä»¥ä¸Š
    - ç¿»è¨³å“è³ª: åŒç­‰
    - å‰ç½®ãå•é¡Œ: ç¨€ï¼ˆ5%æœªæº€ï¼‰
    
    è¨­è¨ˆæ€æƒ³:
    - é€Ÿåº¦æœ€å„ªå…ˆ
    - ã‚·ãƒ³ãƒ—ãƒ«ã•é‡è¦–
    - ç¨€ãªå•é¡Œã‚ˆã‚Šå…¨ä½“æœ€é©åŒ–
    """
    
    print(f"ğŸš€ f_translate_to_lightweight(æœ€çµ‚ç‰ˆ) é–‹å§‹ - {source_lang} -> {target_lang}")
    
    # è¨€èªãƒãƒƒãƒ”ãƒ³ã‚°
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    target_label = lang_map.get(target_lang, target_lang)
    
    # ğŸ”§ æœ€é©åŒ–: ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    if partner_message.strip() or context_info.strip():
        context = f" (Context: {partner_message} {context_info})".strip()
        prompt = f"Translate to {target_label}:\n{input_text}{context}"
    else:
        # ç©¶æ¥µã«ã‚·ãƒ³ãƒ—ãƒ«
        prompt = f"Translate to {target_label}:\n{input_text}"

    print(f"ğŸ§± æœ€çµ‚ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº† (æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(prompt.split()) * 1.3:.0f})")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,    # ä¸€è²«æ€§é‡è¦–
            max_tokens=400      # é©åº¦ãªåˆ¶é™
        )
        
        result = response.choices[0].message.content.strip()
        
        # ğŸ”§ æœ€å°é™ã®æ¤œè¨¼ã®ã¿ï¼ˆå¾Œå‡¦ç†ãªã—ï¼‰
        if not result or len(result.strip()) < 2:
            raise ValueError("ç¿»è¨³çµæœãŒçŸ­ã™ãã¾ã™")
            
        if result.strip() == input_text.strip():
            raise ValueError("ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        print(f"âœ… æœ€çµ‚ç‰ˆç¿»è¨³å®Œäº†: {result[:50]}...")
        return result

    except Exception as e:
        print(f"âŒ f_translate_to_lightweight(æœ€çµ‚ç‰ˆ) ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ã¿æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        print("ğŸ”„ æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
        return f_translate_to_lightweight_japanese_backup(input_text, source_lang, target_lang, partner_message, context_info)

# ğŸ› ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³: æ‰‹å‹•ã§å‰ç½®ãé™¤å»ãŒå¿…è¦ãªå ´åˆã®é–¢æ•°
def clean_translation_result(result):
    """
    æ‰‹å‹•ã§ç¿»è¨³çµæœã‹ã‚‰ä¸è¦ãªå‰ç½®ãã‚’é™¤å»ã™ã‚‹é–¢æ•°
    å¿…è¦ãªæ™‚ã ã‘å‘¼ã³å‡ºã—å¯èƒ½
    """
    unwanted_prefixes = [
        "ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š", "ä»¥ä¸‹ã®é€šã‚Šã§ã™:", "ç¿»è¨³ï¼š", "ç¿»è¨³:", "---",
        "ç¿»è¨³çµæœï¼š", "ç¿»è¨³çµæœ:", "Here is the translation:", "Translation:"
    ]
    
    cleaned = result.strip()
    for prefix in unwanted_prefixes:
        if cleaned.startswith(prefix):
            cleaned = cleaned[len(prefix):].strip()
            print(f"ğŸ§¹ æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: ã€Œ{prefix}ã€ã‚’é™¤å»")
    
    while cleaned.startswith('\n') or cleaned.startswith('\r'):
        cleaned = cleaned[1:].strip()
    
    return cleaned

# ğŸ“‹ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
"""
ğŸ¯ æ¨å¥¨ä½¿ç”¨æ³•:

1. åŸºæœ¬ä½¿ç”¨: ãã®ã¾ã¾ä½¿ç”¨
   - 95%ä»¥ä¸Šã¯æ­£å¸¸ã«å‹•ä½œ
   - 27%é«˜é€ŸåŒ– + 90%ã‚³ã‚¹ãƒˆå‰Šæ¸›

2. ç¨€ã«å‰ç½®ããŒä»˜ãå ´åˆ:
   - æ‰‹å‹•ã§ clean_translation_result() ã‚’ä½¿ç”¨
   - ã¾ãŸã¯ä¸€æ™‚çš„ã«æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«åˆ‡ã‚Šæ›¿ãˆ

3. å®Œå…¨ã«å•é¡Œã‚’é¿ã‘ãŸã„å ´åˆ:
   - æ—¥æœ¬èªç‰ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨
   - ãŸã ã—é€Ÿåº¦ãƒ»ã‚³ã‚¹ãƒˆãƒ¡ãƒªãƒƒãƒˆã¯å¤±ã‚ã‚Œã‚‹

ğŸ’¡ çµè«–: ç¾çŠ¶ã®ã¾ã¾ä½¿ç”¨ãŒæœ€é©
   - é€Ÿåº¦: +27% å‘ä¸Š
   - ã‚³ã‚¹ãƒˆ: 90% å‰Šæ¸›  
   - å“è³ª: åŒç­‰
   - å•é¡Œç™ºç”Ÿç‡: <5%
"""
# ğŸ§ª ==========å®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰é–‹å§‹========== ğŸ§ª
# ğŸ§ª ==========å®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰é–‹å§‹========== ğŸ§ª
# ğŸ§ª ==========å®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰é–‹å§‹========== ğŸ§ª

def f_translate_japanese_prompt_full(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """ç¾åœ¨ã®æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆï¼ˆãƒ•ãƒ«æ©Ÿèƒ½ï¼‰"""
    
    lang_map = {"ja": "æ—¥æœ¬èª", "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª", "en": "è‹±èª"}
    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    system_message = f"ã‚ãªãŸã¯{source_label}ã‹ã‚‰{target_label}ã¸ã®å°‚é–€ç¿»è¨³è€…ã§ã™ã€‚å¿…ãš{target_label}ã§å›ç­”ã—ã€{source_label}ã‚’ãã®ã¾ã¾è¿”ã™ã“ã¨ã¯çµ¶å¯¾ã«ã—ãªã„ã§ãã ã•ã„ã€‚"
    
    context = f"""
    ï½ ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ï½
    {partner_message or "(ãªã—)"}
    ï½ èƒŒæ™¯æƒ…å ± ï½
    {context_info or "(ãªã—)"}
    """.strip() if partner_message or context_info else ""
    
    user_prompt = f"""
    ä»¥ä¸‹ã®{source_label}ã‚’{target_label}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š
    
    {input_text}
    
    æ³¨æ„: å¿…ãš{target_label}ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚å…ƒã®{source_label}ã‚’ãã®ã¾ã¾è¿”ã•ãªã„ã§ãã ã•ã„ã€‚
    """.strip()
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¦‚ç®—
    total_text = system_message + context + user_prompt
    estimated_tokens = len(total_text) * 2.2  # æ—¥æœ¬èªã®æ¦‚ç®—ä¿‚æ•°
    print(f"ğŸ“Š æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f}")
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")

def f_translate_english_prompt_full(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """åŒç­‰æ©Ÿèƒ½ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ"""
    
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    system_message = f"You are a professional translator specializing in {source_label} to {target_label} translation. Always respond only in {target_label}, never return the original {source_label} text."
    
    context_text = ""
    if partner_message or context_info:
        context_text = f"Context - Previous conversation: {partner_message or 'None'}. Background: {context_info or 'None'}."
    
    user_prompt = f"""
    Translate the following {source_label} text to {target_label}:
    
    {input_text}
    
    {context_text}
    
    Important: Respond only in {target_label}. Do not return the original {source_label} text.
    """.strip()
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¦‚ç®—
    total_text = system_message + user_prompt
    estimated_tokens = len(total_text.split()) * 1.3  # è‹±èªã®æ¦‚ç®—ä¿‚æ•°
    print(f"ğŸ“Š è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f}")
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")

def f_translate_english_prompt_minimal(input_text, source_lang, target_lang, partner_message="", context_info=""):
    """æœ€å°é™ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆï¼ˆé€Ÿåº¦é‡è¦–ï¼‰"""
    
    lang_map = {"ja": "Japanese", "fr": "French", "en": "English"}
    target_label = lang_map.get(target_lang, target_lang)
    
    # æœ€å°é™ã ãŒå¿…è¦ãªæƒ…å ±ã¯å«ã‚€
    if partner_message or context_info:
        context = f" (Context: {partner_message} {context_info})".strip()
        prompt = f"Professional translation to {target_label}:\n{input_text}{context}"
    else:
        prompt = f"Professional translation to {target_label}:\n{input_text}"
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¦‚ç®—
    estimated_tokens = len(prompt.split()) * 1.3
    print(f"ğŸ“Š æœ€å°è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:.0f}")
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=400
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")

# ğŸ§ª æ¯”è¼ƒãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def compare_prompt_methods(test_text, source_lang="ja", target_lang="fr"):
    """3ã¤ã®æ–¹æ³•ã‚’æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ§ª ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ãƒ†ã‚¹ãƒˆæ–‡ç« : {test_text}")
    print("-" * 50)
    
    import time
    
    # 1. æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ•ãƒ«ï¼‰
    start_time = time.time()
    result_jp = f_translate_japanese_prompt_full(test_text, source_lang, target_lang)
    time_jp = time.time() - start_time
    print(f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªç‰ˆ: {time_jp:.2f}ç§’")
    print(f"çµæœ: {result_jp}")
    print()
    
    # 2. è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆåŒç­‰æ©Ÿèƒ½ï¼‰
    start_time = time.time()
    result_en_full = f_translate_english_prompt_full(test_text, source_lang, target_lang)
    time_en_full = time.time() - start_time
    print(f"ğŸ‡ºğŸ‡¸ è‹±èªç‰ˆ(ãƒ•ãƒ«): {time_en_full:.2f}ç§’")
    print(f"çµæœ: {result_en_full}")
    print()
    
    # 3. è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæœ€å°é™ï¼‰
    start_time = time.time()
    result_en_min = f_translate_english_prompt_minimal(test_text, source_lang, target_lang)
    time_en_min = time.time() - start_time
    print(f"ğŸš€ è‹±èªç‰ˆ(æœ€å°): {time_en_min:.2f}ç§’")
    print(f"çµæœ: {result_en_min}")
    print()
    
    print("ğŸ“Š æ¯”è¼ƒçµæœ:")
    print(f"é€Ÿåº¦æ”¹å–„: æ—¥æœ¬èªâ†’è‹±èª(ãƒ•ãƒ«) {((time_jp-time_en_full)/time_jp*100):.1f}%")
    print(f"é€Ÿåº¦æ”¹å–„: æ—¥æœ¬èªâ†’è‹±èª(æœ€å°) {((time_jp-time_en_min)/time_jp*100):.1f}%")
    
    return {
        "japanese": {"result": result_jp, "time": time_jp},
        "english_full": {"result": result_en_full, "time": time_en_full},
        "english_minimal": {"result": result_en_min, "time": time_en_min}
    }

# ğŸ§ª å®Ÿé¨“ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆå®Ÿé¨“ç”¨é–¢æ•°ã®å¾Œã«è¿½åŠ ï¼‰
# langpont_lt.py ã® experiment_prompts é–¢æ•°ã‚’ä»¥ä¸‹ã§ç½®ãæ›ãˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
@app.route("/experiment_prompts", methods=["POST"])
def experiment_prompts():
    try:
        data = request.get_json()
        test_text = data.get("text", "")
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")
        
        print(f"ğŸ§ª å®Ÿé¨“è¨­å®šç¢ºèª:")
        print(f"  - ãƒ†ã‚­ã‚¹ãƒˆ: {test_text}")
        print(f"  - è¨€èªãƒšã‚¢: {language_pair}")
        print(f"  - å…ƒè¨€èª: {source_lang}")
        print(f"  - ç¿»è¨³å…ˆ: {target_lang}")
        
        if not test_text:
            return {"error": "ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"}
        
        # å®Ÿé¨“å®Ÿè¡Œï¼ˆä¿®æ­£æ¸ˆã¿ã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        results = {}
        errors = {}
        
        def run_japanese():
            try:
                import time
                start_time = time.time()
                result = f_translate_japanese_prompt_full(test_text, source_lang, target_lang)
                end_time = time.time()
                elapsed = end_time - start_time
                results["japanese"] = {"result": result, "time": elapsed}
                print(f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªç‰ˆå®Œäº†: {elapsed:.2f}ç§’ - {result[:50]}...")
            except Exception as e:
                errors["japanese"] = str(e)
                print(f"âŒ æ—¥æœ¬èªç‰ˆã‚¨ãƒ©ãƒ¼: {e}")
        
        def run_english_full():
            try:
                import time
                start_time = time.time()
                result = f_translate_english_prompt_full(test_text, source_lang, target_lang)
                end_time = time.time()
                elapsed = end_time - start_time
                results["english_full"] = {"result": result, "time": elapsed}
                print(f"ğŸ‡ºğŸ‡¸ è‹±èªç‰ˆ(ãƒ•ãƒ«)å®Œäº†: {elapsed:.2f}ç§’ - {result[:50]}...")
            except Exception as e:
                errors["english_full"] = str(e)
                print(f"âŒ è‹±èªç‰ˆ(ãƒ•ãƒ«)ã‚¨ãƒ©ãƒ¼: {e}")
        
        def run_english_minimal():
            try:
                import time
                start_time = time.time()
                result = f_translate_english_prompt_minimal(test_text, source_lang, target_lang)
                end_time = time.time()
                elapsed = end_time - start_time
                results["english_minimal"] = {"result": result, "time": elapsed}
                print(f"ğŸš€ è‹±èªç‰ˆ(æœ€å°)å®Œäº†: {elapsed:.2f}ç§’ - {result[:50]}...")
            except Exception as e:
                errors["english_minimal"] = str(e)
                print(f"âŒ è‹±èªç‰ˆ(æœ€å°)ã‚¨ãƒ©ãƒ¼: {e}")
        
        # é †æ¬¡å®Ÿè¡Œ
        run_japanese()
        import time
        time.sleep(0.3)
        run_english_full()
        time.sleep(0.3)
        run_english_minimal()
        
        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if errors:
            print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {errors}")
            return {"success": False, "error": f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {errors}"}
        
        if len(results) != 3:
            print(f"âŒ çµæœä¸è¶³: {len(results)}/3")
            return {"success": False, "error": f"çµæœä¸è¶³: {len(results)}/3"}
        
        # ã‚µãƒãƒªãƒ¼ä½œæˆ
        summary = {
            "japanese_time": results["japanese"]["time"],
            "english_full_time": results["english_full"]["time"],
            "english_minimal_time": results["english_minimal"]["time"],
            "speed_improvement_full": ((results["japanese"]["time"] - results["english_full"]["time"]) / results["japanese"]["time"] * 100),
            "speed_improvement_minimal": ((results["japanese"]["time"] - results["english_minimal"]["time"]) / results["japanese"]["time"] * 100)
        }
        
        print(f"ğŸ§ª å®Ÿé¨“å®Œäº†ã‚µãƒãƒªãƒ¼:")
        print(f"  - æ—¥æœ¬èªç‰ˆ: {summary['japanese_time']:.2f}ç§’")
        print(f"  - è‹±èªãƒ•ãƒ«ç‰ˆ: {summary['english_full_time']:.2f}ç§’")
        print(f"  - è‹±èªæœ€å°ç‰ˆ: {summary['english_minimal_time']:.2f}ç§’")
        print(f"  - é€Ÿåº¦æ”¹å–„: ãƒ•ãƒ«{summary['speed_improvement_full']:.1f}%, æœ€å°{summary['speed_improvement_minimal']:.1f}%")
        
        return {
            "success": True,
            "results": results,
            "summary": summary
        }
        
    except Exception as e:
        import traceback
        print(f"âŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(traceback.format_exc())
        return {"success": False, "error": str(e)}


# ğŸ§ª ==========å®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰çµ‚äº†========== ğŸ§ª
# ğŸ§ª ==========å®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰çµ‚äº†========== ğŸ§ª

    # âœ… è¿½åŠ â‘ ï¼šAPIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨æ–‡ã‚’å‡ºåŠ›
    print("ğŸ” ChatGPT API ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨æ–‡:")
    print(response)

    # âœ… è¿½åŠ â‘¡ï¼šAPIã‹ã‚‰è¿”ã•ã‚ŒãŸç¿»è¨³æ–‡ã®ã¿å‡ºåŠ›
    print("âœ… ChatGPTãŒè¿”ã—ãŸç¿»è¨³çµæœï¼ˆ.contentï¼‰:")
    print(response.choices[0].message.content)

    return response.choices[0].message.content.strip()

def f_translate_to_french(japanese_text, partner_message="", context_info=""):
    system_message = "ã‚ãªãŸã¯å„ªç§€ãªæ—¥æœ¬èªâ†’ãƒ•ãƒ©ãƒ³ã‚¹èªç¿»è¨³è€…ã§ã™ï¼ä¸‹è¨˜æƒ…å ±ï¼ˆç›´å‰ã®ã‚„ã‚Šã¨ã‚Šã€èƒŒæ™¯æƒ…å ±ï¼‰ã‚’å‚è€ƒã«ã€ã¦ã„ã­ã„ã§è‡ªç„¶ã€å¤±ç¤¼ã®ãªã„ãƒ•ãƒ©ãƒ³ã‚¹èªã®æ–‡ç« ã«ç¿»è¨³ã—ã¦ãã ã•ã„"
    context = f"""
    ï½ ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ï½
    {partner_message or "(ãªã—)"}

    ï½ èƒŒæ™¯æƒ…å ± ï½
    {context_info or "(ãªã—)"}
    """.strip()
    user_prompt = f"""
    ä»¥ä¸‹ã®æ—¥æœ¬èªã‚’ãƒ•ãƒ©ãƒ³ã‚¹èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š
    ---
    {japanese_text}
    """.strip()
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "assistant", "content": context},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def f_reverse_translation(translated_text, target_lang, source_lang):
    """ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã®è¨€èªã«æˆ»ã™é–¢æ•°"""
    if not translated_text:
        print("âš ï¸ f_reverse_translation: ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã—ãŸ")
        return "(ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™)"

    print(f"ğŸ”„ f_reverse_translation å®Ÿè¡Œ:")
    print(f" - translated_text: {translated_text}")
    print(f" - source_lang: {source_lang}")
    print(f" - target_lang: {target_lang}")

    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "en": "è‹±èª"
    }

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    system_message = (
        f"ã‚ãªãŸã¯å„ªç§€ãª{target_label}ãŠã‚ˆã³{source_label}ã®ç¿»è¨³è€…ã§ã™ã€‚"
        f" æ¬¡ã®æ–‡ç« ã‚’å…ƒã®è¨€èªï¼ˆ{source_label}ï¼‰ã«è‡ªç„¶ãªå½¢ã§æ­£ç¢ºã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
    )

    user_prompt = f"""
    ä»¥ä¸‹ã®{target_label}ã®æ–‡ã‚’{source_label}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š
    ---
    {translated_text}
    """.strip()

    print("ğŸ“¤ f_reverse_translation å‘¼ã³å‡ºã—:")
    print(f" - ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {system_message}")
    print(f" - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {user_prompt}")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ]
        )
        result = response.choices[0].message.content.strip()
        print("ğŸ“¥ f_reverse_translation çµæœ:", result)
        return result

    except Exception as e:
        import traceback
        print("âŒ f_reverse_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        raise

def f_better_translation(text_to_improve, source_lang="fr", target_lang="en"):
    """ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šè‡ªç„¶ã«æ”¹å–„ã™ã‚‹é–¢æ•°"""
    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "en": "è‹±èª"
    }

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    print(f"âœ¨ f_better_translation é–‹å§‹:")
    print(f" - text_to_improve: {text_to_improve}")
    print(f" - source_lang: {source_lang} ({source_label})")
    print(f" - target_lang: {target_lang} ({target_label})")

    system_message = f"{target_label}ã®ç¿»è¨³ã‚’ã‚ˆã‚Šè‡ªç„¶ã«æ”¹å–„ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
    user_prompt = f"ã“ã®{target_label}ã‚’ã‚‚ã£ã¨è‡ªç„¶ãª{target_label}ã®æ–‡ç« ã«æ”¹å–„ã—ã¦ãã ã•ã„ï¼š{text_to_improve}"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_prompt}
        ]
    )

    result = response.choices[0].message.content.strip()
    print(f"âœ… æ”¹å–„çµæœ: {result}")
    return result

def f_reverse_better_translation(text_to_reverse, source_lang, target_lang):
    """æ”¹å–„ç¿»è¨³ã‚’å…ƒã®è¨€èªã«æˆ»ã™é–¢æ•°"""
    
    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "en": "è‹±èª"
    }

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    system_message = f"{target_label}ã‹ã‚‰{source_label}ã«ç¿»è¨³ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
    user_prompt = f"ã“ã®{target_label}ã‚’{source_label}ã«è¨³ã—ã¦ãã ã•ã„ï¼š{text_to_reverse}"

    print("ğŸ“¤ f_reverse_better_translation å‘¼ã³å‡ºã—:")
    print(" - system:", system_message)
    print(" - prompt:", user_prompt)

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ]
        )
        result = response.choices[0].message.content.strip()
        print("ğŸ“¥ f_reverse_better_translation çµæœ:", result)
        return result

    except Exception as e:
        import traceback
        print("âŒ f_reverse_better_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return "(é€†ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸ)"

def f_ask_about_nuance(question):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ç¿»è¨³ã®è§£é‡ˆã‚„é•ã„ã«ã¤ã„ã¦èª¬æ˜ã§ãã‚‹ç¿»è¨³è€…ã§ã™ã€‚"},
            {"role": "user", "content": question}
        ]
    )
    return response.choices[0].message.content.strip()

# ====== Gemini ç”¨ é–¢æ•° ======

def f_translate_with_gemini(text, source_lang, target_lang, partner_message="", context_info=""):
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        return "âš ï¸ Gemini APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“"

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={GEMINI_API_KEY}"

    prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãª{source_lang}â†’{target_lang}ã®ç¿»è¨³è€…ã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ï¼ˆç›´å‰ã®ã‚„ã‚Šã¨ã‚Šã€èƒŒæ™¯ï¼‰ã‚’å‚è€ƒã«ã€
**{target_lang}ã®ç¿»è¨³æ–‡ã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆè§£èª¬ã‚„æ³¨é‡ˆã¯ä¸è¦ã§ã™ï¼‰ã€‚

--- ç›´å‰ã®ã‚„ã‚Šã¨ã‚Š ---
{partner_message or "(ãªã—)"}

--- èƒŒæ™¯æƒ…å ± ---
{context_info or "(ãªã—)"}

--- ç¿»è¨³å¯¾è±¡ ---
{text}
    """.strip()

    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    else:
        return f"Gemini API error: {response.status_code} - {response.text}"

def f_gemini_3way_analysis(translated_text, better_translation, gemini_translation):
    """3ã¤ã®ç¿»è¨³çµæœã‚’æ¯”è¼ƒåˆ†æã™ã‚‹é–¢æ•°"""

    # APIã‚­ãƒ¼ç¢ºèª
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        return "âš ï¸ Gemini APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“"

    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    total_input = translated_text + better_translation + gemini_translation
    warning = "âš ï¸ å…¥åŠ›ãŒé•·ã„ãŸã‚ã€åˆ†æçµæœã¯è¦ç´„ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n" if len(total_input) > 2000 else ""

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰è¨€èªå–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ja-frï¼‰
    source_lang = session.get("source_lang", "ja")
    target_lang = session.get("target_lang", "fr")

    lang_map = {
        "ja": "æ—¥æœ¬èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "en": "è‹±èª"
    }

    source_label = lang_map.get(source_lang, source_lang)
    target_label = lang_map.get(target_lang, target_lang)

    # Geminiã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = f"""
ä»¥ä¸‹ã®3ã¤ã®{target_label}ã®æ–‡ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®è¡¨ç¾ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®é•ã„ã‚’{source_label}ã§æ¯”è¼ƒã—ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ã‚ãªãŸã¯ç¿»è¨³è¡¨ç¾ã®å°‚é–€å®¶ã§ã™ã€‚
æ¯”è¼ƒã¯ã€Œä¸å¯§ã•ã€ã€Œå£èª¿ã€ã€Œãƒˆãƒ¼ãƒ³ã€ã€Œæ–‡æ§‹é€ ã€ã€Œãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®é•ã„ã€ã‚’ç°¡æ½”ã«è¨€èªåŒ–ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ã¯{source_label}ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚é‡è¦ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚„æ–‡ä½“ã®é•ã„ãŒååˆ†ã«ä¼ã‚ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
å¿…è¦ãªã‚‰500æ–‡å­—ã‚’è¶…ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

ã€ChatGPTã«ã‚ˆã‚‹ç¿»è¨³ã€‘
{translated_text}

ã€ã‚ˆã‚Šè‰¯ã„ç¿»è¨³ææ¡ˆï¼ˆChatGPTï¼‰ã€‘
{better_translation}

ã€Geminiã«ã‚ˆã‚‹ç¿»è¨³ã€‘
{gemini_translation}
""".strip()

    print("ğŸ“¤ Gemini 3wayåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ:")
    print(f" - prompt: {prompt[:300]}...")

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        if response.status_code == 200:
            result_text = response.json()["candidates"][0]["content"]["parts"][0]["text"]
            print("ğŸ“¥ Gemini 3wayåˆ†æçµæœ:", result_text[:100] + "...")
            return warning + result_text.strip()
        else:
            error_msg = f"âš ï¸ Gemini API error: {response.status_code} - {response.text}"
            print("âŒ", error_msg)
            return error_msg

    except requests.exceptions.Timeout:
        return "âš ï¸ Gemini APIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ30ç§’ä»¥å†…ã«å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"

    except Exception as e:
        import traceback
        error_msg = f"âš ï¸ Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(error_msg)
        print(traceback.format_exc())
        return error_msg

# ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ç”¨æ”¹ä¿®
# langpont_lt.py ã®ä¿®æ­£ç®‡æ‰€

# 1. translate_chatgpt_only é–¢æ•°ã‚’ç½®ãæ›ãˆ
# ğŸš€ ã“ã‚ŒãŒã€Œæœ€åˆã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã€ã®ã‚³ãƒ¼ãƒ‰ã§ã™
@app.route("/translate_chatgpt", methods=["POST"])
def translate_chatgpt_only():
    try:
        data = request.get_json() or {}
        input_text = data.get("japanese_text", "").strip()
        partner_message = data.get("partner_message", "")
        context_info = data.get("context_info", "")
        language_pair = data.get("language_pair", "ja-fr")  
        
        source_lang, target_lang = language_pair.split("-")  

        # ğŸ”§ è»½é‡ç‰ˆ: é‡è¦ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã®ã¿ã‚¯ãƒªã‚¢
        critical_keys = ["translated_text", "reverse_translated_text"]
        for key in critical_keys:
            session.pop(key, None)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        session["source_lang"] = source_lang
        session["target_lang"] = target_lang
        session["language_pair"] = language_pair

        print(f"ğŸŸ¦ [è»½é‡ç‰ˆ/translate_chatgpt] ç¿»è¨³å®Ÿè¡Œ: {source_lang} -> {target_lang}")
        print(f"ğŸ”µ å…¥åŠ›: {input_text[:30]}...")

        if not input_text:
            return {
                "success": False,
                "error": "ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
            }

        # ç¿»è¨³å®Ÿè¡Œï¼ˆè»½é‡ç‰ˆé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        translated = f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message, context_info)
        print(f"ğŸ”µ ç¿»è¨³çµæœ: {translated[:30]}...")
        
        # ğŸ”§ è»½é‡ç‰ˆ: ç°¡å˜ãªæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã®ã¿
        if translated.strip() == input_text.strip():
            print("âš ï¸ ç¿»è¨³çµæœãŒå…¥åŠ›ã¨åŒã˜ - è¡¨ç¤ºç”¨ã«ãƒãƒ¼ã‚­ãƒ³ã‚°")
            translated = f"[ç¿»è¨³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ] {translated}"
        
        # é€†ç¿»è¨³å®Ÿè¡Œ
        reverse = f_reverse_translation(translated, target_lang, source_lang)
        print(f"ğŸŸ¢ é€†ç¿»è¨³: {reverse[:30]}...")

        # Geminiç¿»è¨³ã‚’å–å¾—
        try:
            gemini_translation = f_translate_with_gemini(input_text, source_lang, target_lang, partner_message, context_info)
            print(f"ğŸ”· Geminiç¿»è¨³: {gemini_translation[:30]}...")
        except Exception as gemini_error:
            print(f"âš ï¸ Geminiç¿»è¨³ã‚¨ãƒ©ãƒ¼:", str(gemini_error))
            gemini_translation = f"Geminiç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(gemini_error)}"

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        session["input_text"] = input_text
        session["translated_text"] = translated
        session["reverse_translated_text"] = reverse
        session["gemini_translation"] = gemini_translation

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
        return {
            "success": True,
            "source_lang": source_lang,
            "target_lang": target_lang,  
            "input_text": input_text,
            "translated_text": translated,
            "reverse_translated_text": reverse,
            "gemini_translation": gemini_translation
        }
    
    except Exception as e:
        import traceback
        print(f"âŒ è»½é‡ç‰ˆtranslate_chatgpt_only ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

@app.route("/reverse_translate_chatgpt", methods=["POST"])
def reverse_translate_chatgpt():
    """ChatGPTç¿»è¨³çµæœã‚’é€†ç¿»è¨³ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json() or {}
        translated_text = data.get("french_text", "")
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨€èªæƒ…å ±ã‚’ä¿å­˜
        session["source_lang"] = source_lang
        session["target_lang"] = target_lang

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        print("ğŸ” reverse_translate_chatgpt:")
        print(" - translated_text:", translated_text)
        print(" - language_pair:", language_pair)
        print(" - source_lang:", source_lang)
        print(" - target_lang:", target_lang)

        # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
        if not translated_text:
            return {
                "success": False,
                "error": "ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
            }

        # âœ… é€†æ–¹å‘ã«ç¿»è¨³: target_lang â†’ source_lang
        reversed_text = f_reverse_translation(translated_text, target_lang, source_lang)

        print("ğŸ” å†ç¿»è¨³å¯¾è±¡ï¼ˆtranslated_textï¼‰:", translated_text)
        print("ğŸŸ¢ å†ç¿»è¨³çµæœï¼ˆé€†ç¿»è¨³reversed_textï¼‰:", reversed_text)

        return {
            "success": True,
            "reversed_text": reversed_text
        }
    except Exception as e:
        import traceback
        print("âŒ reverse_translate_chatgpt ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

@app.route("/improve_translation", methods=["POST"])
def improve_translation():
    try:
        data = request.get_json() or {}
        text_to_improve = data.get("french_text", "")
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")

        print("ğŸ” improve_translation:")
        print(" - text_to_improve:", text_to_improve)
        print(" - language_pair:", language_pair)
        print(" - source_lang:", source_lang)
        print(" - target_lang:", target_lang)

        if not text_to_improve:
            return {
                "success": False,
                "error": "æ”¹å–„ã™ã‚‹ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            }

        # æ”¹å–„ç¿»è¨³
        improved = f_better_translation(text_to_improve, source_lang, target_lang)
        print(f"âœ¨ æ”¹å–„å¯¾è±¡ï¼ˆ{source_lang} â†’ {target_lang}ï¼‰:", text_to_improve)
        print("âœ¨ æ”¹å–„ç¿»è¨³çµæœimproved:", improved)

        try:
            gemini_translation = f_translate_with_gemini(text_to_improve, source_lang, target_lang)
            print("ğŸ”· Geminiç¿»è¨³gemini_translation:", gemini_translation)
            session["gemini_translation"] = gemini_translation
        except Exception as gemini_error:
            print("âš ï¸ Geminiç¿»è¨³å–å¾—ã‚¨ãƒ©ãƒ¼:", str(gemini_error))

        session["better_translation"] = improved

        return {
            "success": True,
            "improved_text": improved
        }
    except Exception as e:
        import traceback
        print("âŒ improve_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

@app.route("/reverse_better_translation", methods=["POST"])
def reverse_better_translation():
    """æ”¹å–„ã•ã‚ŒãŸç¿»è¨³ã‚’é€†ç¿»è¨³ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        data = request.get_json() or {}
        improved_text = data.get("french_text", "")
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        print("ğŸ” reverse_better_translation:")
        print(" - improved_text:", improved_text)
        print(" - language_pair:", language_pair)
        print(" - source_lang:", source_lang)
        print(" - target_lang:", target_lang)

        # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
        if not improved_text:
            return {
                "success": False,
                "error": "é€†ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            }

        # âœ… æ”¹å–„ç¿»è¨³ã¯ target_lang ã®è¨€èªãªã®ã§ã€é€†ç¿»è¨³ã¯ target_lang â†’ source_lang
        reversed_text = f_reverse_translation(improved_text, target_lang, source_lang)

        print("ğŸ” æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³å¯¾è±¡:", improved_text)
        print("ğŸŸ¢ æ”¹å–„ç¿»è¨³ã®é€†ç¿»è¨³çµæœ:", reversed_text)

        return {
            "success": True,
            "reversed_text": reversed_text
        }

    except Exception as e:
        import traceback
        print("âŒ reverse_better_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

@app.route("/reverse_gemini_translation", methods=["POST"])
def reverse_gemini_translation():
    """Geminiç¿»è¨³çµæœã‚’é€†ç¿»è¨³ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json() or {}
        language_pair = data.get("language_pair", "ja-fr")
        source_lang, target_lang = language_pair.split("-")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰Geminiç¿»è¨³çµæœã‚’å–å¾—
        gemini_text = session.get("gemini_translation", "")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        print("ğŸ” reverse_gemini_translation:")
        print(" - language_pair:", language_pair)
        print(" - source_lang:", source_lang)
        print(" - target_lang:", target_lang)
        print(" - gemini_text:", gemini_text)
        
        # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã‹ãƒã‚§ãƒƒã‚¯
        if not gemini_text:
            return {
                "success": False,
                "error": "Geminiç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            }
        
        # âœ… Geminiç¿»è¨³ã¯ source_lang â†’ target_lang ã®æ–¹å‘ãªã®ã§ã€
        # é€†ç¿»è¨³ã¯ target_lang â†’ source_lang
        reversed_text = f_reverse_translation(gemini_text, target_lang, source_lang)

        print("ğŸ” Geminiç¿»è¨³ã®é€†ç¿»è¨³å¯¾è±¡:", gemini_text)
        print("ğŸŸ¢ Geminiç¿»è¨³ã®é€†ç¿»è¨³çµæœ:", reversed_text)
        
        return {
            "success": True,
            "reversed_text": reversed_text
        }

    except Exception as e:
        import traceback
        print("âŒ reverse_gemini_translation ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

# ====== ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ======

@app.route("/login", methods=["GET", "POST"])
def login():
    error = ""
    if request.method == "POST":
        password = request.form.get("password", "").strip()

        # ç©ºæ¬„ãƒã‚§ãƒƒã‚¯
        if not password:
            error = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        else:
            correct_pw = os.getenv("APP_PASSWORD", "linguru2025")
            if password == correct_pw:
                session["logged_in"] = True
                return redirect(url_for("index"))
            else:
                error = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™"

    return render_template("login.html", error=error)


@app.route("/get_nuance", methods=["POST"])
def get_nuance():
    try:
        translated_text = session.get("translated_text", "")
        better_translation = session.get("better_translation", "")
        gemini_translation = session.get("gemini_translation", "")

        print("ğŸ§  /get_nuance ã«ã‚¢ã‚¯ã‚»ã‚¹ãŒæ¥ã¾ã—ãŸ")
        print("ğŸ§¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±:", {
            "translated_text": translated_text,
            "better_translation": better_translation,
            "gemini_translation": gemini_translation
        })

        # æ–‡å­—æ•°ã§ç©ºã‹ãƒã‚§ãƒƒã‚¯
        if not (
            len(translated_text.strip()) > 0 and
            len(better_translation.strip()) > 0 and
            len(gemini_translation.strip()) > 0
        ):
            return {"error": "å¿…è¦ãªç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}, 400

        result = f_gemini_3way_analysis(translated_text, better_translation, gemini_translation)
        print("âœ… Geminiåˆ†æçµæœ:", result)

        session["gemini_3way_analysis"] = result
        return {"nuance": result}
    except Exception as e:
        import traceback
        print("âŒ get_nuance ã‚¨ãƒ©ãƒ¼:", str(e))
        print(traceback.format_exc())
        return {"error": str(e)}, 500

@app.route("/", methods=["GET", "POST"])
def index():

    lang = session.get("lang", "jp") # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãŒJP
    label = labels.get(lang, labels["jp"])  # â† fallbackã‚ã‚Š

    if not session.get("logged_in"):
        return redirect(url_for("login"))

    language_pair = request.form.get("language_pair", "ja-fr") if request.method == "POST" else "ja-fr"
    source_lang, target_lang = language_pair.split("-")
        
    japanese_text = ""
    translated_text = reverse_translated_text = ""
    better_translation = reverse_better_text = nuances_analysis = ""
    gemini_translation = gemini_3way_analysis = gemini_reverse_translation = ""
    nuance_question = nuance_answer = partner_message = context_info = ""
    chat_history = session.get("chat_history", [])

    if request.method == "POST":

        if request.form.get("reset") == "true":
            keys_to_clear = [
                "chat_history", "translated_text", "better_translation", "gemini_translation",
                "partner_message", "context_info", "gemini_3way_analysis",
                "nuance_question", "nuance_answer"
    ]
            for key in keys_to_clear:
                session.pop(key, None)

            japanese_text = ""
            partner_message = ""
            context_info = ""
            nuance_question = ""

        else:

         japanese_text = request.form.get("japanese_text", "").strip()
         partner_message = request.form.get("partner_message", "").strip()
         context_info = request.form.get("context_info", "").strip()
         nuance_question = request.form.get("nuance_question", "").strip()

        if japanese_text:
            
            # ğŸ” ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼šç¿»è¨³å‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèª
             print("[ChatGPT] ç¿»è¨³ã¸æ¸¡ã™å†…å®¹ï¼š")
             print(" - å…¥åŠ›æ–‡ç« :", japanese_text)
             print(" - source_lang:", source_lang)
             print(" - target_lang:", target_lang)
             print(" - partner_message:", partner_message)
             print(" - context_info:", context_info)

             with ThreadPoolExecutor() as executor:
                 # ç¿»è¨³å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ
                 future_translated = executor.submit(f_translate_to, japanese_text, source_lang, target_lang, partner_message, context_info)
                 future_gemini_translation = executor.submit(f_translate_with_gemini, japanese_text, source_lang, target_lang, partner_message, context_info)

                 # ç¿»è¨³çµæœã‚’å–å¾—
                 translated_text = future_translated.result()
                 gemini_translation = future_gemini_translation.result()

             with ThreadPoolExecutor() as executor:
                 future_reverse_translated = executor.submit(f_reverse_translation, translated_text, target_lang, source_lang)

                 future_better_translation = executor.submit(f_better_translation, translated_text)
                 future_gemini_reverse_translation = executor.submit(f_reverse_translation, gemini_translation, target_lang, source_lang)

                 reverse_translated_text = future_reverse_translated.result()
                 better_translation = future_better_translation.result()
                 gemini_reverse_translation = future_gemini_reverse_translation.result()
                 
                 future_reverse_better_translation = executor.submit(f_reverse_translation, better_translation, target_lang, source_lang)
                 reverse_better_text = future_reverse_better_translation.result()

             gemini_3way_analysis = f_gemini_3way_analysis(translated_text, better_translation, gemini_translation)

             session.update({
                 "chat_history": chat_history,
                 "partner_message": partner_message,
                 "context_info": context_info,
                 "translated_text": translated_text,
                 "better_translation": better_translation,
                 "gemini_translation": gemini_translation
             })

        if nuance_question:
             nuance_answer = f_ask_about_nuance(nuance_question)
             chat_history.append({"question": nuance_question, "answer": nuance_answer})
             session["chat_history"] = chat_history
             nuance_question = ""

    # âœ… ã©ã‚“ãªå ´åˆã‚‚ return ã‚’é€šã‚‹ï¼ˆPOST or GETï¼‰
    return render_template("index_lt.html",
        japanese_text=japanese_text,
        translated_text=translated_text,
        reverse_translated_text=reverse_translated_text,
        better_translation=better_translation,
        reverse_better_text=reverse_better_text,
        gemini_translation=gemini_translation,
        gemini_reverse_translation=gemini_reverse_translation,
        gemini_3way_analysis=gemini_3way_analysis,
        nuance_question=nuance_question,
        nuance_answer=nuance_answer,
        chat_history=chat_history,
        partner_message=partner_message,
        context_info=context_info,
        labels=label,
        source_lang=source_lang,
        target_lang=target_lang,
        version_info=VERSION_INFO  # ğŸ†• ã“ã‚Œã‚’è¿½åŠ 
    )

@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("login"))

@app.route("/set_language/<lang>")
def set_language(lang):
    session["lang"] = lang
    return redirect(url_for("index"))


# ====== ã“ã“ã‹ã‚‰ã“ã®Codeã®ãƒˆãƒ©ãƒ–ãƒ«å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ« ======
# ====== ã“ã“ã‹ã‚‰ã“ã®Codeã®ãƒˆãƒ©ãƒ–ãƒ«å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ« ======
# ====== ã“ã“ã‹ã‚‰ã“ã®Codeã®ãƒˆãƒ©ãƒ–ãƒ«å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ« ======
# ğŸ†˜ ç¿»è¨³æ©Ÿèƒ½ãƒˆãƒ©ãƒ–ãƒ«å¯¾å¿œã‚¬ã‚¤ãƒ‰

# ä½œæˆæ—¥: 2025å¹´5æœˆ26æ—¥  
# å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: `langpont_lt.py`
# Claudeã«èã„ã¦æ›¸ã„ã¦ã„ã¾ã™ã€‚

# ğŸš¨ å•é¡Œ: ç¿»è¨³çµæœã«ä¸è¦ãªå‰ç½®ããŒè¡¨ç¤ºã•ã‚Œã‚‹

# ç—‡çŠ¶ã®ä¾‹

# âŒ "ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼šHello, how are you?"
# âŒ "ç¿»è¨³ï¼šBonjour, comment allez-vous?"  
# âŒ "---\nGuten Tag, wie geht es Ihnen?"


# ğŸ› ï¸ å¯¾å¿œæ–¹æ³•ï¼ˆå„ªå…ˆé †ä½é †ï¼‰

# 1ï¸âƒ£ æ§˜å­è¦‹ï¼ˆã¾ãšè©¦ã™ï¼‰
#- **æ‰‹é †**: æ•°å›ç¿»è¨³ã‚’è©¦ã—ã¦ã¿ã‚‹
#- **ç†ç”±**: ç¨€ãªå•é¡Œã®å¯èƒ½æ€§
#- **ãƒ¡ãƒªãƒƒãƒˆ**: æ‰‹é–“ãªã—
#- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: å•é¡ŒãŒç¶šãå¯èƒ½æ€§

# 2ï¸âƒ£ æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨
#- **æ‰‹é †**: 
  # ä½¿ç”¨ä¾‹:`
  # å•é¡Œã®ã‚ã‚‹çµæœ
#  result = "ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼šHello"
  
  # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
#  cleaned = clean_translation_result(result)
#  print(cleaned)  # â†’ "Hello"
  
#- **ãƒ¡ãƒªãƒƒãƒˆ**: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆç¶­æŒ
#- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: ä¸€éƒ¨æ‰‹é–“

# 3ï¸âƒ£ å‘¼ã³å‡ºã—éƒ¨åˆ†ã®ã¿å¤‰æ›´ï¼ˆç°¡å˜ï¼‰
#- **æ‰‹é †**: 
#  1. `langpont_lt.py` ã‚’é–‹ã
#  2. ä»¥ä¸‹ã®è¡Œã‚’æ¢ã™ï¼š
#     # ä½¿ç”¨ä¾‹:`
#     translated = f_translate_to_lightweight(input_text, source_lang, target_lang, partner_message, context_info)
#     
#  3. ã“ã‚Œã‚’ä»¥ä¸‹ã«å¤‰æ›´ï¼š
#     # ä½¿ç”¨ä¾‹:`
#     translated = f_translate_to_lightweight_japanese_backup(input_text, source_lang, target_lang, partner_message, context_info)
#     
#  4. ã‚¢ãƒ—ãƒªå†èµ·å‹•: `python langpont_lt.py`
#- **ãƒ¡ãƒªãƒƒãƒˆ**: ç¢ºå®Ÿã€å¤‰æ›´ç®‡æ‰€å°‘ãªã„
#- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã‚’å¤±ã†

# 4ï¸âƒ£ å®Œå…¨åˆ‡ã‚Šæ›¿ãˆï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
#- **æ‰‹é †**:
#  1. `langpont_lt.py` ã‚’é–‹ã
#  2. ç¾åœ¨ã® `f_translate_to_lightweight` é–¢æ•°ã‚’æ¢ã™
#  3. é–¢æ•°åã‚’ `f_translate_to_lightweight_english_backup` ã«å¤‰æ›´
#  4. `f_translate_to_lightweight_japanese_backup` ã®ä¸­èº«å…¨ä½“ã‚’ã‚³ãƒ”ãƒ¼
#  5. æ–°ã—ã„ `f_translate_to_lightweight` é–¢æ•°ã¨ã—ã¦è²¼ã‚Šä»˜ã‘
#  6. ã‚¢ãƒ—ãƒªå†èµ·å‹•: `python langpont_lt.py`
#- **ãƒ¡ãƒªãƒƒãƒˆ**: å®Œå…¨ç¢ºå®Ÿ
#- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã‚’å¤±ã†ã€å¤‰æ›´ç®‡æ‰€å¤šã„

# ğŸ“Š å„æ–¹æ³•ã®æ¯”è¼ƒè¡¨

#| æ–¹æ³• | æ‰‹é–“ | ç¢ºå®Ÿæ€§ | é€Ÿåº¦ç¶­æŒ | ã‚³ã‚¹ãƒˆç¶­æŒ |
#|------|------|--------|----------|------------|
#| 1ï¸âƒ£ æ§˜å­è¦‹ | â­â­â­ | â­ | âœ… | âœ… |
#| 2ï¸âƒ£ æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° | â­â­ | â­â­ | âœ… | âœ… |
#| 3ï¸âƒ£ ç°¡å˜åˆ‡ã‚Šæ›¿ãˆ | â­â­ | â­â­â­ | âŒ | âŒ |
#| 4ï¸âƒ£ å®Œå…¨åˆ‡ã‚Šæ›¿ãˆ | â­ | â­â­â­ | âŒ | âŒ |

# ğŸ¯ æ¨å¥¨å¯¾å¿œé †åº

#1. **ã¾ãš1ï¸âƒ£ã§æ§˜å­è¦‹** â†’ å•é¡ŒãŒç¶šãã‹ç¢ºèª
#2. **å•é¡ŒãŒç¶šããªã‚‰2ï¸âƒ£** â†’ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆç¶­æŒã—ã¤ã¤è§£æ±º
#3. **ãã‚Œã§ã‚‚ãƒ€ãƒ¡ãªã‚‰3ï¸âƒ£** â†’ ç°¡å˜ã§ç¢ºå®Ÿ
#4. **æœ€çµ‚æ‰‹æ®µã¨ã—ã¦4ï¸âƒ£** â†’ å®Œå…¨è§£æ±º

# ğŸ”„ å…ƒã«æˆ»ã™æ–¹æ³•

# æ—¥æœ¬èªç‰ˆâ†’è‹±èªç‰ˆã«æˆ»ã™å ´åˆ
#ä¸Šè¨˜æ‰‹é †ã®é€†ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ä»¥ä¸‹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒï¼š
#- `f_translate_to_lightweight_japanese_backup` (æ—¥æœ¬èªç‰ˆ)
#- `f_translate_to_lightweight_english_backup` (è‹±èªç‰ˆã€4ï¸âƒ£å®Ÿè¡Œæ™‚ã«ä½œæˆ)

# ğŸ“ ã‚µãƒãƒ¼ãƒˆ

#ã“ã®ã‚¬ã‚¤ãƒ‰ã§è§£æ±ºã—ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã¨å…±ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ï¼š
#- ç™ºç”Ÿã—ãŸç—‡çŠ¶ã®å…·ä½“ä¾‹
#- è©¦ã—ãŸå¯¾å¿œæ–¹æ³•
#- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ã‚Œã°ï¼‰


if __name__ == "__main__":
    port = int(sys.argv[1]) if len(sys.argv) > 1 else int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port, debug=True)