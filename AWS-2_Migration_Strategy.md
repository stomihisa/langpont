# ğŸš€ AWS-2: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œæˆ¦ç•¥

**æˆ¦ç•¥ä½œæˆæ—¥**: 2025å¹´7æœˆ25æ—¥  
**å¯¾è±¡**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ â†’ Redis ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ç§»è¡Œ  
**è¨­è¨ˆè€…**: Claude Code  

## ğŸ¯ ç§»è¡Œæˆ¦ç•¥æ¦‚è¦

### ç§»è¡Œç›®æ¨™
- **ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ **: < 5åˆ†ï¼ˆå¤œé–“ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚ï¼‰
- **ãƒ‡ãƒ¼ã‚¿æå¤±**: 0%ï¼ˆå…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿æŒï¼‰
- **ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½**: 24æ™‚é–“ä»¥å†…ã®ç·Šæ€¥åˆ‡ã‚Šæˆ»ã—å¯¾å¿œ

### ãƒªã‚¹ã‚¯æœ€å°åŒ–æ–¹é‡
1. **æ®µéšçš„ç§»è¡Œ**: Phaseåˆ†å‰²ã«ã‚ˆã‚‹å½±éŸ¿ç¯„å›²é™å®š
2. **ä¸¦è¡Œé‹ç”¨**: æ–°æ—§ã‚·ã‚¹ãƒ†ãƒ åŒæ™‚é‹ç”¨ã«ã‚ˆã‚‹å®‰å…¨æ€§ç¢ºä¿
3. **ãƒ›ãƒƒãƒˆã‚¹ãƒ¯ãƒƒãƒ—**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿æœ€å°é™ã®ãƒ©ã‚¤ãƒ–åˆ‡ã‚Šæ›¿ãˆ

---

## ğŸ“‹ 1. æ®µéšçš„ç§»è¡Œè¨ˆç”»

### Phase 1: ç’°å¢ƒæº–å‚™ãƒ»åŸºç›¤æ§‹ç¯‰ï¼ˆWeek 1-2ï¼‰

#### Phase 1a: ElastiCacheç’°å¢ƒæ§‹ç¯‰
```yaml
# Day 1-3: ã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰
Infrastructure_Setup:
  ElastiCache_Cluster:
    - Redis Clusteræ§‹ç¯‰ï¼ˆMulti-AZï¼‰
    - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—è¨­å®š
    - VPCå†…ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆæ¥ç¶šç¢ºèª
    
  Monitoring_Setup:
    - CloudWatch ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ
    - ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
    - ãƒ­ã‚°ç›£è¦–è¨­å®š
    
  Security_Configuration:
    - èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®š
    - æš—å·åŒ–è¨­å®šï¼ˆTransit/At-Restï¼‰
    - IAM ãƒ­ãƒ¼ãƒ«è¨­å®š
```

#### Phase 1b: ã‚³ãƒ¼ãƒ‰æº–å‚™ãƒ»ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰
```python
# Day 4-7: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æº–å‚™
Application_Preparation:
  Code_Development:
    - Redisæ¥ç¶šãƒ©ã‚¤ãƒ–ãƒ©ãƒªçµ±åˆ
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã‚¯ãƒ©ã‚¹å®Ÿè£…
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Ÿè£…
    
  Test_Environment:
    - ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã§ã®Redisçµ±åˆãƒ†ã‚¹ãƒˆ
    - è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª

# ãƒ†ã‚¹ãƒˆé …ç›®ä¾‹
TEST_SCENARIOS = [
    'basic_session_operations',    # åŸºæœ¬ã‚»ãƒƒã‚·ãƒ§ãƒ³æ“ä½œ
    'concurrent_access',          # åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
    'failover_behavior',          # ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ†ã‚¹ãƒˆ
    'data_persistence',           # ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ãƒ†ã‚¹ãƒˆ
    'performance_benchmark',      # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
]
```

#### Phase 1c: ç§»è¡Œãƒ„ãƒ¼ãƒ«é–‹ç™º
```python
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œãƒ„ãƒ¼ãƒ«
class SessionMigrationTool:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ â†’ Redis ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œãƒ„ãƒ¼ãƒ«
    """
    
    def __init__(self):
        self.file_session_path = '/var/lib/sessions'
        self.redis_client = get_redis_client()
        self.migration_log = []
    
    def analyze_existing_sessions(self) -> dict:
        """æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æ"""
        analysis = {
            'total_sessions': 0,
            'session_sizes': [],
            'session_types': {},
            'estimated_migration_time': 0
        }
        
        for session_file in os.listdir(self.file_session_path):
            if session_file.startswith('sess_'):
                analysis['total_sessions'] += 1
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿åˆ†æ
                session_data = self._load_file_session(session_file)
                size = len(str(session_data))
                analysis['session_sizes'].append(size)
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¨®åˆ¥åˆ†æ
                session_type = self._classify_session(session_data)
                analysis['session_types'][session_type] = analysis['session_types'].get(session_type, 0) + 1
        
        # ç§»è¡Œæ™‚é–“æ¨å®šï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° Ã— å¹³å‡å‡¦ç†æ™‚é–“ï¼‰
        analysis['estimated_migration_time'] = analysis['total_sessions'] * 0.01  # 10ms/session
        
        return analysis
    
    def migrate_session_batch(self, session_files: list) -> dict:
        """ãƒãƒƒãƒã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œ"""
        results = {
            'success_count': 0,
            'error_count': 0,
            'errors': []
        }
        
        for session_file in session_files:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿
                session_data = self._load_file_session(session_file)
                session_id = session_file.replace('sess_', '')
                
                # Redisã‚»ãƒƒã‚·ãƒ§ãƒ³å½¢å¼ã«å¤‰æ›
                redis_sessions = self._convert_to_redis_format(session_id, session_data)
                
                # Redisä¿å­˜
                for category, data in redis_sessions.items():
                    key = f"session:{category}:{session_id}"
                    self.redis_client.hmset(key, data)
                    
                    # TTLè¨­å®š
                    ttl = self._get_ttl_for_category(category)
                    self.redis_client.expire(key, ttl)
                
                results['success_count'] += 1
                
            except Exception as e:
                results['error_count'] += 1
                results['errors'].append({
                    'session_file': session_file,
                    'error': str(e)
                })
        
        return results
```

### Phase 2: ä¸¦è¡Œé‹ç”¨é–‹å§‹ï¼ˆWeek 3ï¼‰

#### Phase 2a: Write-Throughå®Ÿè£…
```python
# æ›¸ãè¾¼ã¿ä¸¡æ–¹åŒæœŸå®Ÿè£…
class DualWriteSessionManager:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»Redisä¸¡æ–¹æ›¸ãè¾¼ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    """
    
    def __init__(self):
        self.file_session = FileSessionManager()
        self.redis_session = RedisSessionManager()
        self.write_errors = []
    
    def set_session(self, session_id: str, category: str, data: dict) -> bool:
        """ãƒ‡ãƒ¥ã‚¢ãƒ«æ›¸ãè¾¼ã¿"""
        file_success = False
        redis_success = False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›¸ãè¾¼ã¿ï¼ˆæ—¢å­˜ï¼‰
        try:
            self.file_session.set(session_id, category, data)
            file_success = True
        except Exception as e:
            logger.error(f"File session write failed: {e}")
            self.write_errors.append(('file', session_id, str(e)))
        
        # Redisã‚»ãƒƒã‚·ãƒ§ãƒ³æ›¸ãè¾¼ã¿ï¼ˆæ–°ï¼‰
        try:
            self.redis_session.set(session_id, category, data)
            redis_success = True
        except Exception as e:
            logger.error(f"Redis session write failed: {e}")
            self.write_errors.append(('redis', session_id, str(e)))
        
        # å°‘ãªãã¨ã‚‚1ã¤æˆåŠŸã™ã‚Œã° OK
        return file_success or redis_success
    
    def get_session(self, session_id: str, category: str) -> dict:
        """èª­ã¿å–ã‚Šå„ªå…ˆé †ä½: ãƒ•ã‚¡ã‚¤ãƒ« â†’ Redis"""
        
        # Phase 2ã§ã¯æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
        try:
            return self.file_session.get(session_id, category)
        except Exception as e:
            logger.warning(f"File session read failed, trying Redis: {e}")
            
            try:
                return self.redis_session.get(session_id, category)
            except Exception as e2:
                logger.error(f"Both session systems failed: file={e}, redis={e2}")
                return {}
```

#### Phase 2b: ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æ¤œè¨¼
```python
class SessionConsistencyValidator:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»Redisé–“ã®ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æ¤œè¨¼
    """
    
    def validate_session_consistency(self, session_id: str) -> dict:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è²«æ€§æ¤œè¨¼"""
        validation_result = {
            'session_id': session_id,
            'consistent': True,
            'differences': [],
            'file_data': {},
            'redis_data': {}
        }
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿
            file_data = self._load_complete_file_session(session_id)
            validation_result['file_data'] = file_data
            
            # Redisã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿
            redis_data = self._load_complete_redis_session(session_id)
            validation_result['redis_data'] = redis_data
            
            # ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ
            differences = self._compare_session_data(file_data, redis_data)
            validation_result['differences'] = differences
            validation_result['consistent'] = len(differences) == 0
            
        except Exception as e:
            validation_result['error'] = str(e)
            validation_result['consistent'] = False
        
        return validation_result
    
    def batch_validate_sessions(self, session_ids: list) -> dict:
        """ãƒãƒƒãƒã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è²«æ€§æ¤œè¨¼"""
        results = {
            'total_sessions': len(session_ids),
            'consistent_sessions': 0,
            'inconsistent_sessions': 0,
            'error_sessions': 0,
            'inconsistencies': []
        }
        
        for session_id in session_ids:
            validation = self.validate_session_consistency(session_id)
            
            if validation.get('error'):
                results['error_sessions'] += 1
            elif validation['consistent']:
                results['consistent_sessions'] += 1
            else:
                results['inconsistent_sessions'] += 1
                results['inconsistencies'].append(validation)
        
        return results
```

### Phase 3: èª­ã¿å–ã‚Šåˆ‡ã‚Šæ›¿ãˆï¼ˆWeek 4ï¼‰

#### Phase 3a: Read-Throughå®Ÿè£…
```python
class ReadThroughSessionManager:
    """
    èª­ã¿å–ã‚Šå„ªå…ˆåº¦å¤‰æ›´: Redis â†’ ãƒ•ã‚¡ã‚¤ãƒ«
    """
    
    def get_session(self, session_id: str, category: str) -> dict:
        """èª­ã¿å–ã‚Šå„ªå…ˆé †ä½: Redis â†’ ãƒ•ã‚¡ã‚¤ãƒ« â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"""
        
        # 1st: Redisèª­ã¿å–ã‚Šè©¦è¡Œ
        try:
            redis_data = self.redis_session.get(session_id, category)
            if redis_data:
                return redis_data
        except Exception as e:
            logger.warning(f"Redis session read failed: {e}")
        
        # 2nd: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šè©¦è¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        try:
            file_data = self.file_session.get(session_id, category)
            if file_data:
                # Redisã«åŒæœŸï¼ˆèª­ã¿å–ã‚Šæ™‚è‡ªå‹•è£œå®Œï¼‰
                try:
                    self.redis_session.set(session_id, category, file_data)
                except Exception:
                    pass  # åŒæœŸå¤±æ•—ã¯ç„¡è¦–
                
                return file_data
        except Exception as e:
            logger.error(f"File session read failed: {e}")
        
        # 3rd: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return self._get_default_session_data(category)
```

#### Phase 3b: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–å¼·åŒ–
```python
class MigrationPerformanceMonitor:
    """
    ç§»è¡Œæ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    """
    
    def __init__(self):
        self.metrics = {
            'redis_read_latency': [],
            'file_read_latency': [],
            'read_success_rate': 0,
            'write_success_rate': 0,
            'consistency_rate': 0
        }
    
    def measure_read_performance(self, session_id: str, category: str) -> dict:
        """èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š"""
        results = {}
        
        # Redisèª­ã¿å–ã‚Šæ€§èƒ½
        start_time = time.time()
        try:
            redis_data = redis_session.get(session_id, category)
            redis_latency = (time.time() - start_time) * 1000
            results['redis'] = {
                'success': True,
                'latency_ms': redis_latency,
                'data_size': len(str(redis_data))
            }
        except Exception as e:
            results['redis'] = {
                'success': False,
                'error': str(e)
            }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šæ€§èƒ½
        start_time = time.time()
        try:
            file_data = file_session.get(session_id, category)
            file_latency = (time.time() - start_time) * 1000
            results['file'] = {
                'success': True,
                'latency_ms': file_latency,
                'data_size': len(str(file_data))
            }
        except Exception as e:
            results['file'] = {
                'success': False,
                'error': str(e)
            }
        
        return results
```

### Phase 4: å®Œå…¨åˆ‡ã‚Šæ›¿ãˆï¼ˆWeek 5ï¼‰

#### Phase 4a: Write-Only Rediså®Ÿè£…
```python
class RedisOnlySessionManager:
    """
    Rediså°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿åœæ­¢ï¼‰
    """
    
    def __init__(self):
        self.redis_session = RedisSessionManager()
        self.file_session = FileSessionManager()  # èª­ã¿å–ã‚Šå°‚ç”¨ä¿æŒ
        
    def set_session(self, session_id: str, category: str, data: dict) -> bool:
        """Rediså°‚ç”¨æ›¸ãè¾¼ã¿"""
        try:
            return self.redis_session.set(session_id, category, data)
        except Exception as e:
            logger.error(f"Redis session write failed: {e}")
            
            # ç·Šæ€¥æ™‚ã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if self._is_emergency_fallback_enabled():
                logger.warning("Emergency fallback to file session")
                return self.file_session.set(session_id, category, data)
            
            return False
    
    def get_session(self, session_id: str, category: str) -> dict:
        """Rediså„ªå…ˆèª­ã¿å–ã‚Š"""
        
        # Redisèª­ã¿å–ã‚Š
        try:
            redis_data = self.redis_session.get(session_id, category)
            if redis_data:
                return redis_data
        except Exception as e:
            logger.warning(f"Redis read failed: {e}")
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šï¼ˆç§»è¡ŒæœŸé–“ã®ã¿ï¼‰
        try:
            file_data = self.file_session.get(session_id, category)
            if file_data:
                # Redisã¸ç§»è¡Œï¼ˆä¸€åº¦é™ã‚Šï¼‰
                try:
                    self.redis_session.set(session_id, category, file_data)
                    logger.info(f"Migrated legacy session: {session_id}:{category}")
                except Exception:
                    pass
                
                return file_data
        except Exception:
            pass
        
        return {}
```

#### Phase 4b: ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹åŒ–
```python
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æ®µéšçš„ç„¡åŠ¹åŒ–
class FileSessionDeprecation:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æ®µéšçš„å»ƒæ­¢
    """
    
    def __init__(self):
        self.deprecation_start = datetime.now()
        self.complete_cutoff = self.deprecation_start + timedelta(days=7)
    
    def should_read_file_session(self, session_id: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿å–ã‚Šå¯å¦åˆ¤å®š"""
        
        # å®Œå…¨ã‚«ãƒƒãƒˆã‚ªãƒ•å¾Œã¯èª­ã¿å–ã‚Šä¸å¯
        if datetime.now() > self.complete_cutoff:
            return False
        
        # Rediså¤±æ•—æ™‚ã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šè¨±å¯
        try:
            redis_session.exists(session_id)
            return False  # Redisã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦
        except Exception:
            return True   # Rediså¤±æ•—æ™‚ã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Š
    
    def cleanup_old_file_sessions(self):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cleanup_count = 0
        
        for session_file in os.listdir(self.file_session_path):
            file_path = os.path.join(self.file_session_path, session_file)
            
            # 1é€±é–“ä»¥ä¸Šå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.getmtime(file_path) < time.time() - 604800:  # 7æ—¥
                try:
                    os.remove(file_path)
                    cleanup_count += 1
                except Exception as e:
                    logger.error(f"Failed to cleanup session file {session_file}: {e}")
        
        logger.info(f"Cleaned up {cleanup_count} old session files")
```

---

## ğŸ§ª 2. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 2.1 å˜ä½“ãƒ†ã‚¹ãƒˆæ–¹é‡

#### ã‚»ãƒƒã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
```python
import unittest
from unittest.mock import Mock, patch

class SessionMigrationTests(unittest.TestCase):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œå˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        self.redis_mock = Mock()
        self.file_session_mock = Mock()
        self.session_manager = DualWriteSessionManager()
    
    def test_dual_write_success(self):
        """ãƒ‡ãƒ¥ã‚¢ãƒ«æ›¸ãè¾¼ã¿æˆåŠŸãƒ†ã‚¹ãƒˆ"""
        session_data = {'user_id': '123', 'username': 'test'}
        
        result = self.session_manager.set_session('sess_123', 'auth', session_data)
        
        self.assertTrue(result)
        self.redis_mock.hmset.assert_called_once()
        self.file_session_mock.set.assert_called_once()
    
    def test_redis_write_failure_fallback(self):
        """Redisæ›¸ãè¾¼ã¿å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.redis_mock.hmset.side_effect = ConnectionError("Redis down")
        session_data = {'user_id': '123'}
        
        result = self.session_manager.set_session('sess_123', 'auth', session_data)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ãŒæˆåŠŸã™ã‚Œã°å…¨ä½“æˆåŠŸ
        self.assertTrue(result)
        self.file_session_mock.set.assert_called_once()
    
    def test_session_consistency_validation(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è²«æ€§æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        validator = SessionConsistencyValidator()
        
        # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿è¨­å®š
        file_data = {'username': 'test', 'role': 'user'}
        redis_data = {'username': 'test', 'role': 'admin'}  # å·®åˆ†ã‚ã‚Š
        
        with patch.object(validator, '_load_complete_file_session', return_value=file_data), \
             patch.object(validator, '_load_complete_redis_session', return_value=redis_data):
            
            result = validator.validate_session_consistency('sess_123')
            
            self.assertFalse(result['consistent'])
            self.assertEqual(len(result['differences']), 1)
    
    def test_performance_benchmark(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
        monitor = MigrationPerformanceMonitor()
        
        # 100å›èª­ã¿å–ã‚Šæ€§èƒ½æ¸¬å®š
        latencies = []
        for i in range(100):
            start = time.time()
            self.session_manager.get_session(f'sess_{i}', 'auth')
            latency = (time.time() - start) * 1000
            latencies.append(latency)
        
        avg_latency = sum(latencies) / len(latencies)
        self.assertLess(avg_latency, 50, "Average latency should be < 50ms")
```

### 2.2 çµ±åˆãƒ†ã‚¹ãƒˆæ–¹é‡

#### ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
```python
class SessionMigrationIntegrationTests(unittest.TestCase):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»è¡Œçµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒ†ã‚¹ãƒˆç”¨Redisèµ·å‹•
        cls.redis_client = redis.Redis(host='localhost', port=6380, db=1)
        
        # ãƒ†ã‚¹ãƒˆç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        cls.test_sessions = cls._create_test_sessions(100)
    
    def test_full_migration_workflow(self):
        """å®Œå…¨ç§»è¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        migration_tool = SessionMigrationTool()
        
        # Phase 1: åˆ†æ
        analysis = migration_tool.analyze_existing_sessions()
        self.assertGreater(analysis['total_sessions'], 0)
        
        # Phase 2: ç§»è¡Œå®Ÿè¡Œ
        session_files = list(self.test_sessions.keys())
        results = migration_tool.migrate_session_batch(session_files)
        
        self.assertEqual(results['error_count'], 0)
        self.assertEqual(results['success_count'], len(session_files))
        
        # Phase 3: æ¤œè¨¼
        validator = SessionConsistencyValidator()
        validation_results = validator.batch_validate_sessions(session_files)
        
        self.assertEqual(validation_results['inconsistent_sessions'], 0)
    
    def test_failover_behavior(self):
        """ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼å‹•ä½œãƒ†ã‚¹ãƒˆ"""
        session_manager = RedisOnlySessionManager()
        
        # æ­£å¸¸æ™‚å‹•ä½œç¢ºèª
        session_manager.set_session('test_session', 'auth', {'user': 'test'})
        data = session_manager.get_session('test_session', 'auth')
        self.assertEqual(data['user'], 'test')
        
        # Rediséšœå®³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        with patch.object(session_manager.redis_session, 'get', side_effect=ConnectionError):
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª
            data = session_manager.get_session('test_session', 'auth')
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒè¿”ã•ã‚Œã‚‹ã“ã¨
            self.assertIsInstance(data, dict)
    
    def test_concurrent_access(self):
        """åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"""
        import threading
        import queue
        
        session_manager = DualWriteSessionManager()
        results = queue.Queue()
        
        def worker(session_id):
            try:
                # åŒæ™‚æ›¸ãè¾¼ã¿
                session_manager.set_session(session_id, 'auth', {'user': session_id})
                
                # å³åº§ã«èª­ã¿å–ã‚Š
                data = session_manager.get_session(session_id, 'auth')
                results.put(('success', session_id, data))
            except Exception as e:
                results.put(('error', session_id, str(e)))
        
        # 50å€‹ã®åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹
        threads = []
        for i in range(50):
            thread = threading.Thread(target=worker, args=(f'concurrent_{i}',))
            threads.append(thread)
            thread.start()
        
        # å…¨ã‚¹ãƒ¬ãƒƒãƒ‰å®Œäº†å¾…ã¡
        for thread in threads:
            thread.join()
        
        # çµæœæ¤œè¨¼
        success_count = 0
        error_count = 0
        
        while not results.empty():
            result_type, session_id, data = results.get()
            if result_type == 'success':
                success_count += 1
            else:
                error_count += 1
        
        self.assertEqual(error_count, 0, "No concurrent access errors should occur")
        self.assertEqual(success_count, 50, "All concurrent operations should succeed")
```

### 2.3 è² è·ãƒ†ã‚¹ãƒˆè¨­è¨ˆ

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
```python
import locust
from locust import HttpUser, task, between

class SessionLoadTest(HttpUser):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³è² è·ãƒ†ã‚¹ãƒˆ"""
    
    wait_time = between(1, 3)  # 1-3ç§’é–“éš”
    
    def on_start(self):
        """ãƒ†ã‚¹ãƒˆé–‹å§‹æ™‚ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒ­ã‚°ã‚¤ãƒ³
        self.client.post("/login", data={
            "username": "test_user",
            "password": "test_password"
        })
    
    @task(3)
    def session_read_heavy(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿å–ã‚Šé›†ç´„ãƒ†ã‚¹ãƒˆ"""
        # ç¿»è¨³ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿å–ã‚Šé›†ç´„ï¼‰
        self.client.get("/")
        
    @task(1)
    def session_write_moderate(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›¸ãè¾¼ã¿ä¸­ç¨‹åº¦ãƒ†ã‚¹ãƒˆ"""
        # ç¿»è¨³å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°ï¼‰
        self.client.post("/translate", data={
            "input_text": "Test translation",
            "source_lang": "en",
            "target_lang": "jp"
        })
    
    @task(1)
    def language_switch(self):
        """è¨€èªåˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ"""
        self.client.post("/set_language", data={
            "language": "en"
        })

# è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè¨­å®š
class LoadTestConfiguration:
    """è² è·ãƒ†ã‚¹ãƒˆè¨­å®š"""
    
    TEST_SCENARIOS = {
        'baseline': {
            'users': 50,
            'spawn_rate': 5,
            'duration': '10m'
        },
        'stress': {
            'users': 200,
            'spawn_rate': 10,
            'duration': '30m'
        },
        'spike': {
            'users': 500,
            'spawn_rate': 50,
            'duration': '5m'
        }
    }
    
    PERFORMANCE_THRESHOLDS = {
        'response_time_p95': 500,  # 95%ile < 500ms
        'error_rate': 0.01,        # ã‚¨ãƒ©ãƒ¼ç‡ < 1%
        'throughput_min': 100,     # æœ€ä½100 req/sec
    }
```

---

## ğŸ”„ 3. ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­è¨ˆ

### 3.1 ç·Šæ€¥åˆ‡ã‚Šæˆ»ã—æ‰‹é †

#### å³åº§å®Ÿè¡Œå¯èƒ½ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
```python
class EmergencyRollback:
    """ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"""
    
    def __init__(self):
        self.rollback_log = []
        self.backup_redis_data = {}
    
    def execute_immediate_rollback(self, reason: str) -> dict:
        """å³åº§ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"""
        rollback_result = {
            'timestamp': datetime.now().isoformat(),
            'reason': reason,
            'steps_completed': [],
            'success': False
        }
        
        try:
            # Step 1: Redisæ›¸ãè¾¼ã¿åœæ­¢
            self._disable_redis_writes()
            rollback_result['steps_completed'].append('redis_writes_disabled')
            
            # Step 2: ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ‰åŠ¹åŒ–
            self._enable_file_sessions()
            rollback_result['steps_completed'].append('file_sessions_enabled')
            
            # Step 3: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šåˆ‡ã‚Šæˆ»ã—
            self._revert_application_config()
            rollback_result['steps_completed'].append('app_config_reverted')
            
            # Step 4: ç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
            self._send_rollback_alert(reason)
            rollback_result['steps_completed'].append('alerts_sent')
            
            rollback_result['success'] = True
            logger.critical(f"Emergency rollback completed: {reason}")
            
        except Exception as e:
            rollback_result['error'] = str(e)
            logger.critical(f"Emergency rollback failed: {e}")
        
        return rollback_result
    
    def _disable_redis_writes(self):
        """Redisæ›¸ãè¾¼ã¿ç„¡åŠ¹åŒ–"""
        # ç’°å¢ƒå¤‰æ•°ã§Redisæ›¸ãè¾¼ã¿ç„¡åŠ¹åŒ–
        os.environ['REDIS_WRITES_ENABLED'] = 'false'
        
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
        with open('/app/config/emergency_config.json', 'w') as f:
            json.dump({
                'session_backend': 'file',
                'redis_enabled': False,
                'emergency_mode': True
            }, f)
    
    def _enable_file_sessions(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ‰åŠ¹åŒ–"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
        session_dir = '/var/lib/sessions'
        if not os.path.exists(session_dir):
            os.makedirs(session_dir, mode=0o755)
        
        # æ¨©é™ç¢ºèªãƒ»ä¿®æ­£
        os.chmod(session_dir, 0o755)
        
        # Flask-Sessionè¨­å®šåˆ‡ã‚Šæˆ»ã—
        os.environ['SESSION_TYPE'] = 'filesystem'
```

### 3.2 ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºä¿

#### ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ãƒ‡ãƒ¼ã‚¿ä¿è­·
```python
class RollbackDataProtection:
    """ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ãƒ‡ãƒ¼ã‚¿ä¿è­·"""
    
    def backup_redis_sessions(self) -> str:
        """Rediså…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        backup_file = f"/backups/redis_sessions_{int(time.time())}.json"
        backup_data = {}
        
        try:
            # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼å–å¾—
            for key in redis_client.scan_iter(match="session:*"):
                if redis_client.type(key) == 'hash':
                    backup_data[key] = redis_client.hgetall(key)
                else:
                    backup_data[key] = redis_client.get(key)
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            with open(backup_file, 'w') as f:
                json.dump(backup_data, f, indent=2, default=str)
            
            logger.info(f"Redis sessions backed up to {backup_file}")
            return backup_file
            
        except Exception as e:
            logger.error(f"Redis backup failed: {e}")
            raise
    
    def restore_from_backup(self, backup_file: str) -> dict:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ"""
        restore_result = {
            'restored_sessions': 0,
            'failed_sessions': 0,
            'errors': []
        }
        
        try:
            with open(backup_file, 'r') as f:
                backup_data = json.load(f)
            
            for key, data in backup_data.items():
                try:
                    if isinstance(data, dict):
                        redis_client.hmset(key, data)
                    else:
                        redis_client.set(key, data)
                    
                    restore_result['restored_sessions'] += 1
                    
                except Exception as e:
                    restore_result['failed_sessions'] += 1
                    restore_result['errors'].append({
                        'key': key,
                        'error': str(e)
                    })
            
        except Exception as e:
            logger.error(f"Backup restore failed: {e}")
            raise
        
        return restore_result
    
    def convert_redis_to_file_sessions(self) -> dict:
        """Redis â†’ ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ›"""
        conversion_result = {
            'converted_sessions': 0,
            'failed_conversions': 0,
            'errors': []
        }
        
        session_dir = '/var/lib/sessions'
        os.makedirs(session_dir, exist_ok=True)
        
        # Rediså…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—
        for key in redis_client.scan_iter(match="session:*"):
            try:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDæŠ½å‡º
                key_parts = key.split(':')
                if len(key_parts) >= 3:
                    category = key_parts[1]
                    session_id = key_parts[2]
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³å½¢å¼ã«å¤‰æ›
                    file_session_data = self._convert_to_file_format(
                        session_id, category, redis_client.hgetall(key)
                    )
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                    session_file = os.path.join(session_dir, f"sess_{session_id}")
                    with open(session_file, 'w') as f:
                        json.dump(file_session_data, f)
                    
                    conversion_result['converted_sessions'] += 1
                
            except Exception as e:
                conversion_result['failed_conversions'] += 1
                conversion_result['errors'].append({
                    'key': key,
                    'error': str(e)
                })
        
        return conversion_result
```

### 3.3 æ®µéšçš„åˆ‡ã‚Šæˆ»ã—

#### éƒ¨åˆ†çš„ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
```python
class GradualRollback:
    """æ®µéšçš„ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    
    def __init__(self):
        self.rollback_phases = [
            'stop_new_redis_sessions',
            'revert_read_priority',  
            'revert_write_priority',
            'disable_redis_completely'
        ]
        self.current_phase = None
    
    def execute_phase_rollback(self, target_phase: str) -> dict:
        """æ®µéšçš„ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"""
        rollback_result = {
            'target_phase': target_phase,
            'completed_phases': [],
            'success': False
        }
        
        try:
            phase_index = self.rollback_phases.index(target_phase)
            
            for i in range(phase_index + 1):
                phase = self.rollback_phases[i]
                
                if phase == 'stop_new_redis_sessions':
                    self._stop_new_redis_sessions()
                elif phase == 'revert_read_priority':
                    self._revert_read_priority()
                elif phase == 'revert_write_priority':
                    self._revert_write_priority()
                elif phase == 'disable_redis_completely':
                    self._disable_redis_completely()
                
                rollback_result['completed_phases'].append(phase)
                self.current_phase = phase
                
                # å„ãƒ•ã‚§ãƒ¼ã‚ºå¾Œã®å®‰å®šæ€§ç¢ºèª
                if not self._verify_phase_stability():
                    raise Exception(f"Phase {phase} instability detected")
            
            rollback_result['success'] = True
            
        except Exception as e:
            rollback_result['error'] = str(e)
            logger.error(f"Phase rollback failed at {self.current_phase}: {e}")
        
        return rollback_result
    
    def _verify_phase_stability(self) -> bool:
        """ãƒ•ã‚§ãƒ¼ã‚ºå®‰å®šæ€§ç¢ºèª"""
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿å–ã‚Šãƒ†ã‚¹ãƒˆ
            test_session_data = self._test_session_operations()
            
            # ã‚¨ãƒ©ãƒ¼ç‡ç¢ºèª
            error_rate = self._calculate_recent_error_rate()
            
            return (test_session_data['success'] and 
                   error_rate < 0.05)  # 5%æœªæº€ã®ã‚¨ãƒ©ãƒ¼ç‡
                   
        except Exception:
            return False
```

---

## â±ï¸ 4. ç§»è¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¨­è¨ˆ

```
Week 1: åŸºç›¤æº–å‚™
â”œâ”€â”€ Day 1-2: ElastiCacheæ§‹ç¯‰ãƒ»è¨­å®š
â”œâ”€â”€ Day 3-4: ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
â””â”€â”€ Day 5-7: ç§»è¡Œãƒ„ãƒ¼ãƒ«é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ

Week 2: ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼
â”œâ”€â”€ Day 8-10: ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒçµ±åˆãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ Day 11-12: è² è·ãƒ†ã‚¹ãƒˆãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª
â””â”€â”€ Day 13-14: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆãƒ»è„†å¼±æ€§ç¢ºèª

Week 3: ä¸¦è¡Œé‹ç”¨é–‹å§‹ï¼ˆPhase 2ï¼‰
â”œâ”€â”€ Day 15: Write-Throughå®Ÿè£…ãƒ‡ãƒ—ãƒ­ã‚¤
â”œâ”€â”€ Day 16-18: ä¸¦è¡Œé‹ç”¨ç›£è¦–ãƒ»èª¿æ•´
â””â”€â”€ Day 19-21: ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æ¤œè¨¼ãƒ»å•é¡Œä¿®æ­£

Week 4: èª­ã¿å–ã‚Šåˆ‡ã‚Šæ›¿ãˆï¼ˆPhase 3ï¼‰
â”œâ”€â”€ Day 22: Read-Throughå®Ÿè£…ãƒ‡ãƒ—ãƒ­ã‚¤
â”œâ”€â”€ Day 23-25: èª­ã¿å–ã‚Šå„ªå…ˆåº¦å¤‰æ›´ç›£è¦–
â””â”€â”€ Day 26-28: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

Week 5: å®Œå…¨ç§»è¡Œï¼ˆPhase 4ï¼‰
â”œâ”€â”€ Day 29: Rediså°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ‡ãƒ—ãƒ­ã‚¤
â”œâ”€â”€ Day 30-32: ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³æ®µéšçš„å»ƒæ­¢
â””â”€â”€ Day 33-35: ç§»è¡Œå®Œäº†ç¢ºèªãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
```

### ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ æœ€å°åŒ–
- **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚é–“**: å¤œé–“2-6æ™‚ï¼ˆJSTï¼‰
- **ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ‡ãƒ—ãƒ­ã‚¤**: ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ é…å¸ƒ
- **ãƒ›ãƒƒãƒˆã‚¹ãƒ¯ãƒƒãƒ—**: è¨­å®šåˆ‡ã‚Šæ›¿ãˆã«ã‚ˆã‚‹å³åº§ç§»è¡Œ

---

## âœ… ç§»è¡Œæˆ¦ç•¥å®Œäº†ç¢ºèª

- âœ… **æ®µéšçš„ç§»è¡Œè¨ˆç”»**: 5Phaseè©³ç´°è¨ˆç”»å®Œæˆ
- âœ… **ãƒ†ã‚¹ãƒˆæˆ¦ç•¥**: å˜ä½“ãƒ»çµ±åˆãƒ»è² è·ãƒ†ã‚¹ãƒˆè¨­è¨ˆå®Œäº†
- âœ… **ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­è¨ˆ**: ç·Šæ€¥ãƒ»æ®µéšçš„åˆ‡ã‚Šæˆ»ã—è¨­è¨ˆå®Œäº†
- âœ… **ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**: 5é€±é–“è©³ç´°ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç¢ºå®š
- âœ… **ãƒªã‚¹ã‚¯æœ€å°åŒ–**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ <5åˆ†ãƒ»ãƒ‡ãƒ¼ã‚¿æå¤±0%è¨­è¨ˆ

**ç§»è¡Œæˆ¦ç•¥å®Œæˆ**: Redisç§»è¡Œå®Œå…¨æˆ¦ç•¥ç¢ºç«‹  
**å®Ÿè¡Œæº–å‚™åº¦**: 100%å®Œäº† - å³åº§ã«ç§»è¡Œå®Ÿè¡Œå¯èƒ½